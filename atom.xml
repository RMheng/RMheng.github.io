<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>rww&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/252dd8f805587344d8d0dd0919c6d079</icon>
  <subtitle>半夏花已开，未来诚可期</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-06-18T13:22:59.217Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>rmheng</name>
    <email>ruanwenwen@iie.ac.cn</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>VT-x, KVM, QEMU如何一起愉快地工作</title>
    <link href="http://yoursite.com/2021/06/18/2021-06-18-VT-x-KVM-QEMU/"/>
    <id>http://yoursite.com/2021/06/18/2021-06-18-VT-x-KVM-QEMU/</id>
    <published>2021-06-18T13:19:10.000Z</published>
    <updated>2021-06-18T13:22:59.217Z</updated>
    
    <content type="html"><![CDATA[<p>Intel Virtualization: VT-x, KVM, QEMU如何一起愉快地工作</p><a id="more"></a><blockquote><p>When we talk about virtualization we mean hardware assisted virtualization where the VM’s processor matches host computer’s processor. </p></blockquote><blockquote><p>Containerization is mostly a software concept and it builds on top of operating system abstractions like process identifiers, file system and memory consumption limits.</p></blockquote><blockquote><p>In case of KVM, this is actually Linux kernel which has KVM modules loaded into it. In other words, KVM is a set of kernel modules that when loaded into Linux kernel turn the kernel into hypervisor. </p></blockquote><p>Full virtualization: when OS that is running inside a VM is exactly the same as would be running on real hardware.</p><p>Paravirtualization: when OS inside VM is aware that it is being virtualized and thus runs in a slightly modified way than it would on real hardware.</p><p><img src="/2021/06/18/2021-06-18-VT-x-KVM-QEMU/image-20210612163024109.png" alt="image-20210612163024109"></p><h2 id="VT-x"><a href="#VT-x" class="headerlink" title="VT-x"></a>VT-x</h2><p>VT-x是用于Intel64和IA-32架构的CPU虚拟化。VT-x中的CPU操作有两种模式：root和non-root。Hypervisor运行在root模式，而VMs运行在non-root模式。non-root模式可以模拟在root模式下的操作，但需要注意的是”global state-changing”指令，这些指令能够影响CPU状态，这些指令是non-root模式下无法执行的。</p><blockquote><p>Examples are those instructions which modify clock or interrupt registers, or write to control registers in a way that will change the operation of root mode.</p></blockquote><h3 id="VMX-Virtual-Machine-Extension"><a href="#VMX-Virtual-Machine-Extension" class="headerlink" title="VMX(Virtual Machine Extension)"></a>VMX(Virtual Machine Extension)</h3><p>VMX是一系列用于支持VT-x的指令。</p><p><code>VMXON</code>： 用于进入虚拟化的指令，执行完毕后，CPU在root模式下；</p><p><code>VMXOFF</code>：执行完毕后，退出虚拟化；</p><p><code>VMLAUNCH</code>：构造一个VM实例并进入non-root模式；</p><p><code>VMRESUME</code>：进入non-root模式和一个已经存在的VM实例。</p><p><img src="/2021/06/18/2021-06-18-VT-x-KVM-QEMU/image-20210607112952018.png" alt="image-20210607112952018"></p><p>当一个VM尝试执行一条不被运行在non-root模式下执行的指令时，CPU以trap-like的方式切换到root模式，这就是VM exit。</p><ul><li>CPU首先运行在普通模式下，执行<code>VMXON</code>开始了root模式下的虚拟化</li><li>接着，执行<code>VMLAUNCH</code>进入non-root模式并构造了一个VM实例</li><li>当VM实例运行自己的代码，并尝试执行不被运行的命令时，会触发<code>VM exit</code>，并切换到root模式</li><li>切换到root模式时，控制权已经转移到了hypervisor上，hypervisor检查引起<code>VM exit</code>的原因，而后执行<code>VMRESUME</code>重新回到non-root模式下的该VM实例</li></ul><p>Q1：hypervisor如何知道VM exit的原因？不同的VM实例之间如何区分？</p><p>A1：从VMCS结构中得知。</p><p>每个vCPU都有一个VMCS，VMCS以CPU级别存储信息。</p><ul><li><code>VMREAD</code>：读取特定VMCS</li><li><code>VMWRITE</code>：写特定VMCS</li></ul><p>这两条指令都需要root模式，并且只有hypervisor能够修改VMCS。Non-root模式下的VM虽然可以执行VMWRITE，但写入的并不是真正的VMCS，而是”shadow” VMCS.</p><p>有一些指令是作用在所有的VMCS实例中，而不是单独的VMCS。</p><ul><li><code>VMPTRLD</code>: load the address of a VMCS</li><li><code>VMPTRST</code>: store the address to a specified memory address</li></ul><p>虽然可以有多个VMCS实例，但只能有一个时刻只能有一个active的VMCS。<code>VMPTRLD</code>标记该特定的VMCS为active。当执行<code>VMRESUME</code>时，non-root模式下的VM通过active VMCS实例就可以知道正在运行的VM和vCPU。</p><p>VMCS主要保存两种类型的信息：</p><ul><li>在进行root和non-root上下文切换时，CPU寄存器需要保存和恢复的信息</li><li>non-root下，决定VM行为的控制信息。（比如设置了特定的比特位，就可以允许VM尝试执行<code>RDTSC</code>时不会引起<code>VM exit</code></li></ul><p>VMCS可以被划分为6个区域：</p><ul><li>GUEST-STATE域：虚拟机从根操作模式进入非根操作模式时，处理器所处于的状态保存在这里</li><li>HOST-STATE域：虚拟机从非根模式退出到根操作模式时，处理器所处于的状态保存在这里</li><li>VM execution control fields：虚拟机在非根操作模式运行时，处理器所处于的状态</li><li>VM exit control fields：虚拟机从非根操作模式下退出时，需要保存的信息</li><li>VM entry control fields：虚拟机从跟模式进入非根模式时，需要读取的信息</li><li>VM exit information fields：虚拟机从非根操作模式退出到根操作模式，将退出的原因保存到该域中</li></ul><p>Guest software指令：</p><ul><li>INVEPT: GPA-&gt;HPA相关缓存刷新</li><li>INVVPID: 用于GVA-&gt;GPA的刷新</li></ul><h2 id="KVM-Kernel-based-Virtual-Machine"><a href="#KVM-Kernel-based-Virtual-Machine" class="headerlink" title="KVM(Kernel-based Virtual Machine)"></a>KVM(Kernel-based Virtual Machine)</h2><p><strong>KVM: a set of Linux kernel modules that when loaded, turn Linux kernel into hypervisor.</strong></p><p>KVM模块可以被分成两部分：</p><ul><li>core module: kvm.ko</li><li>machine specific modules: 取决于host machine CPU，比如VT-x需要的就是kvm-intel.ko</li></ul><p>KVM与用户空间进行交互，在本文的语境下，就是QEMU通过两种方式：</p><ul><li>device file <code>/dev/kvm</code><ul><li>system level: </li><li>vm level: </li><li>vCPU level: </li></ul></li><li>memory mapped pages: 用于QEMU和KVM之间批量数据传递</li></ul><h2 id="QEMU-Quick-Emulator"><a href="#QEMU-Quick-Emulator" class="headerlink" title="QEMU(Quick Emulator)"></a>QEMU(Quick Emulator)</h2><blockquote><p>QEMU creates one process for every VM. For each vCPU, QEMU creates a thread. These are regular threads and they get scheduled by the OS like any other thread. </p><p>As these threads get run time, QEMU creates impression of multiple CPUs for the software running inside its VM. </p></blockquote><p>QEMU能够进行模拟，它能够模拟一些KVM并不支持的I/O操作。举个例子，当VM中的某个软件希望执行I/O操作：</p><ul><li>VM返回KVM</li><li>KVM查找VM exit的原因，将控制权以及I/O请求信息的指针转交给QEMU</li><li>QEMU为该请求模拟I/O设备</li><li>当VM中的软件执行完毕后，KVM重新获得控制权，并且执行VMRESUME重新执行VM。</li></ul><p><img src="/2021/06/18/2021-06-18-VT-x-KVM-QEMU/image-20210612222222989.png" alt="image-20210612222222989"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://binarydebt.wordpress.com/2018/10/14/intel-virtualisation-how-vt-x-kvm-and-qemu-work-together/" target="_blank" rel="noopener">Intel Virtualization: How VT-x, kVM and QEMU Work Together</a></li><li><a href="https://blog.csdn.net/wanthelping/article/details/47068745" target="_blank" rel="noopener">内核VMX基本数据结构与操作</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Intel Virtualization: VT-x, KVM, QEMU如何一起愉快地工作&lt;/p&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="http://yoursite.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://yoursite.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://yoursite.com/tags/KVM/"/>
    
      <category term="VT-x" scheme="http://yoursite.com/tags/VT-x/"/>
    
      <category term="QEMU" scheme="http://yoursite.com/tags/QEMU/"/>
    
  </entry>
  
  <entry>
    <title>kvm environment in vmware</title>
    <link href="http://yoursite.com/2021/06/11/2021-06-11-kvm-environment-in-vmware/"/>
    <id>http://yoursite.com/2021/06/11/2021-06-11-kvm-environment-in-vmware/</id>
    <published>2021-06-11T04:11:10.000Z</published>
    <updated>2021-06-11T12:01:04.612Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下昨天晚上苦逼地搭建KVM unit test环境的过程。</p><a id="more"></a><p>首先梳理一下和<a href="http://liujunming.top/" target="_blank" rel="noopener">liujunming</a>学长讨论得到一些结论：</p><p>Q1：在腾讯云服务器上搭建kvm unit test环境，一直显示：</p><blockquote><p>qemu-system-x86_64: failed to initialize KVM: No such file or directory</p></blockquote><p>尝试了<code>sudo modprobe kvm-intel</code>指令无果，是不是意味着腾讯云服务器上不能跑kvm unit test？</p><p>A1：是的，腾讯云服务器上不能跑，因为腾讯云服务器本身就是kvm，在kvm上再跑qemu，相当于是嵌套虚拟化，而再在qemu上跑kvm unit test（相当于hypervisor），这就是第三层虚拟化了，一般只能嵌套两层，所以不能在腾讯云服务器上跑。</p><h2 id="vmware配置KVM实验环境"><a href="#vmware配置KVM实验环境" class="headerlink" title="vmware配置KVM实验环境"></a>vmware配置KVM实验环境</h2><p>本来以为虚拟机上不能做kvm unit tests的实验，基本快放弃的时候看到了这篇文章<a href="https://www.jianshu.com/p/d0e4ed80b8a1" target="_blank" rel="noopener">KVM虚拟机安装搭建及基本使用</a>，发现在vmware=&gt;硬件=&gt;处理器=&gt;虚拟化引擎选项中有<strong>虚拟化Intel VT-x/EPT或AMD-V/RVI(V)</strong>选项，但是这时候直接开虚拟机会显示<strong>此平台不支持虚拟化的Intel VT-x/EPT</strong>.</p><p>但是要启动VT-x就需要关闭Hyper-V，Hyper-V反正也用不上，控制面板=&gt;程序=&gt;启动或关闭Windows功能，找到Hyper-V的文件夹，将父项以及子项去掉勾选，接下来重新启动。</p><p>由于我的windows10是从家庭版破解出来的专业版，我还按照参考1照着windows10家庭版的关闭流程走了一遍。</p><ul><li>WIN+R打开运行，输入services.msc回车</li><li>在服务中找到HV主机服务，双击打开设置为停用</li><li>以管理员权限打开Windows PowerShell</li><li>运行命令：<code>bcdedit /etc hypervisorlaunchtype off</code></li></ul><p>重启再关一遍HV主机服务，然后打开vmware成功启动虚拟机。</p><p>在命令行输入命令：<code>grep -E &quot;vmx|svm&quot; /proc/cpuinfo</code>，如果能输出一大堆信息，就表明可以成功在虚拟机中开启了虚拟化VT-x。</p><p>kvm unit test的编译和运行实验参考<a href="http://liujunming.top/2019/11/03/Introduction-to-kvm-unit-test/" target="_blank" rel="noopener">Introduction to kvm-unit-test</a>.在执行到最后一步的时候出现错误：</p><blockquote><p>qemu-system-x86_64: failed to initialize kvm: Permission denied</p></blockquote><p>这时候，尝试<code>sudo chmod 666 /dev/kvm</code>，成功运行。</p><h2 id="Hyper-V和VT-x的关系"><a href="#Hyper-V和VT-x的关系" class="headerlink" title="Hyper-V和VT-x的关系"></a>Hyper-V和VT-x的关系</h2><p>Hyper-V：虚拟机化硬件，能够在Windows上跑不同的系统</p><p>VT-x：硬件支持的虚拟化扩展</p><p>在vmware上开启虚拟化VT-x的时候就要关闭Hyper-V，我猜这俩作用相似，一个的开启可能会占用另一个的部分资源。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.cnblogs.com/jaycethanks/p/14087318.html" target="_blank" rel="noopener">此平台不支持虚拟化的Intel VT-x/EPT</a></li><li><a href="http://liujunming.top/2019/11/03/Introduction-to-kvm-unit-test/" target="_blank" rel="noopener">Introduction to kvm-unit-test</a></li><li><a href="https://github.com/sickcodes/Docker-OSX/issues/55" target="_blank" rel="noopener">qemu-system-x86_64: failed to initialize kvm: Permission denied</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录一下昨天晚上苦逼地搭建KVM unit test环境的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="http://yoursite.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="OS" scheme="http://yoursite.com/tags/OS/"/>
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="KVM" scheme="http://yoursite.com/tags/KVM/"/>
    
  </entry>
  
  <entry>
    <title>new to system call</title>
    <link href="http://yoursite.com/2021/06/11/2021-06-11-new-to-system-call/"/>
    <id>http://yoursite.com/2021/06/11/2021-06-11-new-to-system-call/</id>
    <published>2021-06-11T03:30:53.000Z</published>
    <updated>2021-06-11T12:00:57.425Z</updated>
    
    <content type="html"><![CDATA[<p>从入门到入土的system call</p><a id="more"></a><h2 id="Arguemnt-Passing-in-Linux"><a href="#Arguemnt-Passing-in-Linux" class="headerlink" title="Arguemnt Passing in Linux"></a>Arguemnt Passing in Linux</h2><table><thead><tr><th>Register</th><th>Argument User Space</th><th>Argument Kernel Space</th></tr></thead><tbody><tr><td>%rax</td><td>Not Used</td><td>System Call Number</td></tr><tr><td>%rdi</td><td>Argument1</td><td>Argument</td></tr><tr><td>%rsi</td><td>Argument2</td><td>Argument</td></tr><tr><td>%rdx</td><td>Argument3</td><td>Argument</td></tr><tr><td>%r10</td><td>Not Used</td><td>Argument</td></tr><tr><td>%r8</td><td>Argument5</td><td>Argument</td></tr><tr><td>%r9</td><td>Argument6</td><td>Argument</td></tr><tr><td>%rcx</td><td>Argument4</td><td>Destroyed</td></tr><tr><td>%r11</td><td>Not Used</td><td>Destroyed</td></tr></tbody></table><p>syscall的返回值保存在<code>%rax</code>中，该值的范围在-4095到-1之间时，表示错误值。</p><p>能够传递给kernel的值只有两种类型：</p><ul><li><code>INTEGER</code>: 能够存储在通用寄存器中的整数类型；</li><li>``MEMORY<code>: 能够通过堆栈传递并返回内存的数据，大多为</code>strings<code>或</code>memory buffer<code>。举个例子，</code>write()<code>系统调用，第一个参数</code>fd<code>是</code>INTEGER<code>类型，第二个参数</code>buffer<code>是即将被写入文件的数据，它的类型是</code>MEMORY<code>，第三个参数是count，其类型也是</code>INTEGER`</li></ul><blockquote><p>Class INTEGER This class consists of integral types that fit into one of the general purpose registers.</p><p>Class MEMORY This class consists of types that will be passed and returned in memory via the stack. These will mostly be strings or memory buffer.</p></blockquote><h2 id="simple-example"><a href="#simple-example" class="headerlink" title="simple example"></a>simple example</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">        .global _start</span><br><span class="line">        .text</span><br><span class="line"></span><br><span class="line">_start:</span><br><span class="line">        # write(1, message, 13)</span><br><span class="line">        mov $1, %rax      # system call number of write is 1</span><br><span class="line">        mov $1, %rdi      # first argument: file handle 1 is stdout</span><br><span class="line">        mov $message, %rsi   # second argument: address of string to output</span><br><span class="line">        mov $13, %rdx     # third argument: count(number of bytes)</span><br><span class="line">        syscall  # invoke OS to do the write</span><br><span class="line"></span><br><span class="line">        mov $60, %rax     # system call number of exit is 60</span><br><span class="line">        xor %rdi, %rdi  # return code is 0</span><br><span class="line">        syscall</span><br><span class="line">message:</span><br><span class="line">        .ascii &quot;hello, world\n&quot;</span><br></pre></td></tr></table></figure><p>执行<code>gcc -c hello.s &amp;&amp; ld hello.o &amp;&amp; ./a.out</code>在命令行中得到<code>hello, world</code>的输出。</p><h2 id="question"><a href="#question" class="headerlink" title="question"></a>question</h2><blockquote><p>The system call destroys rcx and r11 but others registers are saved across the system call.</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://github.com/rishiba/doc_syscalls/blob/master/doc/05_calling_system_calls.rst" target="_blank" rel="noopener">calling_system_calls</a></li><li><a href="https://cs.lmu.edu/~ray/notes/syscalls/" target="_blank" rel="noopener">System Calls</a></li><li><a href="http://arthurchiao.art/blog/system-call-definitive-guide-zh/" target="_blank" rel="noopener">Linux系统调用权威指南</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从入门到入土的system call&lt;/p&gt;
    
    </summary>
    
      <category term="OS" scheme="http://yoursite.com/categories/OS/"/>
    
    
      <category term="OS" scheme="http://yoursite.com/tags/OS/"/>
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>vmx.c部分代码解读(一)</title>
    <link href="http://yoursite.com/2021/06/01/2021-06-04-KVM-vmx/"/>
    <id>http://yoursite.com/2021/06/01/2021-06-04-KVM-vmx/</id>
    <published>2021-06-01T13:31:53.000Z</published>
    <updated>2021-06-11T12:02:50.028Z</updated>
    
    <content type="html"><![CDATA[<p>vmx.c中部分代码的理解</p><a id="more"></a><h2 id="根据MSR调整CPU中部分功能的开启"><a href="#根据MSR调整CPU中部分功能的开启" class="headerlink" title="根据MSR调整CPU中部分功能的开启"></a>根据MSR调整CPU中部分功能的开启</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> __<span class="function">init <span class="keyword">int</span> <span class="title">adjust_vmx_controls</span><span class="params">(u32 ctl_min, u32 ctl_opt,</span></span></span><br><span class="line"><span class="function"><span class="params">      u32 msr, u32 *result)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">u32 vmx_msr_low, vmx_msr_high;</span><br><span class="line">u32 ctl = ctl_min | ctl_opt;</span><br><span class="line"></span><br><span class="line">rdmsr(msr, vmx_msr_low, vmx_msr_high);</span><br><span class="line"></span><br><span class="line">ctl &amp;= vmx_msr_high; <span class="comment">/* bit == 0 in high word ==&gt; must be zero */</span></span><br><span class="line">ctl |= vmx_msr_low;  <span class="comment">/* bit == 1 in low word  ==&gt; must be one  */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Ensure minimum (required) set of control bits are supported. */</span></span><br><span class="line"><span class="keyword">if</span> (ctl_min &amp; ~ctl)</span><br><span class="line"><span class="keyword">return</span> -EIO;</span><br><span class="line"></span><br><span class="line">*result = ctl;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该函数用于根据<code>MSR</code>寄存器的实际值，校准控制字符(<strong>c</strong>on<strong>t</strong>ro<strong>l</strong>)，其中特定的若干位设置为1，表明开启CPU的某些功能。</p><ul><li><code>ctl_min</code>: 必须开启的设置（minimal required）</li><li><code>ctl_opt</code>: 可选设置</li><li><code>msr</code>: <code>MSR</code>寄存器的地址，表示读取该<code>MSR</code>的控制字符</li><li><code>result</code>: 输出值的地址，用于保存校准值</li></ul><p><code>u32 ctl = ctl_min | ctl_opt</code>临时变量对<code>ctl_min</code>和<code>ctl_opt</code>取或，保留了两个参数中的所有置一位。</p><p>接着<code>rdmsr</code>读取指定<code>MSR</code>寄存器的控制字符。该字符用64位表示特定设置的要求：低32位保存在<code>vmx_msr_low</code>，保证低32位为0的位必须为0：<code>ctl |= vmx_msr_low</code>；高32位保存在<code>vmx_msr_high</code>， 保证高32位为1的为必须为1：<code>ctl &amp;= vmx_msr_high</code></p><p>最后一个判断语句<code>if (ctl_min &amp; ~ctl)</code>是判断开始设置的必须开启的设置是否还是开启的。如果满足，则写入最终结果。</p><h3 id="APIC控制访问"><a href="#APIC控制访问" class="headerlink" title="APIC控制访问"></a>APIC控制访问</h3><p>其实暂时对APIC不是很理解(</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_X86_64</span></span><br><span class="line"><span class="comment">//如果开启了CPU_BASED_TPR_SHADOW,就可以关闭CPU_BASED_CR8_LOAD_EXITING, CPU_BASED_CR8_STORE_EXITING，因为CR8被映射到TPR（读写TPR就等于读写CR8），这样设置的话，当CPU试图访问CR8就不会引起VM exit</span></span><br><span class="line"><span class="keyword">if</span> ((_cpu_based_exec_control &amp; CPU_BASED_TPR_SHADOW))  <span class="comment">//0x00200000</span></span><br><span class="line">_cpu_based_exec_control &amp;= ~CPU_BASED_CR8_LOAD_EXITING &amp;</span><br><span class="line">   ~CPU_BASED_CR8_STORE_EXITING;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><h2 id="vmx-get-cpu"><a href="#vmx-get-cpu" class="headerlink" title="vmx_get_cpu"></a><code>vmx_get_cpu</code></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//called before using a cpu</span></span><br><span class="line"><span class="comment">//@vcpu: VCPU that will be loaded</span></span><br><span class="line"><span class="comment">//disable preemption. Call vmx_put_cpu() when finished</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">vmx_get_cpu</span><span class="params">(struct vmx_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"> <span class="comment">/*</span></span></span><br><span class="line"><span class="function"><span class="comment">1. 获取当前处理器，禁止内核抢占，`int cur_cpu = get_cpu()`</span></span></span><br><span class="line"><span class="function"><span class="comment">2. 设置当前local_vcpu为vcpu（我的理解：相当于上下文切换到vcpu）</span></span></span><br><span class="line"><span class="function"><span class="comment">3. 如果vcpu的cpu不是cur_cpu，执行下面的操作。否则，则直接执行`vmcs_load`指令。</span></span></span><br><span class="line"><span class="function"><span class="comment">   3.1 如vcpu已有cpu，则运行函数`__vmx_get_cpu_hepler(vcpu)`: 清空vcpu的vmcs，并且将local_vcpu置为NULL；</span></span></span><br><span class="line"><span class="function"><span class="comment">   3.2. vpid_sync_context: 首先明确一点，VPID用于区分TLB中不同进程的TLB。`vpid_sync_context`调用`INVVPID`使旧vcpu中的vpid失效</span></span></span><br><span class="line"><span class="function"><span class="comment">   3.3. ept_sync_context：刷新指定的vcpu的ept，`INVEPT`是使EPT中的TLB项失效，当EPT页表有更新时，CPU执行`INVEPT`使旧TLB失效。</span></span></span><br><span class="line"><span class="function"><span class="comment">4. 设置vcpu-&gt;launched为0</span></span></span><br><span class="line"><span class="function"><span class="comment">5. 执行`vmcs_load`指令</span></span></span><br><span class="line"><span class="function"><span class="comment">6. `__vmx_set_cpu`，获得该CPU的host_gdt (set per-cpu TSS and GDT when switch processors)</span></span></span><br><span class="line"><span class="function"><span class="comment">7. 设置vcpu的值为cur_cpu.</span></span></span><br><span class="line"><span class="function"><span class="comment"></span></span></span><br><span class="line"><span class="function"><span class="comment">在执行完毕该函数之后，要调用`put_cpu()`恢复内核抢占。</span></span></span><br><span class="line"><span class="function"><span class="comment"> */</span></span></span><br></pre></td></tr></table></figure><h2 id="刷新EPT"><a href="#刷新EPT" class="headerlink" title="刷新EPT"></a>刷新EPT</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">vmx_ept_sync_vcpu</span><span class="params">(struct vmx_vcpu *vcpu)</span> </span>&#123;</span><br><span class="line">    smp_call_function_single(vcpu-&gt;cpu, __vmx_sync_helper, (<span class="keyword">void</span> *)vcpu, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//smp_call_function_single该函数表示在cpu核上运行__vmx_sync_helper(void* vcpu)函数</span></span><br><span class="line"><span class="comment">//__vmx_sync_helper调用了ept_sync_context(vcpu-&gt;eptp);</span></span><br><span class="line"><span class="comment">//ept_sync_context()：如果设置了vmx_invept_context, 则只对某个进程的EPT(invalidate all mappings associated with bits 51:12 of the EPT pointer(EPTP)specified in the INVEPT descriptor.)进行无效化更新（__invept)；否则对所有EPT表中的所有项更新.</span></span><br></pre></td></tr></table></figure><h2 id="一些杂七杂八的零碎函数"><a href="#一些杂七杂八的零碎函数" class="headerlink" title="一些杂七杂八的零碎函数"></a>一些杂七杂八的零碎函数</h2><p>//GFP_kernel</p><p>用来标记分配内核空间内存的方式。如果内存不够的时候，会等待内核释放内存，直到可以分配相应大小的内存，GFP_kernel用在可以睡眠的场合</p><p>gfp是get free page</p><p>CPU通过<code>GDTR</code>寄存器知道<code>GDT</code>表的位置，通过<code>IDTR</code>寄存器知道<code>IDT</code>表的位置，通过<code>TR</code>寄存器确定<code>TSS</code>的位置</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://blog.csdn.net/basicthinker/article/details/6603541" target="_blank" rel="noopener">Linux/Xen源代码片段解读</a></li><li><a href="https://blog.csdn.net/q1007729991/article/details/52650822" target="_blank" rel="noopener">任务状态段（TSS）</a></li><li><a href="https://github.com/xzffwy/dune_des" target="_blank" rel="noopener">dune_des</a></li><li><a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce.html" target="_blank" rel="noopener">INVEPT</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;vmx.c中部分代码的理解&lt;/p&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="http://yoursite.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="OS" scheme="http://yoursite.com/tags/OS/"/>
    
      <category term="虚拟化" scheme="http://yoursite.com/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>关于我对可信计算的理解</title>
    <link href="http://yoursite.com/2021/06/01/2021-06-01-trusting%20computing/"/>
    <id>http://yoursite.com/2021/06/01/2021-06-01-trusting computing/</id>
    <published>2021-06-01T13:31:53.000Z</published>
    <updated>2021-06-01T13:42:57.518Z</updated>
    
    <content type="html"><![CDATA[<p>可信计算课程的期末报告</p><a id="more"></a><h2 id="1-可信计算和密码学的关系"><a href="#1-可信计算和密码学的关系" class="headerlink" title="1 可信计算和密码学的关系"></a>1 可信计算和密码学的关系</h2><p>可信计算是安全科学中的一个分支，所以先从我对安全科学的理解来谈。众所周知，密码学是所有安全学科的基础。密码学可以说是安全中最接近于科学的小方向，平时更受工业界追捧的工程安全可能处于安全科学领域鄙视链的最底端。Shamir在2002年图灵奖获奖致辞时就直言非密码学的安全为”a mess”。Schell在2001年描述安全领域为”pseudo-science and flying pigs”(伪科学并且充斥着谎话)[1][3]。</p><p>密码学证明安全的过程，最安全的是形式化证明，形式化证明虽然不能保证100%的安全性，但可以保证相对来说非常高的安全性；其次是规约性证明，用理论来证明密码算法的安全性；最不能保证安全的是用攻击来证明安全性。一个密码学算法的最终应用大多要经过严格的理论证明和形式化证明，最终才能走向应用接受现实的攻击实验。</p><p>但在系统安全领域内，大部分论文的安全性分析都是尝试用攻击来证明安全性，这也是硬件隔离机制和密码学的安全性证明很大的不同。可信并不等于安全，可信技术是通过构造一个信任链来让用户信任安全机制的技术。事实上，工业界中的硬件隔离机制也都是先用攻击来证明安全性，当实践已经能证明具有比较高的安全性后，再去考虑形式化验证，这相对密码学来说是个相反的过程。这样相反的论证过程也在一定程度上验证了当前很多可信机制如同漏水大锅一样层出不穷的漏洞。</p><h2 id="2-从SANCTUARY看TEE技术"><a href="#2-从SANCTUARY看TEE技术" class="headerlink" title="2 从SANCTUARY看TEE技术"></a>2 从SANCTUARY看TEE技术</h2><p>体系结构课程上沈海华老师经常喜欢说的一句话就是：体系结构架构师前三十年铆足劲提升性能，分支预测流水线，无所不用其极，近十年的meltdown, spectre攻击无一不是当初强调性能给自己挖的坑。安全是一个negative的因素，强调安全必然会带来性能的下降，结合应用实现，我们需要不断地做安全和性能之间的tradeoff，TEE(Trusted Execution Environment, 可信执行环境)就是tradeoff的产物。值得注意的是很多TEE，比如ARM TrustZone, Intel SGX, AMD SEV等公开的层出不穷的漏洞缺陷大部分都是利用TEE越权。TEE进程一般拥有比普通应用程序更高的权限，通过利用TEE上的漏洞能够以更高的权限获得系统的机密数据和代码。当TEE概念被提出并实现出来后，很多厂家都知道了TEE这么一个好东西后，都希望把自己的机密数据存入TEE中，这带来的后果就是TA(Ttrusted Application, 可信应用程序)数量的不断增大，直接导致了TCB(Trusted Computing Base, 可信计算基)的不断增大。可信计算基的增大意味着攻击面的增大，假设一个TA存在着缺陷，是否会影响到其他TA？这是需要考虑的不同TA之间的隔离性，遗憾的是，很多生产厂家的TEE中不同TAs之间的隔离是非常弱的。</p><p>在可信计算课程中由我为大家介绍的这篇论文《SANCTUARY: ARMing TrustZone with User-space Enclaves》[5]就是基于上述的TrustZone的设计缺陷构造了一个在性能，安全，开发难度之间进行tradeoff的TEE。</p><p>在进行分析后，作者认为目前各大主流TEE不能满足功能丰富的安全移动服务。针对上面提到的现有TEE的问题，SANCTUARY中通过提出了以下三点进行缓解：</p><ul><li>将安全敏感的应用程序移植到IEE(Isolated Execution Environment, 隔离执行环境)中，从而减少TCB的大小；</li><li>移植到IEE之间的应用程序通过动态划分和重分配资源来达到SA(Sanctuary Application)之间的隔离；</li><li>利用TZASC(TrustZone Address Space Controller，TrustZone地址空间控制器)等硬件来保证系统组件之间的隔离。</li></ul><p>TrustZone具有很高的权限，SANCTUARY相当于构造了一个普通权限的TEE，可以访问安全接口但不能直接运行在高权限上。这当然不是凭空产生的想法，SGX是最负盛名的用户态TEE，SANCTUARY的目标实现的就是在ARM架构上的类SGX的TEE。有趣的是，同年有类似想法的还有Keystone，阅读Keystone论文的话就会发现SANCTUARY和Keystone的架构惊人的相似，但Keystone运行在RISC-V架构上。</p><p>一个完整的SANCTUARY实例包括了处于EL0的Sanctuary App(SA)和处于EL1的Sanctuary Lib(SL), SL主要是为SA初始化运行环境并提供服务接口。SANCTUARY的架构图如下图所示。</p><img src="/2021/06/01/2021-06-01-trusting computing/image-20200610153017985.png" alt="image-20200610153017985" style="zoom:50%;"><p>SANCTUARY从4个方面尝试去达成自己的安全目标。下面的篇幅我将打破文章结构介绍，从这四个方面介绍SANCTUARY为实现自己的安全目标所完成的一系列努力。</p><h3 id="2-1-如何实现严格的隔离？"><a href="#2-1-如何实现严格的隔离？" class="headerlink" title="2.1 如何实现严格的隔离？"></a>2.1 如何实现严格的隔离？</h3><p>TEE是基于硬件机制的隔离，首要任务就是保证严格的独立性。SANCTUARY从两个方面来对独立性进行保证：空间和时间。</p><p>空间独立性上主要是为SANCTUARY静态分配物理资源考虑，每个Sanctuary实例都被分配了一个独立的CPU core，利用TZC-400根据CPU core ID为每个Sanctuary实例分配物理内存。每个CPU core的地址范围的上下界都是通过四个地址范围寄存器来保存记录，而每个CPU core对这些地址范围的访问权限也是通过一个访问许可寄存器记录的。另外，为了抵御缓存侧信道攻击，不允许Sanctuary实例映射到L3缓存中（也就是将Sanctuary实例的物理内存都设置为outer uncacheable）</p><p>时间独立性主要是从SANCTUARY的动态加载来考虑，Sanctuary实例是从可信固件中启动CPU core，并且在退出使用之前将内存中的敏感信息全部清空。</p><h3 id="2-2-如何动态分配内核？"><a href="#2-2-如何动态分配内核？" class="headerlink" title="2.2 如何动态分配内核？"></a>2.2 如何动态分配内核？</h3><p>本部分简单介绍SANCTUARY建立和结束运行的过程。</p><h4 id="2-2-1-Sanctuary建立"><a href="#2-2-1-Sanctuary建立" class="headerlink" title="2.2.1 Sanctuary建立"></a>2.2.1 Sanctuary建立</h4><ul><li>当需要执行SA中的敏感代码时，由LA(Legacy Application，普通世界中的应用程序)触发并加载SL和SA的二进制文件后移交给普通世界中位于EL2的KM(kernel module)；</li><li>KM选择一个CPU core来运行Sanctuary实例并采用热拔插技术来关闭这个被选择的CPU core；</li><li>KM请求STA的服务(Static Trusted App)的服务，从而进入monitor模式，在模式切换的过程中，可信固件检查所选择的CPU core是否被合理地关闭而后将控制权转交给STA，后者对SANCTUARY内存进行配置。</li></ul><h4 id="2-2-2-Sanctuary退出"><a href="#2-2-2-Sanctuary退出" class="headerlink" title="2.2.2 Sanctuary退出"></a>2.2.2 Sanctuary退出</h4><p>当LA对SA发出请求表明自己不需要SANCTUARY的服务时，SA首先清除上下文，通过sealing保存自己的状态并将L1缓存等设备中关于自己的进程信息清除。可信固件在检查SANCTUARY core是否被真正关闭，STA将SANCTUARY内存以及其他相关的数据全部清零，防止信息泄露。最后，恢复之前的配置，释放SANCTUARY内存区域和CPU core。</p><img src="/2021/06/01/2021-06-01-trusting computing/image-20200611152941103.png" alt="image-20200611152941103" style="zoom:50%;"><h3 id="2-3-如何提供和SGX类似的安全服务？"><a href="#2-3-如何提供和SGX类似的安全服务？" class="headerlink" title="2.3 如何提供和SGX类似的安全服务？"></a>2.3 如何提供和SGX类似的安全服务？</h3><p>类似的，SANCTUARY需要提供远程认证和密封服务。为了提供远程认证服务，SA和安全世界之间有共享内存，Sanctuary将自己的完整性测量结果与通向代理TA(trusted application, 可信应用程序)的信道相链接，该共享内存就是一个安全信道。而代理TA负责建立一个SA到远程服务器连接的安全信道，所有通过代理TA传输的数据都用平台密钥认证过，并与SA的身份绑定。</p><p>类似于SGX中的sealing服务，用从SA二进制文件计算得到的散列值排除出的唯一加密密钥对机密信息进行加密后存到普通世界的内存中，利用该技术，能够在安全地永久存储SANCTUARY数据信息。</p><h3 id="2-4-是否能够在现实场景中提供足够的性能？"><a href="#2-4-是否能够在现实场景中提供足够的性能？" class="headerlink" title="2.4 是否能够在现实场景中提供足够的性能？"></a>2.4 是否能够在现实场景中提供足够的性能？</h3><p>论文中作者通过构造了一个OTP双因素认证的例子，通过展现该实验构造Provision Key和产生OTP的时间来证明SANCTUARY使用普通世界和安全世界的组件所需要的时间是不会影响用户体验的。</p><h2 id="3-对SANCTUARY的讨论"><a href="#3-对SANCTUARY的讨论" class="headerlink" title="3 对SANCTUARY的讨论"></a>3 对SANCTUARY的讨论</h2><p>计算机领域中有一句很著名的话：“计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决“。SANCTUARY其实就是用了这个思想，TrustZone中只有安全世界和非安全世界，SANCTUARY就构造了一个中间层——隔离执行环境，既能保证安全敏感的应用程序的安全执行，也能保证安全世界中的TCB尽可能小。</p><p>SANCTUARY巧妙地用了已有的多核机制和内存地址控制器来进行硬件资源的隔离，但却忽略了cache coherence的影响。所谓cache coherence是在保证了不同cache之间如果有共享数据，在这些共享数据被修改时该如何维护其他CPU core读到该数据时的正确性。在CITM[6]这篇论文中构造了一个方法，利用CPU的shareability属性来操纵Sanctuary实例中的机密数据泄露或者被篡改。</p><p>cache coherence一直是体系结构中研究非常多的一个方向，在体系结构中考虑的更多是如何保证数据的正确性，但在安全领域的研究人员，看这个问题却是如何利用该机制获取机密信息，不同领域看相同的问题会有不同的角度，因为有不同的借鉴。对于我们来说，我觉得做科研可以了解不同方向的论文，不必让自己的知识栈局限在某个领域内，换个角度看问题也许就能有很多很新颖的发现。</p><p>在Sok[2]这篇文章中提到了有相当一部分的TEE相关的安全漏洞和滥用安全世界的接口有关。SANCTUARY同样是通过安全世界给普通世界提供的安全接口来提供服务，但论文中并没有提到对这些安全接口的保护。</p><p>最后谈一下与SANCTUARY架构非常接近的Keystone[4]，虽然架构相似，但Keystone的出发点和SANCTUARY并不一样，Keystone着眼于构造一个用于配置、建立以及实例化可定制TEEs的框架，实现上就是通过模块化来定制TEE。在内存隔离上，SANCTUARY是利用TZC-400，而Keystone利用RISC-V机器模式的PMP(physical memory protection)。另外，Keystone着重强调将资源管理和安全检查解耦，最高权限的SM(security monitor)用最少的代码实施安全策略，而在S(Supervisor)-mode的RT(runtime)负责安全区中执行的用户代码的生命周期、内存管理、系统调用、与SM进行通信等操作。我认为Keystone和SANCTUARY虽然出发点不同，但最后实现的架构有很多近似的地方。</p><img src="/2021/06/01/2021-06-01-trusting computing/image-20200914110304034.png" alt="image-20200914110304034" style="zoom:80%;"><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Schell R R. Information security: science, pseudoscience, and flying pigs[C]//Seventeenth Annual Computer Security Applications Conference. IEEE, 2001: 205-216.</p><p>[2] Cerdeira D, Santos N, Fonseca P, et al. Sok: Understanding the prevailing security vulnerabilities in trustzone-assisted tee systems[C]//2020 IEEE Symposium on Security and Privacy (SP). IEEE, 2020: 1416-1432.</p><p>[3] Herley C, Van Oorschot P C. Sok: Science, security and the elusive goal of security as a scientific pursuit[C]//2017 IEEE symposium on security and privacy (SP). IEEE, 2017: 99-120.</p><p>[4] Lee D, Kohlbrenner D, Shinde S, et al. Keystone: An open framework for architecting trusted execution environments[C]//Proceedings of the Fifteenth European Conference on Computer Systems. 2020: 1-16.</p><p>[5] Brasser F, Gens D, Jauernig P, et al. SANCTUARY: ARMing TrustZone with User-space Enclaves[C]//NDSS. 2019.</p><p>[6] Wang J, Sun K, Lei L, et al. Cache-in-the-Middle (CITM) Attacks: Manipulating Sensitive Data in Isolated Execution Environments[C]//Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security. 2020: 1001-1015.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;可信计算课程的期末报告&lt;/p&gt;
    
    </summary>
    
      <category term="可信计算" scheme="http://yoursite.com/categories/%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="TEE" scheme="http://yoursite.com/tags/TEE/"/>
    
      <category term="可信计算" scheme="http://yoursite.com/tags/%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Unikraft-Eurosys21</title>
    <link href="http://yoursite.com/2021/05/28/2021-05-28-Unikraft-Eurosys21/"/>
    <id>http://yoursite.com/2021/05/28/2021-05-28-Unikraft-Eurosys21/</id>
    <published>2021-05-28T08:48:53.000Z</published>
    <updated>2021-05-28T12:53:24.073Z</updated>
    
    <content type="html"><![CDATA[<p>Unikraft: Fast, Specialized Unikernels the Easy Way.</p><a id="more"></a><h1 id="Unikraft"><a href="#Unikraft" class="headerlink" title="Unikraft"></a>Unikraft</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li>fully modularizes OS primitives so that it is easy to customize the unikernel and include only relevant components</li><li>exposes a set of composable, performance-oriented APIs in order to make it easy for developers to obtain high performance</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>relying on two key priciples</strong>:</p><ul><li>The kernel should be fully modular(fully and easily customizable) : Unikraft provides a series of OS primitives</li><li>The kernel should provide performance-minded, well-defined APIs that can be easily selected and composed: in Unikraft, such APIs are micro-libraries themselves</li></ul><p>=&gt; define a small set of APIs for core OS components that makes it easy to replace-out a component when is not needed, and pick-and-choose from multiple implementation of the same component when performance dictate(随插随用)</p><h2 id="2-Design-Principles-and-Solution-Space"><a href="#2-Design-Principles-and-Solution-Space" class="headerlink" title="2 Design Principles and Solution Space"></a>2 Design Principles and Solution Space</h2><p>The goal that author want to achieve is <strong>enabling developers to create a specialized OS for every single application to ensure the best performance possible, while bounding OS-related development effort and enabling easy porting of existing applications</strong>. (为每个app定制OS的同时保证能够轻松移植现有的app，这个想法真的斯巴拉西)</p><p>So, key design decisions:</p><ul><li>Single address space</li><li>Fully modular system</li><li>Single protection level: no user/kernel-space separation</li><li>Static linking: enable compiler features</li><li>POSIX support: to support existing applications</li><li>Platform abstraction</li></ul><p>=&gt;how to implement? </p><ul><li>minimize an existing general-purpose OS</li><li>start from an existing unikernel project</li><li>from scratch</li></ul><p>=&gt;existing work</p><p><strong>taking existing OSes and adds or remove functionality</strong></p><p>Existing monolithic OSes do have APIs for each components, but most components depend on each other, which indicates that removing or replacing any single component in the Linux kernel is very difficult.</p><p>So, try to modular certain parts of a monolithic kernel.</p><img src="/2021/05/28/2021-05-28-Unikraft-Eurosys21/image-20210523213724734.png" alt="image-20210523213724734" style="zoom: 67%;"><p><strong>bypass the OS altogether</strong></p><p>apps must be coded against the new network, such as DPDK, netmap…</p><p><strong>add the required OS functionality from scratch for each target app</strong></p><h2 id="3-Unikraft-Architecture-and-APIs"><a href="#3-Unikraft-Architecture-and-APIs" class="headerlink" title="3 Unikraft Architecture and APIs"></a>3 Unikraft Architecture and APIs</h2><p>Unikraft obtain performance via <strong>careful API design and static linking</strong>.</p><p>To achieve the modularity: Unikraft consists of two main components:</p><ul><li>Micro-libraries: software components which implement one of the core Unikraft APIs; they have minimal dependencies and can be arbitrarily small;</li><li>Build system: provides a Kconfig-based menu for users to select which micro-libraries to use in an application build.</li></ul><p><img src="/2021/05/28/2021-05-28-Unikraft-Eurosys21/image-20210524152648074.png" alt="image-20210524152648074"></p><p>接下来作者介绍了四个Unikraft API: uknetdev(network), ukalloc(allocation), uksched(scheduling) and uklock(lock)</p><h2 id="4-Application-Support-and-Porting"><a href="#4-Application-Support-and-Porting" class="headerlink" title="4 Application Support and Porting"></a>4 Application Support and Porting</h2><p>Unikraft rely on the <strong>target application’s native build system</strong>, and use the <strong>statically-compiled object files to link them into Unikraft’s final linking step</strong>.(将Unikraft的boot过程与特定的application绑定？前面确实提到了希望一个application一个OS，所以这边的Unikraft相当于就是一个微型OS，只为选定的app服务？)=&gt;用了<code>musl</code></p><p>To support musl, which depends on Linux syscalls, Unikraft created a micro-library called syscall shim: each library that implements a system call handler register it, via a macro, with this micro-library. The shim layer then generates a system call interface at libc-level.（这里写一下我的理解：<em>每个库用宏向micro-library注册了system call处理函数，从而在libc-level生成system call接口</em>）</p><h3 id="4-1-Application-Compatibility"><a href="#4-1-Application-Compatibility" class="headerlink" title="4.1 Application Compatibility"></a>4.1 Application Compatibility</h3><p>Unikraft是通过将<code>musl</code>中未实现的syscall自己实现来实现Application compatibility，当然，对于源代码未公开的，考虑的是binary compatibility和binary rewriting。</p><h2 id="6-Specializing-Applications"><a href="#6-Specializing-Applications" class="headerlink" title="6 Specializing Applications"></a>6 Specializing Applications</h2><p>这部分确实也点明了<code>Unikraft</code>的目标是尽可能提供<strong>更好的性能</strong>，鲁棒性，正确性和安全性都是未来工作。</p><h3 id="6-1-Specialized-Boot-Code"><a href="#6-1-Specialized-Boot-Code" class="headerlink" title="6.1 Specialized Boot Code"></a>6.1 Specialized Boot Code</h3><p><code>Unikraft</code>为了提高boot的速度，提供了一种静态分配物理页表的方法：</p><blockquote><p>Unikraft binary contains an already initialized page-table structure which is loaded in memory by the VMM</p></blockquote><p>在boot过程中，Unikraft只需要修改page-table register的地址即可。</p><p>这种静态分配的方法能够满足大部分的Application，<code>Unikraft</code>也提供了动态加载的方法：此时所有的page-table将会在boot的时候填充。</p><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p>Unikraft中表示不需要虚拟地址到物理地址的转换，那么如果用虚拟化技术，VM中的app直接是物理地址，那么gp-&gt;vp-&gt;hp，会不会快一点（虽然原来就有gp-&gt;hp的快表）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Unikraft: Fast, Specialized Unikernels the Easy Way.&lt;/p&gt;
    
    </summary>
    
      <category term="OS" scheme="http://yoursite.com/categories/OS/"/>
    
    
      <category term="OS" scheme="http://yoursite.com/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>eglibc-syscall</title>
    <link href="http://yoursite.com/2021/05/21/2021-05-21-eglibc-syscall/"/>
    <id>http://yoursite.com/2021/05/21/2021-05-21-eglibc-syscall/</id>
    <published>2021-05-21T10:53:22.000Z</published>
    <updated>2021-05-21T11:10:15.786Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章是阅读<code>eglibc-2.14</code>中与<code>syscall</code>相关部分的代码解析，由于本人的GCC汇编很烂，所以解释的比较详细。</p><a id="more"></a><p>先明确<code>mov 源地址，目的地址</code>（永远分不清.jpg</p><h1 id="lowlevellock-h"><a href="#lowlevellock-h" class="headerlink" title="lowlevellock.h"></a><code>lowlevellock.h</code></h1><p><code>Dune</code>项目中的eglibc-2.14.diff是在eglibc-2.14源代码基础上所打的补丁，整个文件就是对6处的<code>syscall</code>将其修改为带条件的<code>vmcall</code>.下面看一下<code>Dune</code>修改的代码。</p><p>对这部分的代码我的理解是：<code>%%cs</code>与<code>$3</code>执行test操作，也就是看<code>%%cs</code>最后两位是否都为0，都为0的话跳转执行<code>vmcall</code>，否则执行<code>syscall</code>。（问题：<em>这边的<code>$3</code>去直接理解成了普通的十进制数，另外我也不是很理解为什么要通过检查<code>%%cs</code>的最后两位来判断是执行<code>syscall</code>还是<code>vmcall</code>?</em>）</p><p>(接下来不再介绍<code>diff</code>文件中的修改，因为都一样啊，不一样的话请告诉我(</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+#define DUNE_SYSCALL \</span><br><span class="line">+        &quot;push %%rax\n\t&quot;                                                      \</span><br><span class="line">+        &quot;mov %%cs, %%rax\n\t&quot;                                                 \</span><br><span class="line">+        &quot;test $3, %%rax\n\t&quot;                                                  \</span><br><span class="line">+        &quot;pop %%rax\n\t&quot;                                                       \</span><br><span class="line">+        &quot;jz 69f\n\t&quot;                                                          \</span><br><span class="line">+        &quot;syscall\n\t&quot;                                                         \</span><br><span class="line">+        &quot;jmp 70f\n\t&quot;                                                         \</span><br><span class="line">+        &quot;69:&quot;                                                                 \</span><br><span class="line">+        &quot;vmcall\n\t&quot;                                                          \</span><br><span class="line">+        &quot;70:&quot;</span><br></pre></td></tr></table></figure><p>接下来看插入修改的位置的代码</p><p>先将<code>%%r10</code>置零，然后把<code>%2</code>（根据<a href="https://www.cnblogs.com/taek/archive/2012/02/05/2338838.html#:~:text=GCC%E5%85%81%E8%AE%B8%E4%BD%A0%E9%80%9A%E8%BF%87C%2FC%2B%2B%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%8C%87%E5%AE%9A%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96%E4%B8%AD%22instruction,list%22%E4%B8%AD%E7%9A%84%E6%8C%87%E4%BB%A4%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%2C%E4%BD%A0%E7%94%9A%E8%87%B3%E5%8F%AF%E4%BB%A5%E4%B8%8D%E5%85%B3%E5%BF%83%E5%88%B0%E5%BA%95%E4%BD%BF%E7%94%A8%E5%93%AA%E4%BA%9B%E5%AF%84%E5%AD%98%E5%99%A8%2C%E5%AE%8C%E5%85%A8%E4%BE%9D%E9%9D%A0GCC%E6%9D%A5%E5%AE%89%E6%8E%92%E5%92%8C%E6%8C%87%E5%AE%9A%3B%E8%BF%99%E4%B8%80%E7%82%B9%E5%8F%AF%E4%BB%A5%E8%AE%A9%E7%A8%8B%E5%BA%8F%E5%91%98%E5%85%8D%E5%8E%BB%E8%80%83%E8%99%91%E6%9C%89%E9%99%90%E7%9A%84%E5%AF%84%E5%AD%98%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E6%8F%90%E9%AB%98%E7%9B%AE%E6%A0%87%E4%BB%A3%E7%A0%81%E7%9A%84%E6%95%88%E7%8E%87%3B%201.%E5%B8%A6%E6%9C%89C%2FC%2B%2B%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%A0%BC%E5%BC%8F%3A" target="_blank" rel="noopener">这篇文章</a>中的描述，<code>%2</code>其实就是<code>”i&quot; (SYS_futex)</code>，也就是这边的 立即数<code>202</code>)中的值赋值给<code>%%rax</code>，然后调用<code>syscall</code>，执行完毕后比较<code>%%rdi</code>的值是否为<code>$0</code>，不等的话回头重复执行<code>movq</code>以及接下来的操作。</p><p>Q1: <code>register __typeof (tid) _tid asm (&quot;edx&quot;) = (tid);</code>所以这句话是什么意思？</p><p>A1：经过和Aryb1n的讨论（其实是学长单方面教我(，猜测这句话想表达的意思就是用<code>edx</code>寄存器存<code>tid</code></p><p>Q2: <code>lll_wait_tid</code>这个表达式为了完成什么工作？</p><p>A2: 当<code>tid</code>不为0的时候，进行系统调用，唤醒编号为<code>tid</code>的线程（调用的编号为202，202调用的是<code>sys_futex</code>，参考自<a href="https://blog.csdn.net/sinat_26227857/article/details/44244433" target="_blank" rel="noopener">linux系统调用表(system call table)</a>）（嗯，我瞎猜的）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//eglibc-2.14.orig/libc/nptl/sysdeps/unix/sysv/linux/x86_64/lowlevellock.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> lll_wait_tid(tid) \</span></span><br><span class="line">  <span class="keyword">do</span> &#123;      \</span><br><span class="line">    <span class="keyword">int</span> __ignore;      \</span><br><span class="line">    <span class="keyword">register</span> __typeof (tid) _<span class="function">tid <span class="title">asm</span> <span class="params">(<span class="string">"edx"</span>)</span> </span>= (tid);      \</span><br><span class="line">    <span class="keyword">if</span> (_tid != <span class="number">0</span>)      \</span><br><span class="line">      __asm __volatile (<span class="string">"xorq %%r10, %%r10\n\t"</span>      \</span><br><span class="line">            <span class="string">"1:\tmovq %2, %%rax\n\t"</span>      \</span><br><span class="line"><span class="string">"syscall\n\t"</span>      \</span><br><span class="line"><span class="string">"cmpl $0, (%%rdi)\n\t"</span>      \</span><br><span class="line"><span class="string">"jne 1b"</span>      \</span><br><span class="line">: <span class="string">"=&amp;a"</span> (__ignore)      \</span><br><span class="line">: <span class="string">"S"</span> (FUTEX_WAIT), <span class="string">"i"</span> (SYS_futex), <span class="string">"D"</span> (&amp;tid),      \</span><br><span class="line">  <span class="string">"d"</span> (_tid)      \</span><br><span class="line">: <span class="string">"memory"</span>, <span class="string">"cc"</span>, <span class="string">"r10"</span>, <span class="string">"r11"</span>, <span class="string">"cx"</span>);      \</span><br><span class="line">  &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="clone-S"><a href="#clone-S" class="headerlink" title="clone.S"></a><code>clone.S</code></h2><p>前面四行的<code>movq</code>操作都是传递相应的参数到指定的寄存器中，需要注意的是user mode下的寄存器中的参数和kernel mode中期望的不一样，所以需要传递不同的参数</p><p><code>movl $SYS_ify(clone),%eax</code>的意思是将<code>clone</code>替换成系统调用，存入<code>eax</code>寄存器中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/* eglibc-2.14/libc/sysdeps/unix/sysv/linux/x86_64/clone.S */</span><br><span class="line">/* Do the system call.  */</span><br><span class="line">movq%rdx, %rdi</span><br><span class="line">movq%r8, %rdx</span><br><span class="line">movq%r9, %r8</span><br><span class="line">movq8(%rsp), %r10</span><br><span class="line">movl$SYS_ify(clone),%eax</span><br><span class="line"></span><br><span class="line">/* End FDE now, because in the child the unwind info will be</span><br><span class="line">   wrong.  */</span><br><span class="line">cfi_endproc;</span><br><span class="line">syscall</span><br></pre></td></tr></table></figure><p>来看<code>clone.S</code>中的第二个打补丁的地方的原函数</p><p>这个函数表达的意思: 判断<code>%rdi</code>中存放的是<code>flags</code>，<code>testq</code>依次判断标记位，判断是否设置了<code>CLONE_THREAD</code>，当没有设置就意味着将子进程设置为新的线程组，继续判断是否设置<code>CLONE_VM</code>，没有设置就意味着父子进程不会共享同一个虚拟内存页，然后执行<code>syscall</code>，获得子进程的<code>pid</code>.（RESET_PID看名字就知道为子进程获得一个PID，如果父子进程共用一个PID的话，虚拟内存等资源应该还是共享的。另外，看程序，testq执行<code>CLONE_THREAD</code>和<code>%rdi</code>的与操作，如果设置了<code>CLONE_THREAD</code>位的话，也就是<code>ZF=0</code>（zero标志位不等于0，跳到程序端末尾）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#ifdef RESET_PID</span><br><span class="line">testq$CLONE_THREAD, %rdi</span><br><span class="line">jne1f</span><br><span class="line">testq$CLONE_VM, %rdi</span><br><span class="line">movl$-1, %eax</span><br><span class="line">jne2f</span><br><span class="line">movl$SYS_ify(getpid), %eax</span><br><span class="line">syscall</span><br><span class="line">2:movl%eax, %fs:PID</span><br><span class="line">movl%eax, %fs:TID</span><br><span class="line">1:</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure><h1 id="信号量堵塞处理"><a href="#信号量堵塞处理" class="headerlink" title="信号量堵塞处理"></a>信号量堵塞处理</h1><h2 id="getcontent-S"><a href="#getcontent-S" class="headerlink" title="getcontent.S"></a><code>getcontent.S</code></h2><p>原函数表达的含义: <code>sigprocmask</code>函数用于设定屏蔽信号集中的信号的处理方式（对于某个信号并不希望立即执行该信号，同时也不希望忽略该信号，而是延迟一段时间执行该信号，这就是通过堵塞信号来完成的）</p><p>注:系统调用传递次序为</p><table><thead><tr><th>arch</th><th>arg1</th><th>arg2</th><th>arg3</th><th>arg4</th><th>arg5</th><th>arg6</th></tr></thead><tbody><tr><td>x86_64</td><td>rdi</td><td>rsi</td><td>rdx</td><td>r10</td><td>r8</td><td>r9</td></tr></tbody></table><ul><li><code>SIG_BLOCK</code>：将<code>set</code>所指向的信号集中包含的信号加到当前的信号掩码中（执行<strong>与</strong>操作）（存在<code>%rdi</code>中</li><li><code>set</code>：指向信号集的指针，下面的程序中将其设置为NULL，表示仅想读取现在的屏蔽值</li><li><code>oldset</code>：指向信号集的指针，存放原来的信号集，用来检测信号掩码中存在什么信号（<code>%rdx</code>）</li><li><code>_NSIG/8</code>：信号集的大小（<code>%r10d</code>）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/* eglibc-2.14/libc/sysdeps/unix/sysv/linux/x86_64/getcontent.S */</span><br><span class="line">   /* Save the current signal mask with</span><br><span class="line">   rt_sigprocmask (SIG_BLOCK, NULL, set,_NSIG/8).  */</span><br><span class="line">leaqoSIGMASK(%rdi), %rdx</span><br><span class="line">xorl%esi,%esi</span><br><span class="line">#if SIG_BLOCK == 0</span><br><span class="line">xorl%edi, %edi</span><br><span class="line">#else</span><br><span class="line">movl$SIG_BLOCK, %edi</span><br><span class="line">#endif</span><br><span class="line">movl$_NSIG8,%r10d</span><br><span class="line">movl$__NR_rt_sigprocmask, %eax</span><br><span class="line">syscall</span><br><span class="line">cmpq$-4095, %rax/* Check %rax for error.  */</span><br><span class="line">jaeSYSCALL_ERROR_LABEL/* Jump to error handler if error.  */</span><br></pre></td></tr></table></figure><h2 id="setcontent-S"><a href="#setcontent-S" class="headerlink" title="setcontent.S"></a><code>setcontent.S</code></h2><p>跟上面的<code>getcontent.S</code>中的<code>ENTRY</code>函数类似，同样调用了<code>rt_sigprocmask</code>函数，但第一个参数为<code>SIG_SETMASK</code>，表示将<code>set</code>值(<code>leaq OSIGMASK(%rdi), %rsi</code>) 设定为新的进程信号掩码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ENTRY(__setcontext)</span><br><span class="line">/* Save argument since syscall will destroy it.  */</span><br><span class="line">pushq%rdi</span><br><span class="line">cfi_adjust_cfa_offset(8)</span><br><span class="line"></span><br><span class="line">/* Set the signal mask with</span><br><span class="line">   rt_sigprocmask (SIG_SETMASK, mask, NULL, _NSIG/8).  */</span><br><span class="line">leaqoSIGMASK(%rdi), %rsi</span><br><span class="line">xorl%edx, %edx</span><br><span class="line">movl$SIG_SETMASK, %edi</span><br><span class="line">movl$_NSIG8,%r10d</span><br><span class="line">movl$__NR_rt_sigprocmask, %eax</span><br><span class="line">syscall</span><br><span class="line">popq%rdi/* Reload %rdi, adjust stack.  */</span><br><span class="line">cfi_adjust_cfa_offset(-8)</span><br><span class="line">cmpq$-4095, %rax/* Check %rax for error.  */</span><br><span class="line">jaeSYSCALL_ERROR_LABEL/* Jump to error handler if error.  */</span><br></pre></td></tr></table></figure><p>补丁文件也是修改<code>syscall</code></p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- eglibc-2.14.orig/libc/sysdeps/unix/sysv/linux/x86_64/setcontext.S2012-06-29 15:42:39.000000000 -0700</span></span><br><span class="line"><span class="comment">+++ eglibc-2.14/libc/sysdeps/unix/sysv/linux/x86_64/setcontext.S2012-06-18 14:49:49.000000000 -0700</span></span><br><span class="line">@@ -44,7 +44,16 @@ ENTRY(__setcontext)</span><br><span class="line"> movl$SIG_SETMASK, %edi</span><br><span class="line"> movl$_NSIG8,%r10d</span><br><span class="line"> movl$__NR_rt_sigprocmask, %eax</span><br><span class="line"><span class="deletion">-syscall</span></span><br><span class="line"><span class="addition">+push %rax</span></span><br><span class="line"><span class="addition">+mov %cs, %rax</span></span><br><span class="line"><span class="addition">+test $3, %rax</span></span><br><span class="line"><span class="addition">+pop %rax</span></span><br><span class="line"><span class="addition">+jnz 1f</span></span><br><span class="line"><span class="addition">+vmcall</span></span><br><span class="line"><span class="addition">+jmp 2f</span></span><br><span class="line"><span class="addition">+1:</span></span><br><span class="line"><span class="addition">+ syscall</span></span><br><span class="line"><span class="addition">+2:</span></span><br><span class="line"> popq%rdi/* Reload %rdi, adjust stack.  */</span><br><span class="line"> cfi_adjust_cfa_offset(-8)</span><br><span class="line"> cmpq$-4095, %rax/* Check %rax for error.  */</span><br></pre></td></tr></table></figure><p><code>eglibc-2.14/libc/sysdeps/unix/sysv/linux/x86_64/swapcontext.S</code>主要完成的工作参考函数<code>rt_sigprocmask (SIG_BLOCK, newset, oldset, _NSIG/8)</code>，就是用<code>newset</code>替换原来的<code>oldset</code>，补丁也是直接替换的<code>syscall</code>.</p><h1 id="DO-CALL"><a href="#DO-CALL" class="headerlink" title="DO_CALL"></a><code>DO_CALL</code></h1><p><code>eglibc-2.14/libc/sysdeps/unix/sysv/linux/x86_64/sysdep.h</code>文件</p><p>所有的系统调用都会通过<code>DO_CALL</code>发起</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">undef</span>DO_CALL</span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">define</span> DO_CALL(syscall_name, args)\</span></span><br><span class="line">    DOARGS_#<span class="meta">#args\</span></span><br><span class="line">    movl $SYS_ify (syscall_name), %eax;\</span><br><span class="line">    syscall;</span><br></pre></td></tr></table></figure><p>再往下，<code>INTERNAL_SYSCALL_NCS</code>也调用了<code>syscall</code></p><p><code>LOAD_ARGS_##nr</code>负责把参数<code>args</code>展开，<code>LOAD_REGS_##nr</code>则把对应的参数设置到对应的寄存器中，然后调用<code>syscall</code>。（Q：这个<code>INTERNAL_SYSCALL_NCS</code>和上面的<code>DO_CALL</code>区别在哪里？</p><figure class="highlight hpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">define</span> INTERNAL_SYSCALL_NCS(name, err, nr, args...) \</span></span><br><span class="line">  (&#123;      \</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">int</span> resultvar;      \</span><br><span class="line">    LOAD_ARGS_##nr (args)      \</span><br><span class="line">    LOAD_REGS_##nr      \</span><br><span class="line">    <span class="keyword">asm</span> <span class="keyword">volatile</span> (      \</span><br><span class="line">    <span class="string">"syscall\n\t"</span>      \</span><br><span class="line">    : <span class="string">"=a"</span> (resultvar)      \</span><br><span class="line">    : <span class="string">"0"</span> (name) ASM_ARGS_##nr : <span class="string">"memory"</span>, <span class="string">"cc"</span>, <span class="string">"r11"</span>, <span class="string">"cx"</span>);      \</span><br><span class="line">    (<span class="keyword">long</span> <span class="keyword">int</span>) resultvar; &#125;)</span><br><span class="line"><span class="meta"># <span class="meta-keyword">undef</span> INTERNAL_SYSCALL</span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">define</span> INTERNAL_SYSCALL(name, err, nr, args...) \</span></span><br><span class="line">  INTERNAL_SYSCALL_NCS (__NR_##name, err, nr, ##args)</span><br></pre></td></tr></table></figure><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://blog.csdn.net/weixin_42250655/article/details/102533048" target="_blank" rel="noopener">clone()函数及其与Linux线程实现的关系</a></li><li><a href="https://man7.org/linux/man-pages/man2/rt_sigprocmask.2.html" target="_blank" rel="noopener">rt_sigprocmask</a></li><li><a href="https://cloud.tencent.com/developer/article/1492374" target="_blank" rel="noopener">syscall分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章是阅读&lt;code&gt;eglibc-2.14&lt;/code&gt;中与&lt;code&gt;syscall&lt;/code&gt;相关部分的代码解析，由于本人的GCC汇编很烂，所以解释的比较详细。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>五月的生活</title>
    <link href="http://yoursite.com/2021/05/09/2021-05-09-%E4%BA%94%E6%9C%88%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    <id>http://yoursite.com/2021/05/09/2021-05-09-五月的生活/</id>
    <published>2021-05-09T10:35:48.000Z</published>
    <updated>2021-05-28T08:53:39.534Z</updated>
    
    <content type="html"><![CDATA[<p>胡言乱语</p><a id="more"></a><p>想迁移到Jekyll+github，结果在上传我自己的blog的时候一直上传不上去，我要不就凑合着这个hexo+github好了</p><p>新加的两篇blog图片都显示不出来：我累了，今天先不解决了。</p><p>更新：解决了，出现的问题在于我的乱改名，很多解决方案中说的一定要放图片的文件夹和blog文章的title一致是有原因的，可以通过查看blog源代码发现hexo在解析图片的时候会将图片的链接变成blog名/img名，所以存放的文件夹名和blog名不一致就会解析不成功图片，进而无法显示图片。（虽然花了一点时间，但解决问题的感觉还挺好的hhh）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy</span><br><span class="line">git config --global --unset http.proxy</span><br></pre></td></tr></table></figure><p>接下来就是重复劳动了，今天就先不改了，下次再改~</p><p>一直没更新的原因一方面是我没学到啥，另外一方面是常年挂梯子导致<code>hexo d</code>的时候报错</p><blockquote><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="type">Error</span>: <span class="type">Spawn</span> failed</span><br><span class="line">&gt;     at <span class="type">ChildProcess</span>.&lt;anonymous&gt; (<span class="type">D</span>:\git\blog\node_modules\hexo-util\lib\spawn.js:<span class="number">52</span>:<span class="number">19</span>)</span><br><span class="line">&gt;     at <span class="type">ChildProcess</span>.emit (events.js:<span class="number">203</span>:<span class="number">13</span>)</span><br><span class="line">&gt;     at <span class="type">ChildProcess</span>.cp.emit (<span class="type">D</span>:\git\blog\node_modules\cross-spawn\lib\enoent.js:<span class="number">40</span>:<span class="number">29</span>)</span><br><span class="line">&gt;     at <span class="type">Process</span>.<span class="type">ChildProcess</span>._handle.onexit (<span class="keyword">internal</span>/child_process.js:<span class="number">272</span>:<span class="number">12</span>)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>通过参考<a href="https://www.jianshu.com/p/f7feda035dc9" target="_blank" rel="noopener">这篇</a>，终于修好了。</p><p>回去看体系结构了！（考完并且写完了报告√）</p><p>我的blog排序很混乱，本地存储的时候考虑加上时间（改好了√）。</p><p>blog争取周更（做梦（感谢周报，连续周更了两周，好耶！）</p><p>要改一下yillia默认的英文字体和中文字体</p><p>这周末看完体系结构安全的论文</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;胡言乱语&lt;/p&gt;
    
    </summary>
    
      <category term="日记" scheme="http://yoursite.com/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="生活" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="日记" scheme="http://yoursite.com/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>HypSec-Usenix19</title>
    <link href="http://yoursite.com/2021/04/22/2021-05-09-HypSec-Usenix19/"/>
    <id>http://yoursite.com/2021/04/22/2021-05-09-HypSec-Usenix19/</id>
    <published>2021-04-22T02:27:15.000Z</published>
    <updated>2021-05-28T13:20:17.557Z</updated>
    
    <content type="html"><![CDATA[<p>Protecting Cloud Virtual Machines from Hypervisor and Host Operating System Exploits</p><a id="more"></a><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul><li>an untrusted host: perform most complex hypervisor functionality without access to virtual machine data</li><li>a trusted  core: provide access control to virtual machine data and perform basic CPU and memory virtualization   </li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>目前，应用程序和硬件虚拟化的几个设计提供了很好的机会来解决安全问题:  </p><ul><li>modern hardware includes virtualization support to protect and run the hypervisor at a higher privilege level than VMs</li><li>applications are increasingly designed to use end-to-end encryption for I/O channels （应用程序可以提供更好的I/O通信加密，所以可以减少hypervisor的工作）</li></ul><p>本文的思路:分成两部分</p><p><strong>corevisor</strong> (a small trusted core):</p><ul><li>has full access to hardware resources(VM data)</li><li>provides basic CPU and memory virtualization</li><li>mediates all exceptions and interrupts</li><li>ensures that only a VM and the corevisor can access the VM’s data in CPU and memory</li></ul><p><strong>hostvisor</strong> (a large untrusted hos):</p><ul><li>I/O and interrupt virtualization</li><li>resource management such as CPU scheduling, memory management, and device management </li><li>can leverage a host OS</li><li>may import or export encrypted VM data from the system to boot VM images or support hypervisor features such as snapshots and migration, but otherwise has no access to VM data</li></ul><h2 id="3-Design"><a href="#3-Design" class="headerlink" title="3 Design"></a>3 Design</h2><h3 id="3-1-Boot-and-Initialization"><a href="#3-1-Boot-and-Initialization" class="headerlink" title="3.1 Boot and Initialization"></a>3.1 Boot and Initialization</h3><p><strong>Corevisor boot</strong></p><p>HypSec relies on the hostvisor bootstrapping code to install the corevisor securely at boot time since the hostvisor is initially benign.</p><p>在安装完毕后，corevisor获得硬件的所有控制权，并且deprivileges the hostvisors</p><p><img src="/2021/04/22/2021-05-09-HypSec-Usenix19/image-20210409113004021.png" alt="image-20210409113004021"></p><p>当新的VM创建的时候：</p><ul><li>hostvisor calls VM CREATE to request the corevisor to allocate VM state in corevisor memory, including an NPT and VCPU state, a per virtual CPU(VCPU) data structure.</li><li>hostvisor calls VM BOOT to request the corevisor to authenticate the loaded VM image.</li><li>if loaded successfully, the hostvisor can then call VM ENTER to execute the VM</li></ul><p>hostvisor存储VM images并且将他们加载到内存中，而corevisor负责的是验证VM images的公钥签名。</p><h3 id="3-2-CPU"><a href="#3-2-CPU" class="headerlink" title="3.2 CPU"></a>3.2 CPU</h3><p>Hypervisors通过执行以下四个主要功能来提供CPU虚拟化：</p><ul><li>handling traps from the VM</li><li>emulating privileged CPU instructions executed by the guest OS to ensure the hypervisor retains control of CPU hardware</li><li>save and restore VM CPU state, including GPRs and system registers such as page table base registers, as needed when switching among VMs and between a VM and the hypervisor</li><li>scheduling VCPUs on physical CPUs</li></ul><p>为了让TCB尽可能的小，限制访问corevisor的VM CPU，corevisor需要干的活：handle all traps from the VM, instruction emulation, and world switches between VMs and the hostvisor；而VCPU调度可以由hostvisor来完成。</p><p>corevisor maintains VCPU execution context in the VCPU state in-memory data structure（该data structure是由VM CREATE分配的）</p><p>corevisor maintains the hostvisor’s CPU context in a similar Host state data structure.</p><p>所有的保存和恢复VM CPU state都是由corevisor来完成的，有且仅有corevisor能够运行VM。</p><p>当VM执行的指令需要hostvisor的sharing values时，这些值可以放在GPR(genral purpose registers)。由corevisor基于正在执行的CPU指令决定是否以及什么时候从GPRs中复制值，以及复制什么值。</p><h3 id="3-3-Memory"><a href="#3-3-Memory" class="headerlink" title="3.3 Memory"></a>3.3 Memory</h3><p>Hypervisor通过执行以下三个功能来提供memory virtualization：</p><ul><li>memory protection to ensure VMs cannot access unauthorized physical memory</li><li>memory allocation to provide physical memory to VMs</li><li>memory reclamation to reclaim physical memory from VMs</li></ul><p>guest OS 通过page tables将gVA映射到gPA，然后由hypervisor管理NPT将gPAs(guest physical memory address)映射到hPA(host physical memory address)</p><p>HypSec保护VM内存免受hostvisor的破坏，而将TCB大小控制的很小，尽可能地分隔corevisor的大小</p><ul><li>corevisor负责内存保护，包括configure NPT hardware</li><li>hostvisor负责memory allocation and reclamation</li></ul><p><strong>Memory protection</strong></p><p>corevisor通过hNPT(host Nested Page Table)将vhPA转化成hPA，每个vhPA都被映射到一个确定的hPA。hostvisor负责的是hVAs到vhPAs的转换（也就是虚拟机中的虚拟地址到物理地址的转换），hostvisor是没有权限来访问NPT，一旦尝试非法映射，corevisor就会中断映射。hostvisor中的地址转换是动态的，而hostvisor和corevisor之间的地址分配是静态的。 </p><p><img src="/2021/04/22/2021-05-09-HypSec-Usenix19/image-20210410103736933.png" alt="image-20210410103736933"></p><p><strong>Memory allocation</strong></p><ul><li>step1: 当guest OS尝试将gVA映射到一个unmapped gPA，就会发生一个nested page fault，陷入到corevisor中；</li><li>step2: faulted gPA如果是一个合法的VM内存地址，将NPT Base Register指向HNPT</li><li>step3: 切换到hostvisor，为gPA分配physical page</li><li>step4: 切换到corevisor，验证分配的vhPA没有被分配给其他的VM（通过VMID），并经更新更新到sNPT</li><li>corevisor更新NPT Base Register指向sNPT</li><li>corevisor返回VM</li></ul><p>（文章中提到<em>The corevisor does not shadow guest OS updates in its page table; it only shadows hostvisor updates to the vNPT.</em>这部分是指shadow的内容比较少？shadow page table的作用其实就是记录GVA-&gt;HPA的映射关系)</p><p><strong>Memory Reclamation</strong></p><p>corevisor负责将回收到的内存清楚然后分配给需要的VM。</p><p><strong>Advanced VM Memory Management</strong></p><p>当VM希望和hostvisor分享内存时，可以调用GRANT_MEM和REVOKE_MEM并传递相关的参数，corevisor会通过控制hNPT中的memory region’s mapping来实施访问控制策略。</p><p>merging similar memory pages (KSM)</p><h3 id="3-4-Interrupts"><a href="#3-4-Interrupts" class="headerlink" title="3.4 Interrupts"></a>3.4 Interrupts</h3><p>corevisor configures the hardware to route all physical interrupts and trap all accesses to the interrupt controller to the corevisor.</p><p>hostvisor处理大部分的中断功能：handle physical interrupts and provide the virtual interrupt controller interface（在hostvisor处理中断后，corevisor保护所有的VM CPU以及内存状态）</p><p>在一次MMIO write中</p><ul><li>VM passes the value to be stored in a GPR</li><li>the write traps to the corevisor, which identifies the instruction and memory address</li><li>corevisor copies the value to be written from the GPR to the intermediate VM state to make the value valuable to the hostvisor</li></ul><h3 id="3-5-Input-Output"><a href="#3-5-Input-Output" class="headerlink" title="3.5 Input/Output"></a>3.5 Input/Output</h3><p>modern hypervisors通常依赖于OS kernel以及对应的设备驱动来支持I/O virtualization，这增加了hypervisor的TCB。</p><p>HypSec中介绍了一种end-to-end I/O安全方法，依靠VMs来进行I/O保护（TLS/SSL来保护网络通信，全磁盘加密用于存储）。</p><p>passthrough I/O：corevisor控制IOMMU进行inter-device isolation，并保证passthrough device无法访问到VM自己的I/O buffer.</p><h2 id="4-Implementation"><a href="#4-Implementation" class="headerlink" title="4. Implementation"></a>4. Implementation</h2><p>secure DMA: corevisor uses trap-and-emulate on hostvisor accesses to the SMMU</p><p>virtualize interrupts: 利用hardware features from the VGIC and KVM/ARM’s existing support (support emulated device via MMIO, paravirtualized device via virtio, and passthrough devices)</p><p>secure boot：ARM TrustZone-based framework such as OP-TEE</p><p>Ed25519来验证boot images</p><p>AES：support encrypted VM migration and snapshort </p><p><img src="/2021/04/22/2021-05-09-HypSec-Usenix19/image-20210412165136608.png" alt="image-20210412165136608"></p><p>关于Dune论文</p><p>用硬件特性<code>VT-x</code>来实现普通进程。<code>VT-x</code>是X86下的虚拟扩展，管理的进程有自己的<code>CR3</code>寄存器(guest root mode)，让不可信的进程通过<code>VT-x</code>扩展跑在guest root mode，该进程也无法从分配的内存中逃逸。</p><p>SGX中存在的问题，在于使用的page table是和非enclave共用的，如果SGX跑在<code>VT-x</code>模式下，是guest non-root下的page table是不是能减少一些侧信道攻击的问题？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Protecting Cloud Virtual Machines from Hypervisor and Host Operating System Exploits&lt;/p&gt;
    
    </summary>
    
      <category term="OS" scheme="http://yoursite.com/categories/OS/"/>
    
    
      <category term="OS" scheme="http://yoursite.com/tags/OS/"/>
    
      <category term="virtualization" scheme="http://yoursite.com/tags/virtualization/"/>
    
  </entry>
  
  <entry>
    <title>Browser-NDSS17</title>
    <link href="http://yoursite.com/2021/03/30/2021-05-09-Browser-NDSS17/"/>
    <id>http://yoursite.com/2021/03/30/2021-05-09-Browser-NDSS17/</id>
    <published>2021-03-30T07:03:10.000Z</published>
    <updated>2021-05-21T12:07:23.550Z</updated>
    
    <content type="html"><![CDATA[<p>(Cross-) Browser Fingerprinting via OS and Hardware Level Features</p><p>春季学期web追踪前沿分享的论文，由于本人的web知识浅薄，整理的笔记难免有偏颇的地方。</p><p>基于操作系统和硬件特征来进行单浏览器和跨浏览器指纹追踪。</p><a id="more"></a><p>首先从摘要部分，我们从整体层面看一下这篇论文所完成的工作。</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>提出了一种browser fingerprinting technique——不仅能够在单个浏览器中追踪用户信息，并且能够在同一个机器上的不同浏览器中。</p><p>本文利用了多个novel OS 和硬件级别的特征（比如graphics cards, CPU, installed writing scripts) 。作者通过让浏览器执行依赖于这些OS和硬件级别的功能来提取出对应的特征。</p><p>评估结果表明本文方法能够成功鉴别99.24%的用户，而现有的single-browser fingerprinting技术在相同的数据集上只有90.84%成功率。</p><p>并且，与文献中有相似稳定性的cross-browser approach相比，本文的方法能够获得更高的uniqueness（更高的唯一性）</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>web tracking：用于记录past website visitors。</p><p>一方面，该技术能够认证用户（多种不同的技术结合能够用于multi-factor authentication来增强安全性）；另一方面，该技术能够用于实现personalized service（如果该服务是targeted ads，那么这种web tracking技术就是一种侵犯隐私的行为）</p><p>不管我们是否喜欢web tracking或者该技术是否被合法地使用，Alex Top 500 websites中的多余90%的网站采用该技术。</p><p>（第一段，简单地介绍了该技术）</p><p><strong>“浏览器指纹”是一种通过浏览器对网站可见的配置和设置信息来跟踪Web浏览器的方法</strong>，浏览器指纹就像我们人手上的指纹一样，具有个体辨识度，只不过现阶段浏览器指纹辨别的是浏览器。</p><p>人手上的指纹之所以具有唯一性，是因为每个指纹具有独特的纹路、这个纹路由凹凸的皮肤所形成。每个人指纹纹路的差异造就了其独一无二的特征。</p><p>那么浏览器指纹也是同理，获取浏览器具有辨识度的信息，进行一些计算得出一个值，那么这个值就是浏览器指纹。辨识度的信息可以是UA、时区、地理位置或者是你使用的语言等等，你所选取的信息决定了浏览器指纹的准确性。</p><p><strong>web tracking的发展</strong></p><p>first-generation: 采用stateful, server-set identifiers，比如cookies和evercookies（需要用户登陆才可以得到有效的信息）</p><p>second-generation：利用stateless identifiers，比如plug-in versions和已经存在了browsers中的user agent。（有了浏览器指纹的概念，通过不断增加浏览器的特征值从而让用户更具有区分度，例如（UA、浏览器插件信息）</p><p>前两代tracking技术都被限制在a single browser中，本篇论文提出来的2.5-generation technique能在同一台机器上的相同乃至不同浏览器中追踪用户。经过调查，70%的被调查用户都有在一台电脑上安装和频繁使用至少两个浏览器的习惯。</p><p>本文所提出的2.5-generation technique</p><ul><li>被用作part of stronger multi-factor user authentications even across browsers(更有力的（跨浏览器）多因素用户认证的一部分);</li><li>improve existing privacy-preserving works（保护隐私）</li></ul><p><strong>技术方法</strong></p><p>如果想要在相同的机器上fingerprint不同 的浏览器——利用existing features。但是很多existing features都是browser specific（特定于浏览器的），cross-browser能够让特征稳定但是得到的fingerprint不够unique。</p><p>这也是唯一一篇cross-browser的工作采用了IP地址作为main feature，但是采用IP地址只是一个network-level feature（已经被排除在了现在流行的browser printing中），如果IP地址是被动态分配的，那么还会经常变，也无法获得位于匿名网络或者代理之后的数据。</p><p><strong>本文方法</strong></p><p>本文提出的方法基于很多novel OS以及硬件级别的特征（from graphics card, CPU, audio stack以及installed writing scripts）。具体来说，当请求浏览器通过浏览器APIs执行特定任务时，这些OS和硬件级别的功能都会被这些APIs公开给JavaScript，我们就可以提取这些特征（这些特征能够被用于single/cross-browser fingerprinting）。</p><p>WebGL：在browser canvas object中实现的3D部分。虽然该特征一致被认为“too brittle and unreliable”（因为AmIUnique选择了一个任意的WebGL task，并没有约束变量），但本文展示了WebGL不仅能用于single也可以用于cross-browser fingerprinting。具体来说，让browser用精心挑选的computer graphics parameters渲染了20多个任务，比如纹理，反锯齿，光线，透明度，然后从这些渲染任务的输出中提取出特征。</p><p><strong>本文贡献</strong></p><ul><li>第一个在single-和cross-browser fingerprinting中使用多个novel OS以及hardware features。本篇论文中的方法能够成功fingerprint（定位？）99.24%的用户（而AmIUnique只有90.84%）；另外，本方法能够在91.44%的cross-browser stability上达到83.24%的uniqueness。</li><li>本文在single-和cross-browser fingerprinting上进行了一些有趣的观察。以往工作中的screen resolution（屏幕分辨率）是不稳定的，因为当用户缩小放大网页时，屏幕分辨率会变化。所以作者将缩放比例纳入考虑范围，并且标准化屏幕分辨率的长宽。另外，DataURL和JPEG格式在不同浏览器中是不稳定的，这是因为这些格式有损且在不同的浏览器和服务端都有不同的实现。因为在cross-browser fingerprinting中，需要使用无损格式进行server-client通信。</li></ul><p>第二部分：介绍所有的features，包括从AmIUnique中采用的以及修改的老方法和本文采用的新方法；</p><p>第三部分：介绍本文browser fingerprinting的设计，包括总体架构，渲染任务以及掩膜生成(mask generation)</p><p>第四部分：讨论完成方法</p><p>第五部分：数据收集</p><p>第六部分：评估方法以及展示结果</p><p>第七部分：讨论针对本文的fingerprinting的抵御方法</p><p>其余：伦理问题，相关工作以及结论</p><h2 id="2-fingerprintable-features"><a href="#2-fingerprintable-features" class="headerlink" title="2 fingerprintable features"></a>2 fingerprintable features</h2><p>single-browser fingerprinting的features没有限制，但cross-browser features需要反映OS和硬件级别的信息和操作。OS和硬件级别的这些特征要相对来说更稳定，毕竟所有的浏览器都是跑在相同的OS和硬件上。（比如，顶点着色器和片段着色器都暴露了GPU和OS中的GPU driver的特征）</p><p>若某个操作的输出由浏览器和底层（OS和硬件）共同贡献(contributed)，那么也可以利用该特征用于single-browser fingerprinting，但在cross-browser fingerprinting中需要剔除browser factor。</p><h3 id="A-prior-fingerprintable-features"><a href="#A-prior-fingerprintable-features" class="headerlink" title="A. prior fingerprintable features"></a>A. prior fingerprintable features</h3><p>源自<em>AmIUnique</em>论文中</p><p>4种特征：screen resolution, color depth, list of fonts, platform.</p><h3 id="B-old-features-with-major-modifications"><a href="#B-old-features-with-major-modifications" class="headerlink" title="B. old features with major modifications"></a>B. old features with major modifications</h3><p><strong>Screen Resolution</strong></p><p>目前针对屏幕分辨率的测量是通过JavaScript中的”screen”对象。但是部分浏览器会根据缩放比例变化屏幕分辨率。</p><p>根据已有的工作()根据div tag的大小和设备pixel ratio，然后相应地调整屏幕分辨率。另外，为了更好地保证可靠性，增加了一个特征——屏幕宽度和高度之间的比率，该特征不会随缩放级别而改变。</p><p>一些其他的属性，可用于single- and cross-browser fingerprinting.</p><p>availHeight, availWidth, availLeft, availTop：代表除浏览器菜单和MacOSSierra的工具栏以外等系统区域以外的可用屏幕。</p><p>screenOrientation：用于表示屏幕的位置，是横屏还是竖屏以及该屏幕是否上下颠倒。</p><p><strong>number of CPU virtual Cores</strong></p><p>内核数目可以通过a new browser feature——hardwareConcurrency来获得，该信息能够提供Web Workers的性能信息。不支持该功能的浏览器可以通过侧信道来获得该数据。</p><p>具体来说，我们可以在增加web workers数目的同时监视payload的结束时间。当增加web workers到一定数目时，finishing time增加显著，表明这时候已经达到了hardware concurrency的极限，根据该信息就可以获得内核数目。（部分浏览器比如Safari可能只会给web workers分一半的内核，这时候只需要将内核数目乘2即可）</p><p>web workers:使得一个web应用程序可以在与主执行线程分离的后台线程中运行一个脚本操作。（可以在独立的线程中执行费时的处理任务，从而允许主线程运行时不被堵塞）</p><p>payload：一段代码</p><p>（HardwareConcurrency的inventor清楚该功能是fingerprintable的，所以并没有给他取名叫cores，但在之前的相关研究中，该特征从未被使用）</p><p><strong>AudioContext</strong></p><p>在OS中的音频堆栈(audio stack)和声卡的帮助下，AudioContext提供了包括从信号生成到信号过滤的一系列的音频信号处理功能。</p><p>已有的fingerprinting工作(Online tracking: A 1-million-site measurement and analysis) 使用振荡节点(OscillatorNode)来产生一个三角波(triangle wave)，然后将波注入DynamicsCompressNode，这是一个信号处理模块，能够降低响亮的声音并放大安静的声音（也就是产生一个压缩效果）。然后将处理后的音频信号通过AnalyserNode转化到频域。</p><p>频域中的波在同样的机器上不同的浏览器是不一样的。但作者观察发现peak values（峰值）以及对应的频率在不同的浏览器中都是相对稳定的。</p><p>于是，作者在频率轴和值轴上构造了一个具有small steps（小步进）的容器列表，并且将峰值频率和峰值值映射到对应的容器中。如果一个bin中包含一个频率或者值，就将该容器标记为1，否则为0.这样的bin列表能够作为cross-browser特征。（<em>Therefore, we create a list of bins with small steps on both the frequency and value axes, and map the peak frequencies and values to the corresponding bins. If one bin contains a frequency or value, we mark the bin as one and otherwise zero: such list of bins serve as our cross-browser feature.</em>）（它虽然讲了这么多，但我对它的理解就是把峰值的频率和值拿出来作为一个特征啊。。。那为啥要有这么多容器呢？）</p><p>除了上述的波处理，作者从目标音频设备中获取以下信息：sample rate（采样率）, max channel count（最大通道计数）, number of inputs（输入数）, number of outputs（输出数）, channel count（通道计数）, channel count mode（通道计数模式）, channel interpretation（通道翻译）.（已有的工作都没有用过这些音频特征作为浏览器指纹）</p><p><strong>List of Fonts</strong></p><p>采用(Cookieless monster: Exploring the ecosystem of web-based device fingerprinting)这篇文献中提到的侧信道方法：通过测量某个字符串的宽高来确定字体类型。</p><p>并不是所有的字体都是cross-browser fingerprintable，因为一些字体是特定于web的，并由浏览器提供，所以我们需要应用第三章C部分中的掩码来选择合适的子集。</p><p>（为什么不用flash，因为现在flash逐渐退出历史舞台，很多字体也不需要flash支持；文献20提供了43种字体的子集来fingerprinting，但由于他们的工作是基于single-browser fingerprinting的，所以不考虑）</p><h3 id="C-Newly-proposed-Atomic-Fingerprintable-Features"><a href="#C-Newly-proposed-Atomic-Fingerprintable-Features" class="headerlink" title="C. Newly-proposed Atomic Fingerprintable Features"></a>C. Newly-proposed Atomic Fingerprintable Features</h3><p>atomic: 意味着browser公开一个API或一个component给JavaScript。</p><p><strong>直线，曲线，反锯齿</strong></p><p>直线和曲线都是Canvas（2D部分）和WebGL。反锯齿是一种在单线/曲线对象或者是计算机图形模型边缘中的通过平滑锯齿来减少锯齿（锯齿就是锯齿或者阶梯状的线）。</p><p>现有的用于反锯齿的方法包括first-principles, approach, signal processing approach, mipmapping，这些方法能够让反锯齿变得fingerprintable。</p><p><strong>顶点着色器</strong></p><p>顶点着色引擎(vertex shader) 由GPU和驱动渲染，将一个3D模型中的每个顶点转化成2D裁剪空间中的坐标。顶点着色器能够以三种方式接收数据：</p><ul><li>attributes from buffers （来自缓冲区中的属性）</li><li>uniforms that always stay the same（始终保持一致的数据）</li><li>texture from fragment shader（片段着色器中的纹理）</li></ul><p>当渲染计算机图形任务时，顶点着色器通常与片段着色器相结合。</p><p><strong>片段着色器</strong></p><p>一个片段着色器，由GPU和驱动程序渲染，处理一个片段，比如将一个三角形栅格化输出到一组颜色和一个单独的深度值。</p><p>（片元着色器的作用是处理由光栅化阶段生成的每个片元，最终计算出每个像素的最终颜色。归根结底，实际上就是数据的集合。这个数据集合包含每一个像素的各个颜色分量和像素透明度的值。）</p><p>WebGL通过如下方式获取数据：</p><ul><li>Uniforms：在一次draw call中，一个片段中的每个像素的uniform value都保持一致。因为，uniforms是不可追踪（non-fingerprintable）的特征，在这儿列举出来仅仅是为了完整性</li><li>Varying：varying从顶点着色器传递值到片段着色器，片段着色器在这些值中进行插值并栅格化片段，比如在fragment中绘制每个像素。插入的值在不同的计算机显卡中是不同的，因此，varying也是fingerprintable的。</li><li>Textures：给定顶点和纹理之间的映射，片段着色器可以计算出基于该纹理的每个像素值。由于纹理的分辨率有限，片段着色器需要基于目标周围的纹理像素值为目标像素插入值。在不同的显卡上，纹理插入算法有所差异，这使得texture是fingerprintable的。texture可以被进一步分为：（1）normal texture（上述提到的）；（2）depth texture（一种包含了每个像素的深度值的texture）；（3）animating texture（动画纹理，一种包含了视频帧而不是静态图像的纹理）；（4）压缩纹理（一种接收压缩格式的纹理）</li></ul><p><strong>transparency via alpha channel</strong></p><p>transparency: 一种由GPU和driver提供的特征，允许背景和前景混合。具体来说，alpha channel中的值在0到1之间，使用合成代数将背景和前景图像合成一个单一的，最终图像。</p><p>alpha channel中的两个指纹点(fingerprinting point)：</p><ul><li>使用single alpha value来fingerprint背景和前景的合成算法</li><li>当alpha value的值从0增加到1时，fingerprint透明度效果的变化。（因为一些显卡采用离散的alpha values，当变化透明度效果时，可能能够观察到some jumps）</li></ul><p><strong>图像编码和解码</strong></p><p>PNG：无损格式；JPEG：压缩有损格式。</p><p>对压缩图像的解压是一种fingerprintable feature，因为不同的算法在解压过程中会泄露不同的信息。在本文中，这是一种single-browser feature，并不能被cross-browser使用。</p><p><strong>installed writing scripts(languages)</strong></p><p>writing scripts就是可写语言，比如中文，韩文或者阿拉伯文需要安装一些特殊的lib，虽然浏览器不能提供访问安装语言的API，但是一些信息能够通过侧信道获得。</p><p>具体来说，安装了特定语言的浏览器会正确地显示语言，否则就会显示several boxes。也就是boxes的存在能够被用于fingerprint该语言的存在。</p><h3 id="D-Newly-proposed-Composite-Fingerprintable-Features"><a href="#D-Newly-proposed-Composite-Fingerprintable-Features" class="headerlink" title="D. Newly-proposed Composite Fingerprintable Features"></a>D. Newly-proposed Composite Fingerprintable Features</h3><p>composite：也就意味着公开一个或多个API给JavaScript，有时需要使用基于browser APIs的额外算法构造。</p><p><strong>Modeling and multiple models</strong></p><p>建模也就是本文中的3D建模，是一种通过三维曲面对物体进行数学描述的计算机图形过程。模型的顶点由顶点着色器处理，表面由片段着色器处理。不同对象由不同模型表示，并且在下述技术的作用下（比如光）可能会相互作用。</p><p><strong>Lighting and shadow mapping</strong></p><p>light: 计算机图形中对灯光效果的模拟</p><p>shadow mapping：测试一个像素在一定光照下是否可见，并增加相应的阴影。</p><p>光有很多种类，其区别在于光的来源。另外，很多效果都是和光共同作用产生的，当光和一个或多个计算机图形模型共同作用时，会产生比如反射，半透明，光跟踪，间接照明。</p><p>WebGL没有给lights和shadow提供直接的APIs，但是一些WebGL lib提供了构建在WebGL上的顶点和片段着色器的high-level API。</p><p><strong>Camera</strong></p><p>针孔摄像模型，用于将一个空间中的三维点映射到一个图像中的二维点。在WebGL中，a camera由顶点和片段着色器处理的camera projection matrix（投影矩阵）来表示，并且可以用来放大或缩小一个对象。</p><p><strong>Clipping Planes</strong></p><p>切割面。裁剪将渲染操作限制在感兴趣的范围中。在3D渲染中，裁剪平面距离一定距离并且垂直于camera，这样就可以防止渲染离相机太远的表面。</p><p>WebGL中，裁剪平面是由顶点和片段着色器使用额外提供的算法来执行的。</p><h2 id="3-Design"><a href="#3-Design" class="headerlink" title="3. Design"></a>3. Design</h2><h3 id="A-Overall-Architecture"><a href="#A-Overall-Architecture" class="headerlink" title="A. Overall Architecture"></a>A. Overall Architecture</h3><p>第一步：server端的task manager发送多个渲染任务（比如画曲线或者直线）给客户端（这些渲染任务中包含OS和hardware级别的信息，比如屏幕分辨率和时区）；</p><p>第二步：client端通过调用一个或多个API完成这些渲染任务，并生成相应的结果（比如图像和声波）；</p><p>第三步：这些结果将会被转化为哈希值，从而被方便地发送给server端；同时，浏览器会收集browser-specific信息，比如是否支持反锯齿和压缩纹理，这些都可以被用于server端的fingerprint composition</p><p>第四步：当server在client端收集到了所有的信息，就开始合成指纹。指纹由list of hashes和mask通过“与操作”得到。</p><p>single-browser的指纹值非常直观，是一连串的1. 而cross-browser的指纹值来自两部分。</p><ul><li>收集的浏览器信息：如果该浏览器不支持反锯齿，mask中涉及反锯齿的相关bit位都为0；</li><li>为每个浏览器对设置不同的掩码 </li></ul><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210323155003664.png" alt="image-20210323155003664"></p><h3 id="B-Rendering-Tasks"><a href="#B-Rendering-Tasks" class="headerlink" title="B. Rendering Tasks"></a>B. Rendering Tasks</h3><p>先介绍了一些basic setting，包括坐标设置，环境光[R: 0.3, G: 0.3, B: 0.3]；camera位于[0,0,-7]</p><p>不同于AmIUnique，当当前窗口变化时，本文中的canvas设置依然是可靠的。作者从窗口大小，侧栏，缩放比例三个角度进行变化，窗口中的内容以及哈希值都没有发生变化。（哈希值咋算的？）</p><p><strong>Task(a): Texture</strong></p><p>下图为在片段着色器上测试regular texture feature（Suzanne Monkey Head model被渲染为canvas上的randomly-generated texture）。纹理：是一个大小为256*256的正方形，通过为每个像素随机选择一种颜色来创建。（也就是说，在一个像素上位三种原色生成0-255之间的随机值，然后将该颜色作为该像素的颜色）</p><p>这里选择随机生成的纹理而不是一个定值，是因为这样的纹理具有更好的fingerprintable特征。原因是当片段着色器将纹理映射到一个模型中时，片段着色器需要在纹理中插值使得纹理能够被映射到模型中的每个点。在不同的显卡中插入算法不同，而当颜色中的纹理变化明显时算法差异会增大。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324100038950.png" alt="image-20210324100038950"></p><p><strong>Task(b): Varying</strong></p><p>用于测试canvas上的片段着色器的varying特征。在立方体模型的6个面上绘制不同的颜色，每个面上的4个点也指定上颜色。</p><p>选择这种varying color来提高每个面上的颜色变化和颜色差异（比如某个面有0.9/1的蓝色，那么另一个顶点的蓝色就会比较少，有更多的绿色和红色）。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324144152727.png" alt="image-20210324144152727"></p><p><strong>Task(b’): Anti-aliasing+Varying</strong></p><p>测试anti-aliasing特征，比如浏览器如何平滑模型的边缘。具体来说，就是采用了Task(b)中相同的工作，并增加了反锯齿。（对比一下b和b‘，b’的边缘是平滑的）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324151720029.png" alt="image-20210324151720029"></p><p><strong>Task(c): Camera</strong></p><p>测试相机功能，比如说投射到片段着色器的投射矩阵(projection matrix)。本部分所有的设置和a中相同，不同的在于camera的位置，a中的位置是[0,0,-5], 而在本部分camera中的位置为[-1,-4,-10].</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324151735549.png" alt="image-20210324151735549"></p><p><strong>Task(d): Lines and Curves</strong></p><p>测试直线和曲线。在一个canvas上有一根曲线和三个不同角度的直线。曲线遵从这样的算式：</p><p>y = 256 - 100cos(2.0pix/100.0) + 30cos(4.0pix/100.0) + 6cos(6.0pix/100.0)</p><p>[0,0]是cavas的左部和顶部，x轴向右增长，y轴向下增长。三根线的起始点和结束点分别为{[38.4, 115.2], [89.6, 204.8]},  {[89.6,89.6], [153.6, 204.8]},  {[166.4, 89.6], [217.6, 204.8]}.</p><p>通过选择这些特定的曲线和直线来测试不同的梯度和形状。</p><p>Task(d’)就是增加了反锯齿版本的Task(d).</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324154141105.png" alt="image-20210324154141105"></p><p><strong>Task(e): Multi-models</strong></p><p>测试同一个canvas中的不同模型如何相互影响。平行地放置了两个模型（Suzanne model和sofa model）。sofa model也根据Task(a)中描述的步骤生成一个random texture。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324164542602.png" alt="image-20210324164542602"></p><p><strong>Task(f): Light</strong></p><p>用diffuse（漫射），点光测试了和Suzanne model的相互作用。测试选择的光是白色的，RGB中的每个值都是2，光源位于[3.0,-4.0,2.0]. 选择白色光源是因为single-color light可能会降低texture上的微小差别。光的强度也是谨慎选择的，因为太弱会让模型看不清，太强会让模型变白，降低fingerprintable特征。经过我们的测试，当光强为2时，机器之间的像素差异最大。光源位置是随便选的，这对fingerprinting的结果没有影响。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324165208181.png" alt="image-20210324165208181"></p><p><strong>Task(g): Light and Models</strong></p><p>本任务是为了测试single light, 散射光，点光和两个模型之间的作用，因为当被point light照射时，一个模型可能会在另一个模型上映射一块阴影。光的设置和Task (f)一样，模型的的设置和Task(e)一样。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324170858463.png" alt="image-20210324170858463"></p><p><strong>Task(h): Specular Light</strong></p><p>用diffuse point light（散射点光）和另一种不同颜色的specular point light（镜面点光）在两个模型上测试。两种光都位于[0.8, -0.8, -0.8], diffuse point light的RGB为[0.75, 0.75, 1.0], specular light的RGB为[0.8, 0.8, 0.8].</p><p>选择了更近的位置，因为这样离模型更近并且有更好的效果。沙发模型的背面有被specular point light照亮的部分。虽然diffuse point light看起来照着蓝色，但其中也有很大面积的红色和绿色。虽然希望测试其他颜色，但白色仍然是最适合fingerprinting的颜色。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324191453598.png" alt="image-20210324191453598"></p><p><strong>Task(h’): Anti-aliasing+Specular Light</strong></p><p>反锯齿版本的Task(h’)</p><p><strong>Task(h’’): Anti-aliasing+Specular Light+Rotation</strong></p><p>Task(h’)版本旋转90度</p><p><strong>Task(i): Two Textures</strong></p><p>本部分测试两个不同的纹理映射到同一个物理上的效果。和Task(h)其他的设置都一致，但将另一层随机生成的texture映射到Suzanne和sofa模型。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324205735708.png" alt="image-20210324205735708"></p><p><strong>Task(j): Alpha</strong></p><p>将Suzanne模型和sofa模型平行放置，通过8个不同的alpha值： {0.09, 0.1, 0.11, 0.39, 0.4, 0.41, 0.79, 1}来测试产生效果，其中0意味着完全透明，1完全不透明。</p><p>选择这样一个值集来表示不同的alpha值：{0.1, 0.4, 0.8}，值的变化在0.01，选择这个数是因为部分GPU不支持更小的steps。另一方面，Suzanne和sofa模型以这样的方位摆放部分由交叠，当Suzanne模型透明的时候，sofa模型部分被遮盖的部分能够变得可见。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324210351161.png" alt="image-20210324210351161"></p><p><strong>Task(k): Complex Lights</strong></p><p>测试复杂的光线特征，比如反射，移动光源以及多个模型之间的光线跟踪。具体来说，生成5000个金属环，这些金属环以随机的角度堆在地上。为了可靠性，使用一个随机数生成器，每次在不同的浏览器和机器上使用相同的随机数种子进行重复测试。</p><p>照向底部的黄色和红色的点光源，在整个场景的右上方角落部分缠绕。当光照亮底部的圆环时，其他的圆环通过反射被照亮，两种不同的光同时也被混合在一起。（这里选择单色光是因为模型不是多彩的，所以有颜色的光能够照出更多环上的细节，另外，不同的光之间的交互会产生更多的细节）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324212814603.png" alt="image-20210324212814603"></p><p><strong>Task(k’): Anti-aliasing+Complex Lights</strong></p><p>反锯齿版本的Task(k)</p><p><strong>Task(l): Clipping Plane</strong></p><p>测试裁剪平面的移动以及FPS。具体来说，将一个静态的正四面体放在地上，用准直光照射它，并移动裁剪平面，让观察者感觉四面体在移动。（当移动下图的位置时，四面体是颠倒的）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324212829829.png" alt="image-20210324212829829"></p><p><strong>Task(m): Cubemap Texture+Fresnel Effect(立方图纹理+菲涅尔效应)</strong></p><p>测试光折射中的立方图纹理和菲涅尔效应。</p><p>cubemap texture是一种特殊的纹理，利用一个立方体上的6个面作为map shape（图形映射）</p><p>fresnel effect是基于观察角度时所观察到的反射光数量。</p><p>在本文的实验中，用普通的校园场景构造了一个立方体纹理，并且在该纹理上放置了几个透明泡泡用于菲涅尔效应。所以泡泡随机移动并且相互碰撞。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210324212841814.png" alt="image-20210324212841814"></p><p><strong>Task(n): DDS Textures</strong></p><p>DDS指纹指的是使用了S3 Texture Compression(S3TC)算法的DirectDraw Surface file format(一种特殊的数据压缩格式). S3TC有5种不同的变量：DXT1到DXT5，每种格式都有一个选项支持mipmapping（mipmapping是一种将高分辨率的纹理在纹理文件中缩放成多个texture file的技术）</p><p>下图所示仅测试了DXT1, DXT3, DXT5(因为2和3，4和5比较相似)，另外在最右列增加了ARGB格式，第一行是mipmapping，第二行是without mipmapping（第一行的两个gray cube是因为特定机器上不支持DXT3 and DXT5 with mipmapping）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325102746780.png" alt="image-20210325102746780"></p><p><strong>Task(o): PVR Textures</strong></p><p>PVR texture是一种被很多移动设备采纳的另一种纹理压缩格式。基于数据块有两种模式：4bit模式和2bit模式；有两种流行版本：v1和v3，然后再基于是否mipmapping一共有8种子任务。其中的灰色方块也表示该格式不支持。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325102845109.png" alt="image-20210325102845109"></p><p><strong>Task(p): Float Textures</strong></p><p>浮点纹理，用浮点数代替整数来表示颜色值。浮点纹理的一种特殊类型是深度纹理(depth texture)，该纹理包含特定场景的深度缓冲的数据。下图来自于一个已存的在线测试，该测试是为了渲染浮点纹理和深度纹理。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325102856913.png" alt="image-20210325102856913"></p><p><strong>Task(q): Video(Animating Textures)</strong></p><p>测试video的解压。具体来说，用三种不同的压缩格式（WebM, high quality MP4, standard MP4）的PNG文件构造了一个2s的静态场景视频，将视频从动态纹理映射到方块，并从该视频中捕获6个连续的帧。</p><p>（虽然所有的视频都是用一个PNG文件创建的，但由于图片压缩算法是有损的，所以捕获的帧都是不同的。目标是想捕获特定帧数的帧，但由于js没有提供特定帧数的帧的接口，值提供特定时间的API接口，所以这里选择6个连续的帧来保证目标帧在范围内）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325103014267.png" alt="image-20210325103014267"></p><p><strong>Task(r): Writing Scripts</strong></p><p>采用了一个侧信道方法来测试每个writing scripts的存在。writing scripts中的语言都会在浏览器中被渲染。如果writing scripts支持某个语言，渲染就会成功；否则就会出现一堆box。下图显示：Javanese, Sundanese, Lontara, Thaana在该测试浏览器中不支持。目前作者的测试列表中有36种语言。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325103035220.png" alt="image-20210325103035220"></p><h3 id="C-Fingerprints-Composition"><a href="#C-Fingerprints-Composition" class="headerlink" title="C. Fingerprints Composition"></a>C. Fingerprints Composition</h3><p>在本部分主要介绍的是如何基于客户端的渲染任务的哈希值在服务器端形成一个指纹。</p><p>所有任务的哈希列表以及一个掩码(mask)共同执行“与”操作最终生成一个指纹值。</p><p>如果是single-browser fingerprinting，那么mask值是全1；如果是cross-browser fingerprinting，就需要从两个子任务中计算。第一个子任务是该浏览器是否支持B章节中描述的任务；第二个子任务根据不同的浏览器对有所不同。</p><p>为两个浏览器生成掩码是一个基于训练的过程。具体来说，使用较小的子集来获得一个掩码以优化跨浏览器的稳定性和唯一性(stability and the uniqueness)(稳定性和唯一性就像是硬币的两面，一方变大，另一方就会减小；比如说单浏览器的稳定性是0，但是唯一性确实最高的。)</p><p>下面的算法显示了对每个浏览器对的掩码的训练过程，采用了穷举算法，虽然不是最有效率但是结果最好并且最完整。</p><p>首先枚举了所有的浏览器对(Line 1); 接着枚举了所有的mask(line 4)</p><p>对每个掩码，遍历训练数据(line7)，保证最终选择出来的掩码值是最大的cross-browser稳定性乘上唯一性(Line 8-11, 14-17)。第8行这边的相等是为了找两个不同浏览器之间的共同特征，FS是为了避免重复。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325155911260.png" alt="image-20210325155911260"></p><h2 id="4-Implementation"><a href="#4-Implementation" class="headerlink" title="4 Implementation"></a>4 Implementation</h2><p>本开源实现(three.js, a JavaScript 3D library, glMatrix,a JavaScript library for matrix operations)一共包含21K LoC，其中JavaScripts: 14K lines, HTML: 1K lines; Coffeescript: 2.4K lines; C code: 500 line; Python code: 3.7K lines.</p><p>客户端的代码有一个manager，该manager由Coffeescript生成并转化为JavaScript。</p><ul><li>装载所有的渲染任务</li><li>从渲染任务中国收集结果以及浏览器信息</li><li>将结果发送给JavaScript代码，JavaScript代码执行散列操作并与服务端代码进行通信。</li></ul><p>Task(n)和(o)由C编写并通过Emscripten转化为JavaScript。其余的渲染代码由JavaScript编写，其中(k)-(m)的帮助由three.js协助完成，其余的直接使用WebGL或者JavaScript APIs。所有的渲染任务都使用glMatrix用于向量和矩阵操作。</p><p>服务器端部分的实现由Python编写，作为Apache server的一个模块：</p><ul><li>第一部分为1.2KLoC用于和客户端进行通信，并将哈希值存储在数据库中，图片存储在文件夹中</li><li>第二部分为2.5KLoC用于分析，比如生成并在收集到的指纹上应用masks。</li></ul><h2 id="5-Data-Collection"><a href="#5-Data-Collection" class="headerlink" title="5 Data Collection"></a>5 Data Collection</h2><p>本论文是从众包网站上收集数据：Amazon Mechanical Turks, MacroWorkers. 如果众包工人愿意用两个不同的浏览器登录指定的网站，将会得到额外的奖励。</p><p>为了保证获取完全真实的数据，在每个众包员工访问的链接中插入唯一标识符，比如<code>http://oururl.com/?id=ABC</code>。这个特殊标签会保存在客户端浏览器中作为一个cookie，如果该用户重新访问该浏览器，将会得到一样的身份标识符。每个众包员工只能接一次这个工作。</p><p>对于cross-browser fingerprinting，数据集被等分10份：一个用于生成掩码，其余用于验证。</p><h3 id="A-Comparing-Our-Dataset-with-AmIUnique-and-Panopticlick"><a href="#A-Comparing-Our-Dataset-with-AmIUnique-and-Panopticlick" class="headerlink" title="A. Comparing Our Dataset with AmIUnique and Panopticlick"></a>A. Comparing Our Dataset with AmIUnique and Panopticlick</h3><p>本篇论文方法，AmIUnique, Panopticlick三种得到的数据集在normalized Shannon’s entropy（归一化香农熵）上的对比。</p><p>其中，HM意味着最坏的可能性：也就是所有的指纹都有着相同的概率，也就是所有的指纹都一样。（<em>这儿有个问题：为什么熵最大的时候，是最坏的可能性，这不是意味着没有重复吗？还是说一个物理机器上的不同浏览器之间的重复值基本没有？</em>）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325192759650.png" alt="image-20210325192759650"></p><p>其中，差异比较大的是List of Fonts，主要原因是当前很多浏览器都淘汰了Flash</p><p>TimeZone差异大是因为众包员工来自世界各地；</p><p>另外，本方法的cookie的归一化熵几乎为0，这是因为作者从众包网站上收集数据时，员工必须在支持cookie收集的情况下才能得到奖励。如果他们关闭了cookie，甚至无法登陆进众包网站。而其余两个网站的用户可能有一小部分关闭了cookie(enable)</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325192431886.png" alt="image-20210325192431886"></p><h2 id="6-Results"><a href="#6-Results" class="headerlink" title="6. Results"></a>6. Results</h2><p>首先给出结果的概览，然后将结果分成不同的浏览器对和特征，最后给出一些有趣的观察结果。</p><h3 id="A-Overview"><a href="#A-Overview" class="headerlink" title="A. Overview"></a>A. Overview</h3><p>与AmIUnique比较single-browser fingerprinting，与Boda et al.比较cross-browser fingerprinting。</p><p>Boda et al.中的特征具有着最高的cross-browser stability。</p><p>AmIUnique是开源的，代码可以直接从github获得；Boda et al.提供了开放的测试网站，作者直接下载了fingerprinting JavaScript。这样直接使用它们的源代码能够最小化可能的实现偏差。</p><p>Uniqueness意味着唯一指纹数占总指纹数量的比重，而entropy是Shannon entropy。本论文方法的结果为99.24%，相对于AmIUnique有8.4%的增长。而对于熵，最大值为10.96，两种方法都非常接近这个最大值（尤其是本文的方法更接近一点），这也意味着两种方法中的非特殊的指纹都分散在比较小的匿名空间中。</p><p>stability意味着同一台机器上的不同浏览器中稳定的指纹比例。（举个例子，在Boda et al.中，用户如果选择不同的缩放比例，那么屏幕分辨率也可能不同；GPU渲染可能使用不同的方法，比如硬件渲染或者软件渲染）</p><p>unique相对于Boda提高了很多；另外，cross-browser stability提高到91.44%，这是因为本论文中采集的特征在不同的浏览器中更稳定。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325203512556.png" alt="image-20210325203512556"></p><h3 id="B-Breakdown-by-Browser-Pairs"><a href="#B-Breakdown-by-Browser-Pairs" class="headerlink" title="B. Breakdown by Browser Pairs"></a>B. Breakdown by Browser Pairs</h3><p>其余浏览器包括Maxthon, Coconut, UC浏览器。主对角线代表着single-browser fingerprinting,其余部分表示cross-browser。（有两个N/A是因为Apple放弃了在Windows上支持Safari，而微软从来没有在Mac OS上支持IE和Edge）</p><p>single browser的稳定性为100%是因为只是在和自己比较。其中，火狐拥有最低的唯一性，是因为火狐隐藏了一些信息（比如由于隐私原因隐藏了WebGL渲染和供应商）。IE和Edge的唯一性为100%，说明这两款浏览器都是highly fingerprintable；而Opera，Safari以及其他的浏览器为100%是在我们的数据集中只有比较少的样本。</p><p>接下来观察cross-browser的uniqueness和stability，其中，除了Opera vs IE(因为这对组合的基数非常小) ，其余浏览器对的cross-browser稳定性都很高(&gt;85%)</p><p>IE和Edge对的唯一性很高，这是因为这两者都是由微软设计并且使用了比较少的开源库；而且他们之间的稳定性也很高，说明IE和Edge很有可能共同使用了相当多的代码。</p><p>Edge在和其他浏览器组成浏览器对时，比IE有更高的uniqueness，这是因为Edge引入了更多的功能，比如WebGL遵从标准的完全实现，会有更多的指纹面。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210325210632580.png" alt="image-20210325210632580"></p><h3 id="C-Breakdown-by-Features"><a href="#C-Breakdown-by-Features" class="headerlink" title="C. Breakdown by Features"></a>C. Breakdown by Features</h3><p>表4被分成两个部分，AmIUnique上面的部分显示了AmIUnique采用的特征；而第二部分是本文方法采用的特征。</p><h4 id="1-Screen-Resolution-and-Retio"><a href="#1-Screen-Resolution-and-Retio" class="headerlink" title="1) Screen Resolution and Retio"></a>1) Screen Resolution and Retio</h4><p>single-browser中，屏幕分辨率和屏幕比例的熵为7.41，而宽和高比例的熵仅为1.40.这是因为很多分辨率比如1024x768和1280x960，共享相同的比例。cross-browser的屏幕分辨率的stability非常低(9.13%)，因为用户经常放大缩小网页。cross-browser的宽高比稳定性很高(97.57%)，但低于100%，这是因为部分用户采用两个屏幕，并将两个浏览器分别投射在两个不同的屏幕上。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326144654161.png" alt="image-20210326144654161"></p><h4 id="2-List-of-Font"><a href="#2-List-of-Font" class="headerlink" title="2) List of Font"></a>2) List of Font</h4><p>由于Flash技术的逐渐被取代，由Flash得到的字体列表的熵仅为2.40，而相对低，由JavaScript获得的字体列表的熵为10.4，这也意味着list of fonts是一种highly fingerprintable feature</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326202803918.png" alt="image-20210326145829551"></p><h4 id="3-Anti-aliasing"><a href="#3-Anti-aliasing" class="headerlink" title="3) Anti-aliasing"></a>3) Anti-aliasing</h4><p>(b: varying), (d: lines and curves), (h: specular light), (k: complex lights)</p><p>当增加了反锯齿后，b, d, h的single-browser fingerprinting的熵增加，而k减少了，这是因为b, d, h有更少的边，而反锯齿会增加更多的fingerprintable内容；而k中的每个圆环有很多小边，反锯齿会占据圆环的内容并且降低每个圆环的fingerprintable内容。</p><p>而cross-browser fingerprinting的稳定性特征正相反：b, d, h下降，而k提高。因为一些机器上的所有浏览器并不支持反锯齿，而反锯齿降低了圆环中的一些fingerprintable内容，从而提高了稳定性。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326151523197.png" alt="image-20210326151523197"></p><h4 id="4-Line-amp-Curves"><a href="#4-Line-amp-Curves" class="headerlink" title="4) Line&amp;Curves"></a>4) Line&amp;Curves</h4><p>任务(d)  这部分的熵很小(1.09)，而且cross-browser的稳定性很高(90.77%)，因为直线和曲线都是简单的2D操作，不同浏览器和机器之间不会相差太多（手动分析一些案例得到的主要差异在于起点和终点有几个像素点移动了）</p><h4 id="5-Camera"><a href="#5-Camera" class="headerlink" title="5) Camera"></a>5) Camera</h4><p>比较b和c时，可以发现当增加摄像头时，熵值下降了，这是因为增加摄像头的目的在于缩小(画面拉远)立方体，这会减少表面上的微小差异。b和c的cross-browser稳定性很相似，是因为b和c执行了类似的任务。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326152848288.png" alt="image-20210326152848288"></p><h4 id="6-Texture"><a href="#6-Texture" class="headerlink" title="6) Texture"></a>6) Texture</h4><p>比较DDS, PVR, cubemap, float texture，其中，float和cubemap比其他的纹理的熵高，这是因为这两者其中包含了更多的信息（比如，浮点纹理中的宽以及cubemap纹理中的cube mapping）。PVR纹理的熵值很低，是因为它主要在Apple移动设备上提供支持（众包员工使用Apple移动设备的比较少）。而DDS纹理的cross-browser稳定性很低(68.18%)，这是因为DDS是一个微软格式，不在其他浏览器上提供支持。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326153914549.png" alt="image-20210326153914549"></p><p>比较Task(h)和Task(i)，当增加了一层纹理后，single-和cross-browser的熵都减小了，这是因为本文中的纹理是精心挑选的，其中包含了很多fingerprintable特征，当增加了两个纹理之后，一些特征被减小了，从而使two-texture的任务变得less fingerprintable。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326155403356.png" alt="image-20210326155403356"></p><h4 id="7-Model"><a href="#7-Model" class="headerlink" title="7) Model"></a>7) Model</h4><p>比较Task(a)和(e)以及Task(f)和Task(g)中关于模型的影响。(e)和(g)相对于(a)和(f)增加了沙发模型，但熵值都只增加了0.03，说明Sofa模型带来的fingerprintable feature的增加非常有限。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326155932072.png" alt="image-20210326155932072"></p><h4 id="8-Light"><a href="#8-Light" class="headerlink" title="8) Light"></a>8) Light</h4><p>(a), (e), (f), (h), (k)都是与光相关的部分。其中，f相对于a增加了diffuse point light(散射点光)，熵值相对增加了0.01，说明散射点光在fingerprinting中产生了比较小的作用。而(h)表明镜面光有更显著的作用，因为h在单浏览器和cross-browser中的指纹识别中，熵值都增加了超过0.9（相比较f）。而任务k的熵值也很高，是因为k中有超过5000个模型，并且不同颜色光在这些模型上反射并相互混合。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326160933816.png" alt="image-20210326160933816"></p><h4 id="9-Alpha"><a href="#9-Alpha" class="headerlink" title="9) Alpha"></a>9) Alpha</h4><p>在0.09到1之间选择了5个不同的值赋给alpha。通过实验结果，可以发现随着alpha值增加，熵值开始也随之增加但慢慢产生了回落。作者比较了修改了alpha值的图像和标准图像，发现回退主要是由于软件渲染引起的，软件渲染近似于Alpha值。作者还观察到了回退中的一些模式，这些模式以0.1的增量步骤发生。</p><p>（<em>瞎翻的，具体为什么会回退看论文没看懂</em>）</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326162314054.png" alt="image-20210326162314054"></p><h4 id="10-Clipping-Planes"><a href="#10-Clipping-Planes" class="headerlink" title="10) Clipping Planes"></a>10) Clipping Planes</h4><p>single-browser中的熵为3.48，cross-browser的熵为1.93，有着76.61%的稳定性。熵结果和pure texture值接近，因为折叠平面用JavaScript实现，并没有贡献多少指纹。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326164243396.png" alt="image-20210326164243396"></p><h4 id="11-Rotation"><a href="#11-Rotation" class="headerlink" title="11) Rotation"></a>11) Rotation</h4><p>h’’相对于h’增加了稳定性，但降低了熵，因为Suzanne模型的正面和沙发模型的里面有更多的细节，当旋转到另一个角度时，会让fingerprintable细节减少而相应地稳定性提高。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326164436353.png" alt="image-20210326164436353"></p><h4 id="12-AudioContext"><a href="#12-AudioContext" class="headerlink" title="12) AudioContext"></a>12) AudioContext</h4><p>本文中测量的AudioContext（目标音频的信息和转换波）是cross-browser稳定的。熵值为1.87，相比较测量Englehardt[18]测量整个wave得到的熵值(5.4)要小很多。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326164713108.png" alt="image-20210326164713108"></p><h4 id="13-Video"><a href="#13-Video" class="headerlink" title="13) Video"></a>13) Video</h4><p>video的熵值是所有任务中最高的(7.29)，因为解码视频需要浏览器，驱动和硬件的共同参与。而video关于cross-browser的稳定性非常低(5.48%)，而熵将至2.32。这是因为类似于图片编码和解压，浏览器在解压WebM和MP4格式时会伴随着损失，但作者并没有找到像图片一样的针对视频的无损格式。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326165442054.png" alt="image-20210326165442054"></p><h4 id="14-Writing-Scripts"><a href="#14-Writing-Scripts" class="headerlink" title="14) Writing Scripts"></a>14) Writing Scripts</h4><p>writing scripts(support)包含的是特定书写字体是否被支持的信息（比如，如果某个比特位为1就说明支持某个字体，否则就不支持，而我们获取是否支持的信息就是从box detection）</p><p>writing scripts(images)是客户端的图片渲染。 writing scripts中的single-browser熵要比writing script(support)大3.13，这是因为图像中包含着更多的信息。</p><p>writing scripts(support)的cross-browser稳定性是在应用了掩码之后基于结果计算得到的，因为有些writing scripts是随浏览器一起发布的，并且不是跨浏览器稳定的，相对而言，writing scripts(support)跨浏览器的熵要比单浏览器低。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210326202803918.png" alt="image-20210326202803918"></p><h4 id="15-CPU-Virtual-Cores"><a href="#15-CPU-Virtual-Cores" class="headerlink" title="15) CPU Virtual Cores"></a>15) CPU Virtual Cores</h4><p>CPU 虚拟内核的数量是从HardwareConcurrency值计算得到的（如果不支持HardwareConcurrency，那么该值为”undefined”），单浏览器指纹的熵值为1.92（作者认为未来该熵值会增大，因为就在论文提交不久前，Firefox48开始支持该特性）。cross-browser的稳定性为100%是因为作者检测浏览器是否支持HardwareConcurrency，并应用定制掩码。cross-browser的熵比single-browser的药效，是因为数据集比较小，并且他们归一化后值其实非常接近。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210327094903410.png" alt="image-20210327094903410"></p><h4 id="16-Normalized-WebGL-Render"><a href="#16-Normalized-WebGL-Render" class="headerlink" title="16) Normalized WebGL Render"></a>16) Normalized WebGL Render</h4><p>WebGL渲染器并不是cross-browser fingerprintable，因为不同浏览器提供不同层面的信息。作者从不同的浏览器中提取共同的信息，并用标准格式对其这些信息。对其标准化的过程会丢弃部分信息，使得single-browser的熵从5.70降到4.98，但另一方面，cross-browser的稳定性从15.39%上升到37.39%。</p><p>这里需要注意两个点</p><ul><li>WebGL供应商并没有提供比WebGL渲染器更多的信息，所以当结合两者的值时，熵值仍然是WebGL渲染器的值；</li><li>GPU任务提供了比WebGL供应商和渲染器更多的信息，因为GPU渲染是软件和硬件信息的共同作用，而WebGL仅仅提供了用于硬件渲染的物理信息。</li></ul><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210327101200107.png" alt="image-20210327101200107"></p><h3 id="D-Observation"><a href="#D-Observation" class="headerlink" title="D. Observation"></a>D. Observation</h3><p>接下来介绍作者观察到的几个有趣的事实。</p><p><strong>观察1：fingerprintable特征是高度可信赖（即使移除单个特征对总的指纹结果来说影响非常小）</strong></p><p>通过任意从AmIUnique和本方法中移除一个特征并计算两者的唯一性值，从而比较两个方法的可靠程度。结果表明即使任意移除表4中的特征，作者的fingerprinting的唯一性仍然保持在99%以上，而AmIUnique中移除6个属性(user agent, timezone, list of HTTP headers, screen resolution, color depth) 中的任何一个，AmIUnique的唯一性会将至84%。</p><p>得出结论：本方法相比较AmIUnique在使用的特征上有更可靠。</p><p><strong>观察2：软件渲染可以用于指纹</strong></p><p>对WebGL的一个共识是软件渲染可能会减少由显卡带来的差异。但是本实验表明软件渲染能够用于指纹识别。具体来说，作者选用WebGL中所有由SwiftShader渲染的数据，SwiftShader是一个Google开发的开源软件渲染器，当硬件渲染无法使用时由Chrome使用。作者计算了所有GPU渲染任务的特殊指纹（task(a)-(p)包括writing scripts和video）</p><p>由于大部分例子使用了硬件渲染，作者仅采集了88例使用SwiftShader的例子，并找到了11个不同的指纹，其中，7例是唯一的。软件渲染的唯一性是低于任何一种硬件渲染，但也不是0</p><p><strong>观察3：WebGL渲染是软件和硬件共同完成的，其中硬件贡献过于软件</strong></p><p>Microsoft Basic Rendering对各类显卡提供了通用驱动，也就是该渲染器能够最大地降低软件驱动的影响，从而显示硬件的效果。作者选择使用了Microsoft Basic Rendering的例子并计算指纹。</p><p>仅采集到32例使用Microsoft Basic Rendering的例子，并找到了18例独特的GPU指纹，其中15例是唯一的。Microsoft Basic Rendering的唯一性低于正常使用普通显卡驱动的例子，说明WebGL的渲染是通过软硬件共同完成的。但同时，硬件做出了更多的贡献，因为Microsoft Basic Rendering的唯一性高于观察2中的软件渲染器。</p><p><strong>观察4：DataURL在不同浏览器中有不同的实现</strong></p><p>DataURL是一种在先前的指纹识别中用于表示图像的通用格式。但本文作者发现DataURL在不同浏览器中的实现是非常不同的。这对于单浏览器指纹识别很好，但却不利于跨浏览器指纹识别。Canvas中的跨浏览器稳定性非常低，仅为8.17%，这是因为AmIUnique使用DataURL来存储图像信息。</p><p><img src="/2021/03/30/2021-05-09-Browser-NDSS17/image-20210327111906064.png" alt="image-20210327111906064"></p><p><strong>观察5：渲染结果之间的差别非常小（只有1到2个像素的差别）</strong></p><p>部分渲染结果（尤其软件和硬件渲染）差别很大，但有部分渲染结果差别很小（尤其是当显卡相似时）。比如，Suzanne模型当使用iMac和另一个Mac Pro渲染时，在纹理上的差异仅有1个像素，当作者旋转模型时，仅有的差异也消失了。</p><p>最后，刘老师真好！给分很高！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;(Cross-) Browser Fingerprinting via OS and Hardware Level Features&lt;/p&gt;
&lt;p&gt;春季学期web追踪前沿分享的论文，由于本人的web知识浅薄，整理的笔记难免有偏颇的地方。&lt;/p&gt;
&lt;p&gt;基于操作系统和硬件特征来进行单浏览器和跨浏览器指纹追踪。&lt;/p&gt;
    
    </summary>
    
      <category term="课堂论文分享" scheme="http://yoursite.com/categories/%E8%AF%BE%E5%A0%82%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="web" scheme="http://yoursite.com/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>leaky -CCS17</title>
    <link href="http://yoursite.com/2021/02/28/2021-02-28-leaky/"/>
    <id>http://yoursite.com/2021/02/28/2021-02-28-leaky/</id>
    <published>2021-02-28T14:17:15.000Z</published>
    <updated>2021-02-28T09:41:48.614Z</updated>
    
    <content type="html"><![CDATA[<p>Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel Hazards in SGX </p><p>论文阅读摘要，建议阅读原文</p><a id="more"></a><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>简单介绍了一下背景：目前的研究热点是针对在当时新提出来的page-fault attack（OS级别的攻击者通过产生page faults来观察SGX中受保护的进程的page-level访问模式）。虽然提出了很多保护措施，但是这些保护措施的功效其实还是未知的。</p><p>提出本篇论文做出的工作：</p><ul><li>系统地分析了SGX所面临的侧信道攻击的威胁（主要在内存管理上，从TLB到DRAM模块）</li><li>当从page channel中恢复EdDSA密钥时对enclave program进行细粒度的监控时能够避免高频率的AEXs（如何避免AEXs的同时在cache和cross-enclave DRAM中恢复EdDSA密钥）</li><li>揭露现有针对SGX的安全研究和side-channel weakness之间的鸿沟</li><li>启发如何安全地使用SGX这样的一个系统</li></ul><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>第一段简单地介绍了TEE和SGX的概念，然后介绍了SGX存在的问题。SGX强调简单的设计理念导致很多资源都是部分或者是全部被untrusted OS所控制，因此很容易受到侧信道攻击的影响。</p><p>第二部分介绍了侧信道攻击的影响，当攻击者完全控制住了OS，他能够通过构造一个完全没有噪音的环境，在该环境中观察中断来操纵页表中运行的代码。在page level的级别定义程序运行轨迹，从而提取出运行的文本信息。（攻击者获得了对OS的控制权，他就能够操纵运行在enclave-mode中的页表代码怎么做的呢？通过在一个由攻击者构造的环境中观察中断，他能够根据page level的执行轨迹提取出运行的文本信息，从popular application libraries得到图片信息。)</p><p>第二部分讲的就是侧信道攻击的实现方法以及可能带来的危害。</p><p>提到了intel官方对于侧信道攻击的态度：intel官方非常清楚SGX是无法防御侧信道攻击的，他们把问题的解决留给了软件方。</p><p>提出的问题是对可能存在的攻击面的不完全理解会导致不能很好地防御。（提出问题）</p><p>第三部分，也就是理解侧信道攻击这部分，作者提出了本文最重要的三个点：</p><ul><li>不仅仅只有page faults会泄露程序的内存访问布局</li><li>不是所有的侧信道攻击都会触发大量的AEX（asynchronous enclave exits）</li><li>需要对side-channel进行一个更细粒度的观察，比如说在cache-line层面上</li></ul><p>作者所作出的工作：</p><ul><li>探索memory side-channel攻击面（该研究从address translation到memory operation之间的每一步都考虑在内）</li><li>通过一种更有效的侧信道攻击来减少副作用。（避免跟踪程序碎片进入和退出的轨迹，转而测量不同页面之间的执行时间从而推测它们之间的执行路径；另外，提供了一种新的方法来刷新TLBs，该方法利用了intel的HyperThreading，并通过与enclave code共享的CPU core的攻击进程，从而减少所需要的中断数量）（这部分主要是介绍了本文作者所完成的工作：提出了一种新的方法SPM，该方法已有的侧信道攻击方法相比优势所在，简单介绍了该方法运用了什么技术，用SPM技术最后呈现的效果如何）</li><li>提高了攻击空间粒度。（page-fault attacks的访问粒度在4KB，而本文是64B）</li></ul><p>影响</p><p>贡献：</p><ul><li>第一篇对SGX内存侧信道攻击面的in-depth研究</li><li>提出了新的攻击</li><li>提出了缓解措施，强调对类似于SGX等安全措施的更好的理解</li></ul><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>背景主要从虚拟地址和物理地址管理，对内存隔离的安全检查以及内存加密三个方面进行表述。</p><p>虚拟地址和物理地址管理</p><p>SGX为enclave应用程序和相关的控制结构保留了一段Processor Reserved Memory（PRM），而EPC就是PRM的一个子集。虚拟地址转换成物理地址是通过untrusted system software来完成，比如TLB，CPU在enclave和非enclave之间的切换通过EENTER和EEXIT指令来完成。</p><p>然后SGX分成enclave和非enclave，接下来就介绍对内存隔离是如何保证的。如何enclave的地址被映射到了非PRM中或者非enclave的地址被映射到了PRM中，就会出现page fault。</p><p>最后介绍安全内存是如何来保证安全性的，也就是内存加密的介绍。如果有EPC被驱逐出来，就会通过加密手段对该内存进行加密，另外通过MAC机制保证加密的完整性。</p><h2 id="攻击模型"><a href="#攻击模型" class="headerlink" title="攻击模型"></a>攻击模型</h2><p>关注的重点在于威胁enclave programs的机密性的侧信道分析。</p><p>假设攻击者将恶意代码加载到enclave中，攻击者能够获取enclave binary在虚拟地址空间的基地址</p><p>以及攻击者能够在执行攻击之前获取对相同配置的机器的访问。</p><h1 id="理解攻击面"><a href="#理解攻击面" class="headerlink" title="理解攻击面"></a>理解攻击面</h1><p>通过对individual vectors的分析得到的攻击面总结了SGX中侧信道攻击面。</p><h2 id="攻击面"><a href="#攻击面" class="headerlink" title="攻击面"></a>攻击面</h2><p>作者从虚拟地址到物理地址的转换进行考虑，首先评估address translation caches，并且walk through 内存中的page tables。</p><p><strong>Address Translation Cache</strong>。这一部分负责完成虚拟地址到物理地址的转换工作来进行讨论，主要介绍TLB（translation lookaside buffer），如果TLB都miss了，就要进行虚拟地址到物理地址的转化，intel中的话就需要进行4步转换操作。</p><p>vector1. shared TLBs and paging-structure caches under hyperthreading</p><p>当超线程被开启的时候，enclave模式下的TLB和paging-structure caches会和非enclave mode下的代码共享。</p><p>vector2. Flushing selected entries in TLB and paging-structure caches at AEX.</p><p>vector3. referenced PTEs are cached as data.</p><p>第三章的攻击面从地址转换cache，页表，缓存内存层次三个方面选择了8个可能存在攻击的点进行讨论，而实施侧信道攻击的影响可以从空间粒度，时间角度以及AEXs，中断频率等方面观察。</p><p>第四章介绍了新的侧信道攻击（sneaky page monitoring attacks），使用这样的攻击在带来相同攻击效果的同时会极大地减少AEXs。在介绍sneaky攻击时，利用页表的accessed flag，时间监控，利用超线程的TLB flushing这三个攻击面实施的侧信道攻击。然后介绍了这三种攻击分别在三个软件工具上的实现效果来证明攻击的有效性。在第四章的最后部分，作者在最新的Libgcrypt库中以较少的EAXs恢复EdDSA密钥。</p><p>第五章考虑以一种更为细粒度的方式实施cache-DRAM侧信道攻击，本部分通过提高空间粒度来显示了更为有效的攻击效果，分别介绍了cross-enclave Prime-Probe cache attack，cross-enclave DRAMA攻击以及一个cache-DRAM攻击。最后根据构造的timer评价了实施攻击的准确性，作者根据结果总结得出如果实施64byte粒度的cache-DRAM攻击，将能够达到和flush-reload cache攻击相似的攻击结果。</p><p>第六章首先讨论的是对前文所介绍的攻击面进行讨论和总结，比如说应用64byte的cache-DRAM攻击能和FLUSH+RELOAD达到相同的效果（但是由于EPC只能由一个enclave拥有一次，也就是它只有在这个enclave运行的时候才能被拥有，所以该攻击是无法在SGX上执行的），并简单介绍了一些其他没有被介绍的攻击面。</p><p>接下来介绍的是现有的缓解措施的效果。这部分是对现有的5种不同角度考虑的tee安全防御措施的效果进行了讨论，指出他们的作用并提出了他们所存在的问题。</p><p>第三部分是根据前面的攻击和上面的讨论得出的一些思考，比如SGX开发者必须意识到可能存在的攻击民并在软件开发时尽量避免，给予软件层面的保护并进行硬件保护。</p><p>第七章就是介绍相关的工作</p><p>第八章是对本文工作的总结</p><p>第九章是致谢以及本工作依托的项目。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel Hazards in SGX &lt;/p&gt;
&lt;p&gt;论文阅读摘要，建议阅读原文&lt;/p&gt;
    
    </summary>
    
      <category term="SGX" scheme="http://yoursite.com/categories/SGX/"/>
    
    
      <category term="SGX" scheme="http://yoursite.com/tags/SGX/"/>
    
  </entry>
  
  <entry>
    <title>Keystone EuroSys20</title>
    <link href="http://yoursite.com/2021/01/29/2021-01-29-keystone-2020/"/>
    <id>http://yoursite.com/2021/01/29/2021-01-29-keystone-2020/</id>
    <published>2021-01-29T09:53:50.000Z</published>
    <updated>2021-01-29T13:31:15.281Z</updated>
    
    <content type="html"><![CDATA[<p>Keystone论文的精读笔记~</p><a id="more"></a><p>Keystone是第一个用于构造<strong>定制TEE</strong>的开源框架。Keystone使用硬件提供的简单抽象比如内存隔离和不可信组件（比如操作系统）下的可编程层。Keystone在这些抽象中（memory isolation，programmable layer underneath untrusted components）构造可重复使用的TEE core primitives，同时允许特定于平台的修改和硬件特性。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>（简单地介绍一下TEE）</p><p>TEE被广泛地应用于诸如安全云服务、数据库、大数据计算、安全银行、区块链共识协议等场景中。</p><p>弊端：任何一个vendor TEE仅支持针对威胁模型、硬件需求、资源管理、移植操作以及功能兼容性的一小部分设计空间。一旦，一个软件开发者选择了一个特定的硬件平台，无论他们的实际需求是什么，他们都会被锁定在对应固定的硬件平台中。现有的TEE解决方案不管是在RISC-V平台或者是OpenSPARC中，进行重新设计都需要耗费巨大的经历，并且仅仅另一个固定的设计点中起效。（这边举了一个sgx的例子，SGXv1在设计之初只支持固定的enclave大小并且缺乏I/O和系统调用，所以就造成TCB非常大，尽管研究人员们提出了很多复杂的解决方法，但仅有intel能够对内部设计进行更改，所以用户得等到SGXv2，才能拥有动态的enclave虚拟内存。）</p><p>为了利用riscv的原语构造一个高可定制的TEE，keystone主张硬件必须提供安全原语而非点到点的解决方案。（将一部分重要的原语信息暴露给软件将会带来更好的用户定制效果）<strong>Keystone的宗旨是通过借鉴模块化内核的概念，允许一组通用的软件模块根据硬件平台和用例调整特性和安全模型。</strong></p><p>可定制化的TEEs的概念是允许实体创建一个硬件，操作它，并在相同的基准上构造和配置不同的TEE设计。（也就是同样的硬件，硬件通过提供原语，开发者可以根据这些提供的原语构造出针对不同用户需求和威胁模型的TEEs）</p><p><strong>作者考虑的需求</strong></p><ul><li>在不可信OS下构造a highly programmable trusted layer；</li><li>将资源管理、虚拟化以及信任边界的隔离机制解耦（hypervisor是负责安全和虚拟化的可编程层，将我们的需求变得复杂化；而硬件和微代码并不满足可编程的需求。另外，也不应该依赖于硬件隔离来实现一个固定的安全和非安全边界）</li></ul><p>–》构造一个common，portable的软件基来适应千变万化的硬件功能和用户需求</p><p>Keystone是第一个用于构造可定制TEE的开源框架。使用physical memory protection(PMP)。PMP通过利用RISC-V中的programmable machine mode来指定对物理内存区域的任意保护。keystone中使用该machine mode来运行一个security monitor（SM）在无需进行资源管理的同时提供安全边界。</p><p>每个enclave运行在各自的隔离物理内存区域，并且拥有自己的supervisor-mode runtime（RT）组件来管理enclave的虚拟内存。</p><p>基于这个设计，RT主要是完成特定于enclave的功能，而SM管理硬件完成的保证。RT仅完成特定的功能，比如说和SM进行通信，通过共享内存与主机进行通信，为enclave user-mode application（eapp）提供服务。（与安全无关的功能）</p><p>SM利用hardware primitives来提供对诸如secure boot，memory isolation以及attestation等TEE保证。而RT提供诸如系统调用接口，标准libc支持，in-enclave虚拟内存管理，自分页等enclave内部的功能性模块。<em>SM利用了一切可利用的硬件来构造额外的安全机制，比如highly configurable cache controller，与PMP协调，来抵御cache side-channel。</em>（这块的抵御侧信道攻击需要仔细看一下）</p><p><strong>总结</strong>：作者提出了当前TEEs的各种问题，然后提出了定制TEEs的概念（这个定制TEEs的概念其实也是从SDN中派生出来的），然后提出了自己对定制TEEs的需求，接着提出了设计理念。</p><p>作者构造了Keystone，两个RTs（自己制作的RT-Eyrie和一个现成的微内核seL4）以及几个模块，这些模块可以供由enclave绑定的user application选择性地配置和使用功能。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/1.png" alt="image-20200914110304034"></p><p><strong>贡献</strong></p><ul><li>customizable TEEs. 定义了一个新的范式，基于这样的一个范式，硬件制造商、开发商以及enclave开发人员能够定制自己的TEE；</li><li>Keystone框架。本文提供了第一个用于配置、建立以及实例化可定制TEEs的框架。主要方法是通过保证Keystone的模块化来根据需求定制TEE instances。</li><li>开源实现。在无需任何微架构的修改能够适应威胁模型、使用硬件特性、处理工作负载并且提供丰富的功能。</li><li>基准测试和实际应用。基于CoreMark,Beebs,RV8, IOZone来评估了Keystone，使用seL4搭载的Torchin Eyrie，FANN演示了真实世界中使用keystone的机器学习负载和一个keystone本地安全远程计算应用程序。最后演示对具有物理访问权限的攻击者的防御。</li></ul><h2 id="2-不同TEE的共同基准"><a href="#2-不同TEE的共同基准" class="headerlink" title="2 不同TEE的共同基准"></a>2 不同TEE的共同基准</h2><h3 id="2-1-商用TEEs"><a href="#2-1-商用TEEs" class="headerlink" title="2.1 商用TEEs"></a>2.1 商用TEEs</h3><p>目前很多的商用TEEs迎合特定且容易受到攻击的用例，但是仅仅在设计空间中仅考虑到了一部分。假设考虑在不可信云环境下的服务器运行高负载的程序，比如ML inferences。</p><ul><li>基于intel SGX的解决方案需要很大的软件栈来扩展额外支持的功能</li><li>AMD SEV-based solution用一个巨大的TCB隔离一个完整的VM（不管是SGX还是SEV，如果要考虑防御侧信道攻击，还需要格外的用户空间软件机制）</li><li>如果在IoT设备或者边缘感应器上，就需要考虑TrustZone，TrustZone位于一个叫secure world由硬件实现隔离的区域，但进一步的隔离需要基于软件的Secure world OS解决办法在secure application之间进行多路复用。</li></ul><p>一个新的研究方向是使用a thin layer of trusted software，类似于在kernel设计中的reference monitor。这样的设计能够抵御强大的攻击者且能够包含一个小的TCB。</p><ul><li><p>sanctum对硬件进行了修改为RISC-V构造user-space enclave。</p></li><li><p>Komodo：提供了一个verified monitor，该monitor能够在ARM TrustZone上运行</p></li></ul><h3 id="2-2-可定制的TEE"><a href="#2-2-可定制的TEE" class="headerlink" title="2.2 可定制的TEE"></a>2.2 可定制的TEE</h3><p>customizable TEEs：使用一个共同的软件框架，根据用户不同的需求来定制一个特定的TEE。硬件提供商仅需要提供基础的原语。实现一个特定的TEE实例需要涉及平台提供商对硬件接口，可信模型以及enclave开发人员的功能性需求。实体可以根据自己的需求把特定的模块组合起来实例化成一个特定的TEE。</p><p>现在的商用TEE系统都提供了固定的与各自的硬件平台相关的威胁模型。</p><ul><li>intel SGX不支持任何针对它的内存保护措施的修改，那么sgx对于不需要昂贵的内存加密的用例来说是不必要的</li><li>ARM TrustZone并不适合用来构造一个模块化的TEE（TrustZone的设计核心就是只分成了两个区域）如果有多个enclaves，还必须使用MMU（内存管理单元）</li><li>RISC-V基于machine mode和PMP寄存器提供per-hardware-thread 的物理内存视图（RISC-V同时允许多线程的enclave访问不相交的内存区域，同时允许enclave使用supervisor mode以及MMU）</li></ul><p>支持Keystone的安全硬件平台必须满足：</p><ul><li>仅对trusted boot process可见的device-specific secret key</li><li>a hardware source of randomness</li><li>a trusted boot process</li></ul><h3 id="2-3-TEE生命周期中的实体"><a href="#2-3-TEE生命周期中的实体" class="headerlink" title="2.3 TEE生命周期中的实体"></a>2.3 TEE生命周期中的实体</h3><ul><li>hardware manufacturer：负责设计和制造RISC-V硬件，包括trusted boot的相关IP</li><li>Keystone platform provider：购买制造商生产的硬件，操作硬件，并使之能够给它的客户使用，配置SM；</li><li>Keystone programmer：开发Keystone软件组件，包括SM，RT和eapps</li><li>Keystone user：选择RT和eapp的配置来构造一个Keystone，实例化一个能在Keystone platform provider提供的硬件上运行的enclave</li><li>Eapp user：与TEE中运行的eapp进行交互</li></ul><p>Acme 公司将他们的网站托管在 Apache 服务器上，该服务器运行在 Cloud 公司提供的一个基于 Keystone的安全区云服务上，该云服务基于 Bar 公司制造的硬件。   </p><p><strong>例子</strong></p><ul><li>Acme Corp：Keystone user</li><li>Apache webserver：eapp programmer</li><li>Bar Corp：hardware manufacturer</li><li>Cloud Corp提供云服务：Keystone platform provider，RT programmer，SM programmer</li></ul><h2 id="3-Keystone概览"><a href="#3-Keystone概览" class="headerlink" title="3 Keystone概览"></a>3 Keystone概览</h2><p>简单介绍一下RISC-V：RISC-V是一个有着不同开源内核实现的开源ISA。它支持4种特权模式：</p><ul><li>U-mode（user）：user-space processes</li><li>S-mode（supervisor）：kernel</li><li>H-mode（hypervisor）：hypervisor</li><li>M-mode（machine）：对物理资源的直接访问</li></ul><h3 id="3-1-设计原则"><a href="#3-1-设计原则" class="headerlink" title="3.1 设计原则"></a>3.1 设计原则</h3><ul><li>利用不可信代码下的可编程层和隔离原语。SM使用M-mode的特性来实现TEE保证：1）对平台提供者来说是可编程的；2）满足对于最小范围的最高特权级别的需求；3）在系统中控制系统中断和异常的代理；4）使用M-mode控制PMP，保证在运行时memory-mapped control features的隔离。（保证在运行时隔离内存映射功能）</li><li>解耦资源管理和安全检查。SM在最高权限以最少的代码实施安全策略，几乎只完成安全相关的功能。而S-mode的RT负责在enclave中运行的user code的生命周期，管理内存，系统调用，与SM进行通信，使用SBI（supervisor binary interface）代表eapp请求SM的操作。</li><li>设计模块化的层。Keystone使用模块化的层次（SM，RT，eapp）来支持不同的工作负载。（每个层都是独立的，上一层的安全性可以由下一层来进行检查？）</li><li>允许细粒度的TCB配置。Keystone可以根据用户的需求来实例化一个拥有最小TCB的TEEs、</li></ul><h3 id="3-2-Keystone-Enclave工作流"><a href="#3-2-Keystone-Enclave工作流" class="headerlink" title="3.2 Keystone Enclave工作流"></a>3.2 Keystone Enclave工作流</h3><p>platform用一个比较合适的硬件配置和安全扩展来初始化SM，这些安全扩展能够带来额外的隔离保证，比如cache partitioning；enclave开发者使用诸如virtual memory management和系统调用等丰富的功能来编写eapps和RTs。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/2.png" alt="image-20200914221209627"></p><h3 id="3-3-编写eapps"><a href="#3-3-编写eapps" class="headerlink" title="3.3 编写eapps"></a>3.3 编写eapps</h3><p>对于编写enclave application，Keystone提供了3种方法：（用英文原文）</p><ul><li>独立的Keystone原生eapps</li><li>具有RT支持的未修改的RISC-V binaries</li><li>partitioned application running in the selected parts in the enclave</li></ul><h3 id="3-4-威胁模型"><a href="#3-4-威胁模型" class="headerlink" title="3.4 威胁模型"></a>3.4 威胁模型</h3><p><strong>假设</strong></p><ul><li>Keystone设计框架相信PMP规范，认为PMP和RISC-V硬件都是无bug的</li><li>只有当验证完SM的测量值是正确的（被可信硬件签名且是正确的版本号），Keystone user才会信任SM</li><li>SM只信任硬件，host信任SM，RT信任SM，eapp信任SM和RT</li><li>SM，RT和eapp都是bug-free的，这可以通过formal verification来完成（eapp不可能是恶意的吗？）（对RT和eapp进行充分的检查，来</li></ul><p><strong>攻击者模型</strong></p><ul><li>physical attacks：拦截、修改、重放芯片发出的信号，假设物理攻击者不会修改芯片包内部的组件</li><li>software attacks：控制host app，untrusted OS，网络通信，配置攻击enclaves，任意篡改未受保护的内存，篡改enclave信息</li><li>side-channel attacks：通过观察可信组件和不可信组件之间的交互收集信息，分三种：cache side-channel，timing side-channel，controlled channel</li><li>denial-of-service attacker：take down enclave或者host OS</li></ul><p>Keystone没有针对speculative execution attacks和timing side-channel attacks的防护（相关的防护措施，需要程序开发人员和硬件制造商来完成），也不考虑off-chip的侧信道攻击，比如说memory bus中的侧信道攻击</p><h2 id="4-Keystone-Security-Monitor"><a href="#4-Keystone-Security-Monitor" class="headerlink" title="4 Keystone Security Monitor"></a>4 Keystone Security Monitor</h2><p>SM使用的是RISC-V平台上的标准功能，所以很容易与RISC-V平台兼容。</p><h3 id="4-1-内存隔离"><a href="#4-1-内存隔离" class="headerlink" title="4.1 内存隔离"></a>4.1 内存隔离</h3><p>PMP是由RISC-V提供的一项功能，它通过PMP条目限制S-mode和M-mode对物理内存区域的访问。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/3.png" alt="image-20200915163351206"></p><p>使用SM来完成memory isolation.</p><ul><li><p>所有的enclave不是共享一块大的内存区域，而是以多个不连续的enclave内存区域形式存在</p></li><li><p>PMP条目可以覆盖4bytes到DRAM的全部内存区域（enclave的地址范围不是固定的）</p></li><li><p>PMP条目分配得到的物理内存区域可以在运行的时候动态调节（可以随时多申请一块内存区域或者释放一块内存区域）</p></li></ul><p>SM首先给自己配置一块PMP entry来覆盖自己的内存区域，然后配置最低的PMP entry覆盖所有的内存并且允许所有mode访问。</p><p>OS创建一个enclave，然后找到一块合适的连续的物理内存通知SM。SM进行验证后，添加一个PMP条目并disable该条目的所有权限。OS和其他的进程都不能访问该PMP条目。</p><p><strong>内核之间的PMP实施</strong></p><p>每个内核都拥有自己的PMP条目的完整列表。对PMP条目的修改会通过inter-processor interrupts（IPIs）扩散到所有的内核中。在enclave执行的过程中，对PMP条目的修改只会在本地完成，不会扩散到其他内核中，IPIs的同步只会在enclave的创建和销毁中执行。（当enclave要进行扩容的时候，是否需要进行同步？如果不进行同步的话，一块内存是否会同时被两个enclave申请）</p><h3 id="4-2-enclave中的页管理-创建后"><a href="#4-2-enclave中的页管理-创建后" class="headerlink" title="4.2 enclave中的页管理(创建后)"></a>4.2 enclave中的页管理(创建后)</h3><p>在初始化过程中使用OS生成的页表，而在执行过程中，将virtual-to-physical的页表映射的任务完全交给enclave来完成。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/4.png" alt="image-20200915213129136"></p><p>enclave中具有S-mode的RT，所以keystone能够操纵特定enclave的页表来管理自己的virtual memory。–》消除了controlled side-channel attacks。</p><h3 id="4-3-中断和异常"><a href="#4-3-中断和异常" class="headerlink" title="4.3 中断和异常"></a>4.3 中断和异常</h3><p>在enclave执行期间，所有的machine interrupts 都由SM直接捕获。异常（page faults）会通过RISC-V的exception delegation register由RT代理，进而将异常报告给untrusted OS。</p><p>为了应对针对某个内核的DoS攻击，SM设置了一个machine timer，一旦timer interrupt触发，SM将会重新获取控制权–》DoS攻击的应对</p><h3 id="4-4-Enclave生命周期"><a href="#4-4-Enclave生命周期" class="headerlink" title="4.4 Enclave生命周期"></a>4.4 Enclave生命周期</h3><ul><li><p>creation：Keystone测量enclave memory来保证OS在物理内存中加载了正确的enclave binaries。（这里的测量值是initial virtual memory，所以，SM需要OS来初始化enclave页表，并且给enclave分配physical memory。SM walk OS提供的页表并检查其中是否有不合法的映射，并且保证一个虚拟地址只能映射到一个物理地址。接着计算page content和virtual address，configuration data的哈希值）</p></li><li><p>execution：SM设置PMP entry，并将控制权移交给enclave entry point</p></li><li><p>destruction：在将控制权还给OS之前清除enclave memory region</p></li></ul><h3 id="4-5-TEE原语"><a href="#4-5-TEE原语" class="headerlink" title="4.5 TEE原语"></a>4.5 TEE原语</h3><p>secure boot. Keystone的root-of-trust可以是一个temper-proof software或者是hardware。在每次CPU的reset阶段，root-of-proof</p><ul><li>测量SM image</li><li>从secure source of randomness生成一个新鲜的认证密钥</li><li>将认证密钥存储到SM memory中</li><li>用hardware-visiable key对测量结果和public key进行签名</li></ul><p>secure boot的实现可以有多种方式，目前通过一个修改的first-stage bootloader模拟一个secure boot。</p><p>secure source of randomness. SM提供了一个安全的SM SBI 调用-random，它能够返回64bit的随机值（没说具体咋实现的，而且应该不是依赖于硬件）</p><p>remote attestation：SM基于provisioned key来实现measurement和attestation。Keystone通过在signed attestation report中加入limited arbitrary data将attestation值与secure channel绑定起来。</p><p>其他的primitives. 1）通过标准rdcycle指令允许enclaves访问read-only hardware-maintained timer register；2）在SM内存中保持一个limited counter state（有限的计数器状态）来提供单调计数器。通过这些特征能够提供可信计数器，rollback defense以及sealed storage等。</p><h3 id="4-6-特定平台的扩展"><a href="#4-6-特定平台的扩展" class="headerlink" title="4.6 特定平台的扩展"></a>4.6 特定平台的扩展</h3><p><strong>secure on-chip memory.</strong> 利用L2  memory controller动态实例化一个最高可以到2MB的scratchpad memory，该内存区域可以用来生成一个usable on-chip memory region。（这边的on-chip memory region是将L2 cache分成一部分，这部分只能由特定的enclave来使用吗）该scratchpad memory可以分配给一个enclave，给enclave在自己的运行期间就可以独占该scratchpad memory。</p><p>如果一个enclave需要运行在on-chip memory，跟标准过程的差别仅在：</p><ul><li>enclave在被加载后，会被分配一个经过修改的page tables，该页表指向final scratchpad address</li><li>SM在进行measurement之前将标准enclave memory region复制到新的scratchpad region中。</li></ul><p>–》保护免受可以进入DRAM的物理攻击者的攻击</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/5.png" alt="image-20200916095137404"></p><p>cache分块。实现的方式：</p><ul><li>类似于intel’s CAT（对CAT的理解是，通过增加一个CLOS位，管理缓存将缓存分给特定的应用，在本文中就是分给特定的enclave）的L2 cache controller’s waymasking primitive</li><li>PMP以透明的方式对L2 cahce进行分区，将其分配给OS和enclave</li></ul><p>在上下文切换的时候，enclave对应的cache partition中的值会被flushed。而在运行时，enclave physical memory中的值可以很好地被PMP保护。</p><p>–》抵御cache side-channel attacks</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/6.png" alt="image-20200916105840680"></p><p>动态调整大小。（SBI是由SM提供的API，不同的caller通过调用SBI，能够执行不同的功能）</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/7.png" alt="image-20200916112211215"></p><p>静态地定义了最大的enclave size，并分配static physical or virtual memory：1）避免因为workload而动态扩展大小；降低复杂性5 </p><p>当需要扩容的时候，RT需要OS发出SBI调用，来给enclave memory region增加连续的物理页。当成功分配后，SM通过扩容对应PMP条目来增加enclave的大小并通知RT。 </p><h2 id="5-Keystone-模块化runtime"><a href="#5-Keystone-模块化runtime" class="headerlink" title="5 Keystone 模块化runtime"></a>5 Keystone 模块化runtime</h2><p>enclave中的RT提供的功能类似于一个kernel，但是它并不需要大多数的kernel功能，作者构造了一个Eyrie的RT，其中仅仅包含了必要的功能从而降低了TCB。（仅允许RT访问shared memory buffer；另外，允许轻松移植成熟的微内核）</p><h3 id="5-1-enclave内存管理模块"><a href="#5-1-enclave内存管理模块" class="headerlink" title="5.1 enclave内存管理模块"></a>5.1 enclave内存管理模块</h3><p>默认情况下，Keystone enclave会占用一块由OS分配的固定的连续物理内存，该内存在加载之时就被静态映射到了一块virtual memory。（Keystone enclaves occupy a fixed contiguous physical memory allocated by the OS with a statically-mapped virtual address space at load time.  ）</p><p><strong>释放内存。</strong> 在enclave保存unmapped physical memory之后，<strong>构造一个模块让Eyrie RT来进行page table的管理</strong>。未被映射的memory region在eapp执行之前将被设置为0。–》page table management</p><p>In-Enclave自分页。为了Eyrie RT构造了一个in-enclave page wapping模块。该模块负责处理page-faults，并使用一个通用page backing-store来管理evicted page的存储和恢复。（页表驱逐策略是一个简单的random eapp-only page eviction policy）自分页和释放内存两个一起负责管理Eyrie RT中的virtual memory management。</p><p>保护离开enclave的页表内容。当某个enclave处理自己的page fault，那么就需要将secure physical memory中的部分页面驱逐出去。当这些页面被copied out时，它们的内容也需要被保护。完成了一个backing-store layer来完成page encryption和integrity protection来允许页表中的内容被驱逐到insecure storage中。这部分可以考虑由RT或者指定的trusted hardware unit——内存加密引擎来完成。</p><p>free-》page table管理，self-page-》wapping管理  前两者共同管理virtual memory</p><h3 id="5-2-功能性模块"><a href="#5-2-功能性模块" class="headerlink" title="5.2 功能性模块"></a>5.2 功能性模块</h3><p>Edge Call Interface. eapp不能访问Keystone中的非enclave memory。所以如果需要读取enclave以外的数据，Eyrie RT需要代表eapp执行edge calls。Eyrie将该调用安全传送到untrusted host，并将返回值传送给enclave，最后传给eapp。具体的实现方案是：</p><p>1）OS将host memory space中的一块shared buffer给SM；2）SM将地址传递给enclave使得RT能够访问该内存区域；3）SM使用一块单独的PMP条目来使得OS能够访问shared buffer。</p><p>通过该interface，Keystone可以利用现有的攻击措施来抵御Iago attacks。</p><p><strong>多线程。</strong> 通过将线程管理授权给runtime来实现multi-threaded eapps。（多个RT能够同时运行自己的eapps）</p><p>并不支持parallel multi-core enclave execution（多个处理器同时执行多个任务，每个任务分配在一个处理器上执行） （但是这可以通过SM在不同的内核中多次调用enclave execution，这个的意思是不是SM一次在core0上调用enclave execution，接下来再去在core1上调用enclave execution）</p><h2 id="6-安全分析"><a href="#6-安全分析" class="headerlink" title="6 安全分析"></a>6 安全分析</h2><h3 id="6-1-对enclave的保护"><a href="#6-1-对enclave的保护" class="headerlink" title="6.1 对enclave的保护"></a>6.1 对enclave的保护</h3><p>软件攻击者无法访问enclave memory</p><p>controlled side-channel无法实施：因为enclave拥有对应的page management和in-enclave page tables。</p><p>mapping attacks. 受信任的RT在enclave creation阶段来对page tables进行初始化或者加载由SM验证过的static mapping的页表。在动态内存调整时，RT会在映射到enclave中首先检查它们是否安全并在将内存还给OS之前，清空其中的内容。</p><p>syscall tampering attacks。（伪造系统调用攻击）–》利用现有的防御机制来作为RT模块的插件来抵御这种攻击</p><p>侧信道攻击：由于enclave不会和host OS或者其他的用户应用程序分享状态，因此不会受到controlled channel attacks的攻击。干净的上下文切换</p><h3 id="6-2-保护host-OS"><a href="#6-2-保护host-OS" class="headerlink" title="6.2 保护host OS"></a>6.2 保护host OS</h3><p>内存隔离</p><p>第一步，OS能够访问OS memory来进行boot操作</p><p>这边的图 是说enclave在执行的时候，所有的部分都能够读取enclave memory（all_perm)吗？但是如果两个enclave同时运行时，不应该只能一个keystone访问属于自己的内存区域，而不能访问其他的内存区域</p><h2 id="7-PMP"><a href="#7-PMP" class="headerlink" title="7 PMP"></a>7 PMP</h2><p>几个概念</p><ul><li>WPRI：Reserved Writes Preserve Values, Reads Ignore Values</li><li>WLRL: Write/Read Only Legal Values</li><li>WARL: Write Any Values, Reads Legal Values </li></ul><p>关于RISC-V的知识点</p><p>Sv32分页虚拟内存模式下，RV32可能会拥有34位物理地址空间-》支持34位的物理内存访问管理。</p><p>Sv32的虚拟地址是32位的，每个页的大小为4KB，它的物理地址是34位的。supervisor virtual address被转化为supervisor physical address需要一个two-level page tables，20-bit的VPN被转化为22-bit的physical page number（PPN），在最终转化为machine-level physical address之前，需要一些physical memory protection structures（PMP）。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/11.png" alt="image-20200919150238758"></p><p>PMP checks are also applied to page-table accesses for virtual-address translation, for which the effective privilege mode is S. </p><p>PMP仅支持固定数量的内存区域。</p><p>PMP entries是由一个8-bit configuration register和一个MXLEN-bit address register描述的。最多仅能支持16个PMP entries。仅有M-mode能够访问PMP CSRs。</p><p>控制寄存器是8位（1个字节）的，但是在实际的机器中是不会存在8位的寄存器，所以其实是将一个CSR分成4个pmp entry configuration register.</p><p>下图中展示的是RV32，用4个CSRs，pmpcfg0-pmpcfg3来保存pmp0cfg-pmp15cfg这16个PMP entries.</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/8.png" alt="image-20200918171027557"></p><p>而在RV64中，pmpcfg0和pmpcfg2保存了16个PMP entries。将pmp8cfg到pmp15cfg保存在pmpcfg2，是因为在RV32和RV64的情况下，pmp8cfg到pmp11cfg都保存在pmpcfg2中，这样就可以减少对64位支持的开销。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/9.png" alt></p><p>而保存PMP address registers的是pmpaddr0-pmpaddr15这些CSRs。在RV32中，每个PMP address registers编码34bit物理地址中的2-33bit；在RV64中，每个PMP address registers编码56bit物理地址中的2-55bit。（Each PMP address register<br>encodes bits 33–2 of a 34-bit physical address for RV32, as shown in Figure 3.29.  For RV64, each PMP address register encodes bits 55–2 of a 56-bit physical address, as shown in Figure 3.30.   ）（下图我认为3.29应该是到33结束）并不是所有的地址位都被设置了，所以pmpaddr registers也是WARL。</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/10.png" alt="image-20200919135409757"></p><p>PMP configuration registers的构造如下图所示。R，W，X设置分别代表可读，可写，可执行。如果设置R=0，W=1，那么该寄存器将会被reserved for future use. </p><p>A：对相关的PMP address register的address-matching mode进行编码</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/12.png" alt="image-20200919164058052"></p><p>（Keystone中仅支持TOR和NAPOT）</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/13.png" alt="image-20200919165823798"></p><p>NAPOT是利用address registers的low-order bits来定义地址范围</p><p>类型为NAPOT的情况下：</p><p>yyyy…yyy0，连续1的个数为0，则XLEN=0，NAPOT range为2^(0+3)=8</p><p>yyyy…yy01，连续1的个数为1，则XLEN=1，NAPOT range为2^(1+3)=16</p><p>1111…1111，连续1的个数为XLEN，NAPOT range为2^(1+XLEN)</p><p>如果是y…y01…1，连续1的个数为n，则该PMP entry所控制的地址空间为从y…y00…0开始的2^(n+3)个字节</p><p>类型为NA4（Naturally Aligned Four-byte regions）的情况下：</p><p>当pmpaddr值为yyyy…yyyy，那么控制的地址范围就是从yyyy…yyyy开始的4个字节</p><p>类型为TOR的情况下：</p><p>该PMP entry所控制的地址范围由前一个地址寄存器和后一个地址寄存器共同决定，也就是匹配满足以下条件的地址y：</p><p>pmpaddri-1≤y≤pmpaddri</p><p>当第0个PMP entry的A字段为TOR，其所控制的地址空间的下界被认为是0，也就是匹配所有满足 0≤y≤pmpaddr0</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/14.png" alt="image-20200919193458254"></p><p>L bit：锁定PMP entry。</p><p>当L bit=1时，对内存区域的访问将会应用在所有的privilege modes。（U, S, M模式都必须遵循配置寄存器的权限设置）</p><p>当L bit=0时，符合PMP entry的M-mode访问都会成功；S和U模式下需要遵循配置寄存器中的权限设置。</p><h3 id="7-1-物理内存保护以及分页"><a href="#7-1-物理内存保护以及分页" class="headerlink" title="7.1 物理内存保护以及分页"></a>7.1 物理内存保护以及分页</h3><p>通过S mode去对页表访问是最有效的。</p><p>当装有页表或者是指向page table的physical memory发生改变时，M-mode的软件必须在virtual memory system中同步PMP设置。这部分是通过SFENCE.VMA指令（rs1=x0, rs2=x0）来完成的。</p><h3 id="7-2-waymasking"><a href="#7-2-waymasking" class="headerlink" title="7.2 waymasking"></a>7.2 waymasking</h3><p>对waymasking的理解是通过waymask寄存器来允许特定的master访问某些way</p><p>waymaskX registers：仅影响分配，仍然可以尝试读取被masked的ways。</p><p>有16个waymaskX寄存器，分别是waymask0-waymask15，waymaskX register表示的是该L2 cache能够被master X驱逐。</p><p>在enclave执行过程中，只有enclave physical memory中的enclave lines会在对应的cache partition中，所以就会被PMP保护。</p><p>（我觉得目前，可能是直接把8个分区，比如0-7直接分给了keystone。如果一个时刻只有一个enclave运行的话，这些分区就不需要再细分。FU540中一共分了8个pmp entry，在waymasking的master这边有8个chiplink domain，可能就是一一对应的关系）</p><p>比如设置WayMask0[2].RW = 0x1，就表示enable way2 for Master0</p><p><img src="/2021/01/29/2021-01-29-keystone-2020/15.png" alt="image-20200920163932004"></p><p><img src="/2021/01/29/2021-01-29-keystone-2020/C:%5CUsers%5Crww%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200920164733863.png" alt="image-20200920164733863"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Keystone论文的精读笔记~&lt;/p&gt;
    
    </summary>
    
      <category term="Keystone" scheme="http://yoursite.com/categories/Keystone/"/>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="RISC-V" scheme="http://yoursite.com/tags/RISC-V/"/>
    
      <category term="Keystone" scheme="http://yoursite.com/tags/Keystone/"/>
    
  </entry>
  
  <entry>
    <title>CITM CCS20</title>
    <link href="http://yoursite.com/2021/01/29/2021-01-29-CIMT/"/>
    <id>http://yoursite.com/2021/01/29/2021-01-29-CIMT/</id>
    <published>2021-01-28T16:00:00.000Z</published>
    <updated>2021-01-29T14:38:34.718Z</updated>
    
    <content type="html"><![CDATA[<p>Cache-in-the-Middle (CITM) Attacks : Manipulating Sensitive Data in Isolated Execution Environments的精读笔记~</p><p>这篇论文是我在组会讲解的第一篇论文，也很感激第一篇讲的是这篇，因为这篇完全就是中国人写的感觉，推荐阅读原文，非常好读懂</p><a id="more"></a><p>TrustZone的制造商希望通过约束安全世界中的第三方应用程序的安装来最小化可信计算基（TCB）,但是第三方的开发人员更希望能够在安全世界中自由地安装自己的应用。</p><p><strong>解决方法</strong>：在普通世界中构造了一个Isolated Execution Environment（IEEs）来保护安全敏感的应用程序。</p><p><strong>本文所完成的工作：</strong>针对IEE的数据保护模型（data protection models)和ARM cache属性（cache attributes），发现了三种基于cache的漏洞（CITM 漏洞），这些漏洞能够被用来操纵保护在IEE内部的敏感数据。</p><p>另外，由于映射到IEE内存中的缓存的安全措施的低效和不连贯的，普通世界中的攻击者能够通过以下几点措施降低IEE数据的安全性：</p><p>1）并发执行；</p><p>2）在安全敏感的应用程序被suspend或者终止（finished）时绕过强制的安全措施；</p><p>3）在IEE上下文切换进程中国措施使用不完整的安全措施。</p><p><strong>完成的工作：</strong></p><p>1）作者通过在一些著名的IEE systems中，包括SANCTUARY，Ginseng和TrustICE进行案例研究揭示了CITM漏洞的广泛存在；</p><p>2）CITM漏洞是能够在硬件测试床上利用的</p><p>3）分析导致CITM的漏洞的根本原因，并提供了解决对策。</p><p>实验证明我们的防御测试具有一个很小的开销。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>IEEs的主要思想是通过一个安全世界中的trusted reference monitor确保只有授权的IEE app能够访问IEE敏感资源。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200824180749550.png" alt="image-20200824180749550"></p><p>Ginseng：在普通世界中构造第三方应用程序，同时避免部署安全世界中的application-specific logic（ Ginseng [55] constructs the IEEs to protect secrets of third-party applications in the normal world without deploying any application-specific logic in the secure world.这段的意思是否是不依赖于安全世界中的特殊逻辑）</p><p>SANCTUARY：将它的IEEs定位在per-core环境中来保护IEE指定的内存（避免这些受保护的内存被其他非安全的内核访问）</p><p>TrustICE：通过IEE monitor动态控制IEE memory的安全属性来保护IEE内存。</p><p><strong>攻击方法</strong></p><ul><li>攻击者在并发执行中通过cross-core缓存操作操纵IEE数据；（侧信道攻击？）（在多核系统上，仅仅core-wise的隔离是无法保证安全的，因为缓存是允许cross-core的访问，因此能够被攻击者利用）–》针对Sancutary</li><li>通过将不安全的缓存映射到用于安全措施的IEE内存中来绕过switch out操作后的安全防护操作；–》针对Ginseng</li><li>针对动态控制内存的安全属性的方法，作者认为在switch out过程中能够窃取敏感IEE数据，而在switch in的过程中可以伪造IEE数据。–》针对TrustICE</li></ul><p>本文指出了为了确保IEE数据的安全性，除了内存以外，保护缓存安全的重要性。</p><p><strong>根本原因</strong></p><ul><li>缓存和内存安全属性的非相关性（这个非相关性如何理解？）</li><li>缓存和内存读写操作的不同步</li></ul><p><strong>本文工作</strong></p><ul><li>为IEE内存安全配置cache attributes</li><li>在进行上下文切换时，清除cache mapping to the IEE 内存（难道其他三个没有进行这步的操作吗？）</li></ul><p><strong>名词解释</strong></p><p>switch out：从IEE到untrusted rich OS的上下文切换，switch out之前是secure的</p><p>switch in：逆过程。switch in之前是non-secure的</p><p>cross-core cache：意味着这个cache是被多个核共享的，比如l2 cache</p><h2 id="2-背景知识"><a href="#2-背景知识" class="headerlink" title="2 背景知识"></a>2 背景知识</h2><p>L1-cache被进一步分为 I-cache（指令cache）和D-cache（数据cache）</p><p>L1-cache和L2-cache都被配置为N-way Set Associative cache。</p><p>全部的cache空间被分为N equally-sized块，也就是N路，每一路用k cache lines进行索引，每个cache line是一个数据单元。内存被分块成大小为一个cache line的多个数据块。j = i mod k</p><p>inner cacheability domain–&gt;L1 cache</p><p>outer cacheability domain–&gt;L2 cache</p><p>cacheability domain’s attributes:</p><ul><li>non-cacheable：内存上的任何读写操作都不会经过该cacheability domain；</li><li>write-through：在当前的cache上进行的写操作会立刻被传送到下一级别的storage；（L1 cache上的读写会被forwarded 到L2 cache——》主存）</li><li>write-back：当前cache上的改变暂存在缓冲区中，当被驱逐时写入下一级的存储部件中</li><li>write-allocate：当进行写操作时出现cache miss，该写结果将会被分配一个新的cache line，如果write-allocate未被设置，cache-missed write会对next level storage进行修改</li></ul><p>invalidation指令：储存在cache中的数据全部失效；</p><p>cleaning指令：将目标缓存上的内容强制写入下一级存储设备或者主存</p><h2 id="3-Threat-Model"><a href="#3-Threat-Model" class="headerlink" title="3 Threat Model"></a>3 Threat Model</h2><p>normal world中的rich OS是不可信的；</p><p>攻击者具有root权限，目的是破坏IEE中的敏感数据的机密性和完整性；</p><p>TrustZone能够提供normal world和secure world之间的安全隔离，安全世界中运行的app是可信的，并且是不会被rich OS降低安全性的；</p><p>安全敏感的app在IEE中运行，不会故意泄露信息。</p><h2 id="4-CITM漏洞"><a href="#4-CITM漏洞" class="headerlink" title="4 CITM漏洞"></a>4 CITM漏洞</h2><h3 id="4-1-IEE数据保护模型"><a href="#4-1-IEE数据保护模型" class="headerlink" title="4.1 IEE数据保护模型"></a>4.1 IEE数据保护模型</h3><p>本部分介绍IEE中的两种数据保护模型。</p><p>（1）安全敏感app能够和不可信app同时运行在normal world中的两个或多个core中。（在安全敏感app执行时，不可信app是可以运行的）</p><p>当安全敏感app在normal world中的一个核上运行时，不可信进程可以同时运行在不同的核或者以分时的状态（in a time-sharing manner）运行在相同的内核中。该模型的安全措施：–》SANCTUARY&amp;Ginseng</p><ul><li>在并发执行时，敏感app使用core-isolated storage（不允许其他core访问的内存或者说是core上的寄存器）传递隐私数据；</li><li>在敏感app suspend或者执行结束时，它core-isolated storage中的所有的隐私数据会在switch out过程中被清除；</li><li>在安全敏感的app重新运行时，在switch in过程中由IEE monitor负责恢复或者分配新的core-isolated storage</li></ul><p>（2）不可信进程不被允许同时和安全敏感 app运行在normal world中。</p><p>在normal world中的任何时间，所有的core只能同时运行安全敏感的app或者是不可信进程。但是在IEE进行上下文切换的过程中，仍然需要继续安全操作。除了在model中介绍的措施外，还需要配置：</p><ul><li>在switch out进程中，对于normal world来说，IEE内存无法被访问；</li><li>在switch in进程中，允许normal world对IEE内存的访问。</li></ul><h2 id="4-2-CITM-Attack-Types"><a href="#4-2-CITM-Attack-Types" class="headerlink" title="4.2 CITM Attack Types"></a>4.2 CITM Attack Types</h2><p>当不可信rich OS操纵normal world中的cache时，两种数据保护模型的安全性都将被降低。从攻击者的角度，可以从两个方面进行攻击：</p><ul><li>manipulating the core-isolated memory (在并发执行中)</li><li>篡改IEE的上下文切换</li></ul><h3 id="漏洞1：在并发执行时操纵core-isolated内存"><a href="#漏洞1：在并发执行时操纵core-isolated内存" class="headerlink" title="漏洞1：在并发执行时操纵core-isolated内存"></a>漏洞1：在并发执行时操纵core-isolated内存</h3><p>在多核系统上，与安全敏感的app并发执行的恶意OS可以通过操纵normal world中的cache来窃取或者修改core-isolated 内存中的IEE数据。因为安全敏感的APP运行在normal world中，而它相应的cache line被标记为non-secure，所以能够被不可信rich OS操纵。（伪造页表，用一个物理地址指向一个core-isolated memory page，恶意OS能够通过访问相应的虚拟地址操纵它的cache line）</p><p>产生的原因：ARM平台提供了保证memory isolation的硬件特性，但缺少相应的针对cache isolation的特性。（比如，TZC-400的Identity-based Filtering features可以用于隔离内存，但不能保证cache的隔离）</p><h3 id="漏洞2：在IEE的switch-out过程中绕过安全措施"><a href="#漏洞2：在IEE的switch-out过程中绕过安全措施" class="headerlink" title="漏洞2：在IEE的switch out过程中绕过安全措施"></a>漏洞2：在IEE的switch out过程中绕过安全措施</h3><p>switch in过程是IEE monitor在secure world中完成的，所以被cache line被配置为secure，所以是很难绕过安全检查并利用，但是switch out不管是由normal world还是secure world中的IEE执行，都是可以绕过安全操作的。</p><p>memory cleaning是在normal world中被执行的，相应的cache line是non-secure的，所以有可能通过控制non-secure cache限制cache中的内存写操作或者保持内存不变。比如，当内存被设置为write-back，write-allocate时，所有的内存写都会被暂存在缓冲区中直到cache set被驱逐。攻击者通过使用lockdown技术阻止cache eviction，进而直到敏感app被悬挂或者终止时，隐私数据都没有被安全地写入IEE内存。</p><p>当安全措施需要在secure world中执行时，IEE需要在不涉及rich OS的情况下将控制权转移到secure world中的IEE monitor。从normal world到secure world的上下文切换是由rich OS kernel中的Secure Monitor Call（SMC）高特权指令完成的。SMC是无法由进程或者app直接触发的，所以安全敏感app通过故意访问secure memroy来故意触发一个external abort。但是只要是在normal world中被访问，安全内存所被映射的cache lines就是non-secure的。（即使是secure world中的secure memory，一旦被normal world中的non-secure cache 映射了，就会变成non-secure），OS就会操纵相应的cache lines来绕过上下文切换和安全措施（data cleaning）。</p><h3 id="漏洞3：IEE-cache上下文切换时不完整的安全措施"><a href="#漏洞3：IEE-cache上下文切换时不完整的安全措施" class="headerlink" title="漏洞3：IEE cache上下文切换时不完整的安全措施"></a>漏洞3：IEE cache上下文切换时不完整的安全措施</h3><p>某些IEE系统在上下文切换中的内存保护是通过动态控制IEE内存的安全属性来完成的（TrustICE）（在switch in过程是不安全的，在switch out过程是安全的）</p><p>switch out阶段不合适的cache cleaning可能会导致IEE data leakage；有害数据可能在switch in阶段被加载入安全敏感的APP。漏洞3是由于cache上不完整的安全措施，而漏洞2是在上下文切换的时候绕过安全检查。</p><p>Model1–》3种漏洞</p><p>Model2–》2和3</p><p>漏洞1,2–》当内存用于存储IEE数据，能够被利用（为什么？）</p><p>漏洞3–》只有在IEE执行switch out的安全措施使才有此要求</p><h2 id="4-3-Cache-lockdown技术"><a href="#4-3-Cache-lockdown技术" class="headerlink" title="4.3 Cache lockdown技术"></a>4.3 Cache lockdown技术</h2><p>cache lockdown：允许程序加载代码和数据到cache中，并标记它们不被eviction（驱逐）–》提高更快的系统反应速度，减少执行时间</p><p>但是CITM中的漏洞2可以利用该lockdown技术，将cache中针对内存的写操作锁住，从而使memory-cleaning操作无效。</p><p>实现cache lockdown的三个方法：</p><ul><li>一些ARM开发板允许用户通过配置L2 auxiliary cache control register来lock L2 cahce ways。–》ARMv8处理器目前已经不支持该基于硬件的locking control 寄存器；</li><li>攻击者将自己控制的内存区域设置为outer cacheable，其他内存区域全部设置为outer non-cacheable，从而独占L2缓存–》huge overhead</li><li>更细粒度地控制内存页面的缓存属性从而独占L2缓存</li></ul><p>相同编号的blocks构成了一个page cache set，攻击者将想要控制的内存页面标记为outer cacheable，其他标记为non-cacheable。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200825222106254.png" alt="image-20200825222106254"></p><p>page1和page6分享相同的page cache set，page1设置为cacheable，而page6被设置为non-cacheable（这边即使是修改了page1，由于page1没有被驱逐，所以page1的修改不会被写入到内存中）</p><p>本文选择了使用第三种方法，针对L2 cache实施了cache lockdown。</p><h2 id="5-case-study-of-CITM-attacks"><a href="#5-case-study-of-CITM-attacks" class="headerlink" title="5 case study of CITM attacks"></a>5 case study of CITM attacks</h2><p>SANCTUARY实际上是在ARM fast models virtualization tools上完成的，本文作者在i.MX6Quad开发板上模拟了SANCTUARY的cache操作，Ginseng在HiKey620开发板，TrustICE在i.MX6Quad SABRE开发板上实现。</p><h3 id="5-1-SANCTUARY：操作L1-cache"><a href="#5-1-SANCTUARY：操作L1-cache" class="headerlink" title="5.1 SANCTUARY：操作L1 cache"></a>5.1 SANCTUARY：操作L1 cache</h3><p>每个IEE运行在拥有core-isolated内存的core中，并且每次运行时IEE不会被其他core干扰。</p><h4 id="5-1-1-SANCTUARY的数据保护机制。"><a href="#5-1-1-SANCTUARY的数据保护机制。" class="headerlink" title="5.1.1 SANCTUARY的数据保护机制。"></a>5.1.1 SANCTUARY的数据保护机制。</h4><p>switch out：当IEE结束运行，隐私数据将会被IEE中的微内核清除（向受保护的core-isolated memory中写入全0，并使L1 cache无效）（L2cache在SANCTUARY中被禁止给core-isolated的内存使用）</p><p>switch in：在启动IEE之前，secure world中的IEE monitor将会为IEE建造一个干净的环境。在敏感app加载之前，L1 cache也会被invalided。</p><p>由于在switch in和switch out过程中，core-isolated memory和L1 cache都被安全地清空，所以对于漏洞3是免疫的。由于data cleaning操作是被IEE中的微内核完成的，所以对于漏洞2也是免疫的。如果想要绕过data cleaning，那么就必须锁住L1 cache，但是L1 cache的eviction是由该内核以及core-isolated内存页表的cache属性决定的，攻击者无法通过操纵另一个内核来控制eviction。（core-isolated内存的cache属性是由IEE中的微内核来控制和保护的）</p><p>SANCTUARY给每个内核分配一个独特的Non-Secure Access IDentifier(NSAID)，并且通过配置TZC-400给每个CPU（根据NSAID）分配独立的内存区域。ARM平台上的NSAID都是相同的，所以这部分是在ARM的快速模型虚拟化工具上来完成的。</p><p>受保护的内存区域通过配置cache属性为outer non-cacheable来避免缓存到L2 cache中，而L1 cache一般位于每个内核的内部，不会直接被其他内核访问，但除此之外，SANCTUARY就没有在并发执行时给予其他的保护。</p><h4 id="5-1-2-SANCTUARY中的漏洞"><a href="#5-1-2-SANCTUARY中的漏洞" class="headerlink" title="5.1.2 SANCTUARY中的漏洞"></a>5.1.2 SANCTUARY中的漏洞</h4><p>通过调研，作者发现了名为shareability的缓存特性，该特性能够通过操作一个内核的L1 data cache进而读/写另一个内核的L1 data cache。–》缓存的一致性</p><p>inner shareability domain：在一个cluster中的core的数据一致性（一个cluster表示one group of cores）</p><p>outer shareability domain：所有的cluster的core的数据一致性</p><p>当处理器运行在Symmetric Multi-Processing(对称多核处理器，SMP)模式时，shareability属性将会被配置。（SMP模式在多核平台中是默认设置的）当shareability属性被设置，Snoop Control Unit（窥探控制单元，SCU）会通过处理直接的核之间cache-to-cache转移来保证数据一致性。如果设置为inner shareable，在某个内核中的L1 data缓存中的某个值的修改会同步到该簇上其他内核的L1数据缓存。但是non-secure cache中的数据不会扩散到secure cache。</p><p>结论：当内核都运行在normal world中，访问相同的物理内存地址，并且该物理内存的内存页表的缓存属性都是inner shareable或者outer shareable时，某个内核上的L1数据缓存可能会被另一个内核上的L1数据缓存读取或者篡改。（当设置为non-shareable时，就不会被窃取或者篡改）</p><p>（IEE能否去将SANCTUARY所在内核的内存页表的缓存属性设置为non-shareable）</p><h4 id="5-1-3-攻击过程"><a href="#5-1-3-攻击过程" class="headerlink" title="5.1.3 攻击过程"></a>5.1.3 攻击过程</h4><p>首先，为core1构造一个page table entry，将它的物理页表的缓存属性设置为shareable，并将它的物理地址指向core0的内存页。接下来，进入core1中对应的虚拟地址，core0中的L1数据缓存中的隐私数据就能够通过shareability属性被窃取或者修改。</p><p>（这边有个问题是：一个内存能否被两个内核共同访问吗？making its physical address point to a memory page of core_0）</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826093249629.png" alt="image-20200826093249629"></p><p>对IEE内存范围的获取是通过排除法，排除已知的不可信内存，而TEE内存是secure的，IEE内存是non-secure的，对TEE内存的访问会返回0或者触发中断，在读取IEE内存时当内存数据在cache中缓存时，是会得到真实的数据值的，虽然cache要比内存小很多，但经过多次探测，也能确定IEE内存的地址范围。</p><h3 id="5-2-Ginseng：映射到不安全的缓存"><a href="#5-2-Ginseng：映射到不安全的缓存" class="headerlink" title="5.2 Ginseng：映射到不安全的缓存"></a>5.2 Ginseng：映射到不安全的缓存</h3><p>Ginseng是在多核平台上保护选定功能的敏感数据的IEE系统。为了避免被同时运行的有害OS攻击，Ginseng选择将敏感数据仅存放在寄存器中，而不是core-isolated内存，所以这就对漏洞1免疫。另外，由于寄存器中的数据不经过缓存，所以也不受漏洞3的影响。</p><p>Ginseng在switch out过程中依赖于secure world中的TEE monitor来执行data cleaning操作。（因为IEE中的rich OS是不可信的，所以需要借助于TEE）通过试图访问TEE中的安全内存来触发一个安全中断，从而由IEE进入TEE。但是secure memory所映射的缓存是non-secure的，通过操纵该缓存，可以阻止从IEE到TEE monitor的控制流切换，从而绕过data cleaning操作。</p><h4 id="5-2-1-数据保护措施"><a href="#5-2-1-数据保护措施" class="headerlink" title="5.2.1 数据保护措施"></a>5.2.1 数据保护措施</h4><p>Ginseng提供了一个编译器，通过静态污点分析识别携带隐私数据的变量，并将它们保存在寄存器中。包含隐私数据的函数将会被判定为隐私函数，在退出前要进行代码完整性检查。</p><p>Ginseng引入了六种安全的API函数，用于将控制流从normal world中的用户空间直接转移到GService（Ginseng中的IEE monitor）</p><ul><li>ss_write(),ss_read()：用于和GService安全通信</li><li>其余四种被编译器自动插入到程序中，</li><li>ss_saveCleanv()：被插入在敏感函数中的每次函数调用之前，用于加密隐私数据，将加密后的数据保存在内存中，并清除相应的寄存器</li><li>ss_readV()：被插入在敏感函数的每次函数调用之后，解密隐私数据，并恢复这些数据在寄存器中</li><li>ss_start()：被插入在每个敏感函数的开始，用于进行诸如代码完整性检查等准备工具</li><li>ss_end()：插入在敏感函数的末尾，清楚寄存器中的数据防止数据泄露。</li></ul><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826140050212.png" alt="image-20200826140050212"></p><p>当需要GService进行安全敏感操作时，需要从normal world中的用户空间上下文切换到运行在secure world中的GService。cross-world的上下文切换是通过SMC指令来完成的。通过配置TZASC，每个API函数被分配了一个独特的安全内存，调用一个安全的API函数将会触发一个security violation，因为它试图在普通世界读取安全内存。</p><p>在处理该violation时，处理器会在normal world中发出一个external abort（EA）, GService在Secure Configuration Register中设置了external abort比特位，所以GService无需kernel的参与就可以直接处理EA和secure API发出的请求。</p><h4 id="5-2-2-Ginseng中的type-II-攻击"><a href="#5-2-2-Ginseng中的type-II-攻击" class="headerlink" title="5.2.2 Ginseng中的type II 攻击"></a>5.2.2 Ginseng中的type II 攻击</h4><p>ss_saveCleanv首先加载__channel_save_clean的地址（指向ss_saveCleanv函数的安全内存的虚拟地址）到寄存器4中，然后将该地址为x4的安全内存中的数据加载到寄存器x0中。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826161849045.png" alt="image-20200826161849045"></p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826160551699.png" alt="image-20200826160551699"></p><ol><li>当执行“安全内存加载”指令（第18行），处理器首先会尝试去缓存中加载数据；</li><li>由于缓存中不会存放敏感数据，所以应是cache miss；cache根据提供的地址去secure memory中获取数据；</li><li>由于是从normal world中尝试去访问secure world中的数据，所以会触发一个external abort，该EA被GService捕获；</li><li>GService根据该安全API的要求，加密敏感数据并清除相应的寄存器；</li><li>控制流回到secure API ss_saveCleanV()；</li><li>调用非敏感函数insensitive_func()</li></ol><p>其中，1中的cache是non-secure cache，这儿可以被攻击者利用。</p><p>在HiKey620开发板（8-core ARM Cortex-A53 processor）上实现了原型系统</p><p>攻击过程就是红线描述的过程，最重要的是其中的步骤0</p><p>步骤0在缓存中填充了映射secure memory的缓存行，这样在步骤1的时候就会cache hit，那么步骤2-5都不会执行，就直接执行了步骤6中的insensitive function。而insensitive_func()可能会被攻击者利用读取未被清零的敏感寄存器，insensitive function和sensitive function都运行在相同的内核中，但缺少了安全检查。所以，我们可以通过修改libc.so库利用printf()函数来读取寄存器中的隐私数据，比如说keys。</p><p>接下来详细阐述cache0的攻击过程：writeSM是用于向cache中写入__channel_save_clean（ss_saveCleanV()的安全内存）的函数。</p><ol><li>__channel_save_clean的虚拟地址被加载到寄存器x4中；</li><li>由于__channel_save_clean的虚拟地址-物理地址映射被保存在rich OS内核中，攻击者可以很容易地获得它的物理地址；</li><li>将寄存器x0中的数据保存到地址值为x4的安全内存。该数据会被首先写入到安全内存__channel_save_clean的缓存中，因为Ginseng中的安全内存被设置为write-back和write-allocate，所以数据会被暂时存放在缓存中，直到缓存满了之后才被驱逐。</li><li>作者利用lockdown技术将映射到同一个page cache set的内存页表设置为outer non-cacheable（阻止缓存到l2缓存中）。</li></ol><p>通过在ss_saveCleanV()之前调用writeSM函数，本文作者成功实现了绕过GService中的安全保护。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826170916865.png" alt="image-20200826170916865"></p><h3 id="5-3-TrustICE：不完整的cache-cleaning"><a href="#5-3-TrustICE：不完整的cache-cleaning" class="headerlink" title="5.3 TrustICE：不完整的cache cleaning"></a>5.3 TrustICE：不完整的cache cleaning</h3><p>TrustICE是在一个单核平台上实现的IEE系统，安全敏感app运行在包含一个用户程序和一个微内核的IEE中，该app不会受到rich OS的干扰。</p><h4 id="5-3-1-数据保护措施"><a href="#5-3-1-数据保护措施" class="headerlink" title="5.3.1 数据保护措施"></a>5.3.1 数据保护措施</h4><p>TrustICE静态地将物理内存分成了三个分离的区域给normal world中的rich OS，normal world中的IEE和secure world中的Trusted Domain Controller（TrustICE中的IEE monitor）。隐私数据保护是通过动态配置IEE内存的安全属性完成的。</p><ul><li><p>当系统boot up时，可信区域控制器设置IEE内存为安全的。</p></li><li><p>在新建一个IEE之前（switch in），可信区域控制器从IEE内存中给该IEE分配一块内存空间，并将其属性设置为non-secure。</p></li><li><p>当IEE结束运行时（switch out），IEE中的微内核通过调用SMC指令将当前控制流直接转移到secure world。在将控制权转交给rich OS之前，可信区域控制器将配置相应的IEE内存空间为secure。</p></li></ul><h4 id="5-3-2-TrustICE中的type-III-攻击"><a href="#5-3-2-TrustICE中的type-III-攻击" class="headerlink" title="5.3.2 TrustICE中的type III 攻击"></a>5.3.2 TrustICE中的type III 攻击</h4><p>TrustICE遵从了model2，所以对漏洞1来说是免疫的。</p><p>当malicious OS运行时，IEE内存被设置为secure；当security-sensitive app退出时IEE被设置为non-secure。在switch out过程中，通过动态配置IEE内存为secure，保证数据的安全性。该保护是无法绕过的，因为这是通过在secure world中调用SMC指令强制将控制流从IEE中的微内核转移到secure world。所以不受漏洞2的干扰。</p><p>虽然在上下文切换的过程中，内存得到了严格的保护，但相应的缓存还是non-secure的，并且没有被完全清理干净，因此，可以利用漏洞3。</p><h4 id="5-3-3-攻击过程"><a href="#5-3-3-攻击过程" class="headerlink" title="5.3.3 攻击过程"></a>5.3.3 攻击过程</h4><p>在normal world中构造一个页表条目，该页表条目的的物理地址指向IEE内存页，并且该内存页的cache属性被设置为write-back和write-allocate。</p><p>switch out：由于TrustICE并不会去清除缓存行中的数据，所以能够访问残留在对应缓存行的残留数据</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826210642807.png" alt="image-20200826210642807"></p><p>switch in：rich OS根据IEE内存页向缓存中写入malicious data，并使用lockdown技术锁住这些缓存行。当IEE执行时，它首先读到的是被污染后的缓存行，而不是IEE内存页中的合法数据。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826210712579.png" alt="image-20200826210712579"></p><h2 id="6-应对措施"><a href="#6-应对措施" class="headerlink" title="6 应对措施"></a>6 应对措施</h2><p>本文作者通过配置IEE内存中的缓存属性以及在进行上下文切换时清除IEE内存来消除CITM漏洞。</p><h3 id="6-1-抵御措施"><a href="#6-1-抵御措施" class="headerlink" title="6.1 抵御措施"></a>6.1 抵御措施</h3><p>产生CITM漏洞的主要原因在于缓存和主存这两级内存架构之间的不连贯性。</p><p>漏洞1的原因：内存隔离并不能自动确保缓存隔离。比如在SANCTUARY中，当一个特定内核的内存区域通过TZC-400的identity-based filtering features获得了一块独立的内存区域，相应的L1缓存仍然能够在内核之间共享。</p><p>解决方法：将该core-isolated内存的cache属性设置为outer non-cacheable，non-shareable。</p><p>漏洞2产生的主要原因：内存和缓存中的读写操作是不同步的。Ginseng中的cross-world的切换就通过限制安全缓存中的读写绕过了。预加载并提前将恶意数据锁定在对应于secure memory的缓存中，IEE在读取安全内存时也会先hit预加载的恶意花奴才能。</p><p>解决方法：使内存和缓存中的读写同步。可以将IEE内存中cache属性设置为write-through,non-write-allocate.</p><p>漏洞3：缓存行是被自动设置的，当被一个运行在normal world中的内核访问时，该缓存行就被定义为non-secure；反之，如果被一个运行在secure world中的内核访问时，该缓存行就被定义为secure。所以，在TrustICE上完成的CITM攻击是通过在switch out之后读取IEE内存的non-secure缓存，并且在switch in之前在non-secure缓存中写入并锁定恶意数据。</p><p>解决办法：在switch in和switch out过程中清除缓存行，那么攻击者就不会读取缓存中残留的数据或者是在缓存中留下恶意数据。</p><p>综上所述，CITM漏洞可以通过以下几点来进行消除：</p><ul><li>配置IEE内存的页表属性为inner write-through non write-allocate,outer non-cacheable, non-shareable</li><li>在进行上下文切换时清除IEE内存对应的缓存。缓存清除可以通过调用IEE中的invalidation和cleaning指令来完成。在switch in中调用invalidation来保证cache的干净，在switch out中调用cleaning来同步cache和内存的数据，接着调用invalidation来清除cache数据。</li></ul><h3 id="6-2-defense-overhead"><a href="#6-2-defense-overhead" class="headerlink" title="6.2 defense overhead"></a>6.2 defense overhead</h3><p>设备：i.MX6Quad SABRE开发板（quad-core ARM Cortex-A9处理器 at 1.2GHz with 1GB DDR3 SDRAM)</p><p>强制缓存属性的情况，在一个IEE中运行一个AES加密app</p><p>第一列是大部分的IEE，第三列是本文中介绍的defense系统，由于关闭了L2，所以导致开销达到了90%，但是和同样关闭了L2的SANCTUARY相比，开销是忽略不计的。而第三列是开启了L2的defense系统，与第一列的开销类似。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826225035890.png" alt="image-20200826225035890"></p><p>评估在rich OS中引入额外的cross-domain上下文切换，该上下文切换针对针对页表更新操作。相比较没有进行保护时，仅有2.65%的额外开销。</p><p>数据库的I/O操作需要17.74%是由于从硬盘到内存的数据拷贝需要修改一堆页表映射。</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826225341791.png" alt="image-20200826225341791"></p><p>在涉及到频繁的页表更新操作时的开销，所有的开销都小于10%</p><p><img src="/2021/01/29/2021-01-29-CIMT/image-20200826230608632.png" alt="image-20200826230608632"></p><h2 id="7-讨论"><a href="#7-讨论" class="headerlink" title="7 讨论"></a>7 讨论</h2><p>intel SGX：对于SGX来说，CITM攻击是无效的。因为SGX中的敏感信息都放在EPC（enclave page cache）上。EPC的页表和对应的缓存只能由运行着enclave的处理器来访问（避免恶意OS对缓存行的操纵）。并且，每个EPC页只会被分配给一个enclave。（避免另一个恶意enclave对EPC页缓存行的访问）–》该解决方法搭载在intel架构上，而移动设备往往是使用的arm处理器</p><p>基于虚拟化的解决办法：ARMv7中引入了hyp CPU模式，该模式运行在一个高特权的hypervisor中，一般认为该hypervisor是安全且可信的。在利用该hypervisor的解决办法中，IEE内存通过两个阶段的地址转换机制来进行管理。第一步，是由OS内核来完成的，将虚拟地址转化成一个intermediate physical address（过渡物理地址，IPA）。在第二阶段，由hypervisor将IPA进一步转化成一个真正的物理地址。为了抵御恶意OS，hypervisor通常会根据IPA到PA的映射来进一步确认分配给IEE和rich OS的隔离物理地址空间。–》依赖于一个可靠的hypervisor，本文的TrustZone-based IEE系统基于一个secure world中的small-sized的IEE来保护安全敏感程序免受normal world中的不可信os和hypervisor的攻击。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Cache-in-the-Middle (CITM) Attacks : Manipulating Sensitive Data in Isolated Execution Environments的精读笔记~&lt;/p&gt;
&lt;p&gt;这篇论文是我在组会讲解的第一篇论文，也很感激第一篇讲的是这篇，因为这篇完全就是中国人写的感觉，推荐阅读原文，非常好读懂&lt;/p&gt;
    
    </summary>
    
      <category term="TrustZone" scheme="http://yoursite.com/categories/TrustZone/"/>
    
    
      <category term="TrustZone" scheme="http://yoursite.com/tags/TrustZone/"/>
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="System Security" scheme="http://yoursite.com/tags/System-Security/"/>
    
  </entry>
  
  <entry>
    <title>SoK S&amp;P20</title>
    <link href="http://yoursite.com/2021/01/29/2021-01-29-SoK-TrustZone/"/>
    <id>http://yoursite.com/2021/01/29/2021-01-29-SoK-TrustZone/</id>
    <published>2021-01-28T16:00:00.000Z</published>
    <updated>2021-01-29T13:31:27.346Z</updated>
    
    <content type="html"><![CDATA[<p>S&amp;P2020中关于TrustZone的SoK精读笔记~</p><a id="more"></a><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li>understand which types of vulnerabilities and limitations affect existing TrustZone-assisted TEE system(威胁现存TrustZone支持下的漏洞和限制类型)</li><li>正确构建的challenges</li><li>现有研究中可以消除这些威胁的贡献</li><li>在研究了Qualcomm, Trustonic, Huawei, Nvidia, Linaro的TrustZone-TEE系统在publicly documented exploits和vulnerabilities和对TEE固件进行的逆向分析，定义了值得关注的关键vulnerabilities。</li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>对ARM Cortex-A设备中的TrustZone-assisted TEE公开的漏洞进行了系统性的研究（已公开的安全问题报告大多分散而且unverified，无法获得一个全面的理解）</p><ul><li>针对这样的问题，本文作者研究了从2013年到2018年的207个TEE bug，主要是Qualcomm, Trustonic, Huawei, Nvidia, 和Linaro五家主要生产厂家的TEE设备。</li><li>对这些漏洞检查并进行分类</li><li>通过分析和对TEE硬件manual analysis，获得了对产生existing vulnerabilities的不同的insights，并且有potential solutions 来缓解这些漏洞</li></ul><p>作者观察得到的问题：</p><ul><li>TEEs系统大多具有着critical implementation bugs (包括classic input validation errors，such as buffer overflows)</li><li>TrustZone<strong>架构的缺陷</strong>也催生了针对vulnerable TAs的利用。(在现代操作系统中比较常见的比如ASLR或者page guards等memory protection mechanisms在大多数被分析的系统中是缺失的。)TEE系统往往容易暴露a large attack surface，包括能够被TA调用的危险的TEE system calls。</li><li>在架构和微架构层面的TrustZone中的important hardware properties被忽略。（比如说侧信道攻击）</li></ul><p>我们认为，通过采用最新的防御措施，商用TrustZone-assisted TEEs在解决当前的漏洞的情况下会变得更加安全。针对architecture，implementation和hardware issues，提供了对应的解决方法。</p><p><strong>本文的贡献</strong></p><ul><li>对已有的漏洞进行系统的研究</li><li>architectural flaws</li><li>implementation bugs</li><li>hardware elements</li><li>分析main defenses</li><li>将TrustZone与可替代的TEE enabling technologies分析比较</li></ul><h2 id="2-Background"><a href="#2-Background" class="headerlink" title="2 Background"></a>2 Background</h2><p>trusted OS的核心是trusted kernel，为调度和管理TAs提供了基本的OS primitives。</p><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201028105600728.png" alt="image-20201028105600728"></p><p>trusted OS完成</p><ul><li>device drivers for accessing trusted peripherals</li><li>handle cross-world requests through the world switching SMC instruction and shared memory</li><li>implement shared libraries and TEE primitives(remote attestation, trusted I/O, secure storage)</li></ul><p>TEE所包含的组件：</p><ul><li>secure monitor：完成mechanisms for secure context switching between worlds and runs with highest privilege, in protection ring EL3</li><li>TEE bootloader: bootstraps the TEE system into a secure state</li></ul><p>trusted OS, secure monitor, TEE bootloader共同组成了software TCB of a typical TEE system</p><h3 id="攻击TEE-enabled设备"><a href="#攻击TEE-enabled设备" class="headerlink" title="攻击TEE-enabled设备"></a>攻击TEE-enabled设备</h3><ul><li><p>compromise the TEE kernel.</p></li><li><p>compromise the REE kernel.</p><ul><li>一个vulnerable TA可能成为对linux kernel提权的一个跳板。</li></ul></li><li><p>the extent of the problem.</p></li></ul><h2 id="3-Overview"><a href="#3-Overview" class="headerlink" title="3 Overview"></a>3 Overview</h2><h3 id="3-1-研究方法"><a href="#3-1-研究方法" class="headerlink" title="3.1 研究方法"></a>3.1 研究方法</h3><p>在分析商用TEE系统时，遇到了很多问题。</p><ul><li>这些系统都是不开源的</li><li>因为缺少文档，并且采用了代码混淆技术，二进制文件也很难分析</li><li>相同厂家提供的legacy TEE software和TrustZone硬件的多样性和异构性共同存在带来新的复杂性</li></ul><p><strong>攻击模型</strong></p><p>攻击者的目标：</p><ul><li>obtain secrets from the TEE</li><li>obtain secrets from the REE</li><li>escalate privileges to the REE kernel</li><li>escalate privileges to the TEE</li></ul><p>通过以下两种方法从NW访问SMC interface：</p><ul><li>在N-EL1直接获取code execution privileges（允许伪造arbitrary SMC calls）</li><li>在N-EL0间接通过向一些目标TA发出命令。</li></ul><p><strong>分析的TEE系统</strong>：Qualcomm, Trustonic, Huawei, Nvidia(for Nvidia chips), Linaro(OP-TEE)</p><p><strong>数据来源</strong></p><ul><li><p>CVE：搜索相关的关键词，比如TrustZone</p></li><li><p>SVE（Samsung Vulnerabilities and Exposures）</p></li><li><p>SP （S&amp;P）</p></li><li><p>MR（miscellaneous reports available online）网络上可获得的多种报告</p></li><li><p>SC（source code）根据OP-TEE的changelog来分析对安全性问题的修订过程</p></li></ul><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201028164343172.png" alt="image-20201028164343172"></p><p><strong>公开漏洞的分类</strong></p><p>critical（CVSS&gt;9) a compromise of configentiality or integrity in the TEE(对机密性和完整性的损害)</p><p>severe(CVSS[7,9])</p><p>medium(CVSS[5,7])</p><p>low(CVSS[0,5])</p><p><strong>binary analysis</strong></p><ul><li><p>量化每个系统TCB的大小</p></li><li><p>定义特定系统的软件架构（huawei：ARM Trusted Fireware)</p></li><li><p>分析每个TEE实施的memory protection features</p></li></ul><p><strong>threats to validity</strong></p><p>信息不完整的漏洞可能会对分类造成不精确的影响。</p><p>对于那些公开漏洞比较多的系统，需要给出general conclusions。</p><p>仅对公开的漏洞进行分析。</p><h3 id="3-2-观察结果概述"><a href="#3-2-观察结果概述" class="headerlink" title="3.2 观察结果概述"></a>3.2 观察结果概述</h3><p>124个漏洞中的53个被定义为critical，每一个TEE都有被发现non-low severity vulnerability。</p><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201029090631064.png" alt="image-20201029090631064"></p><p>其中，高通被公开的漏洞最多，并不代表高通就是最不安全的，只是研究高通的TEE的研究者很多（类比intel和AMD，虽然intel被爆的漏洞更多，但不代表Intel没有AMD安全，只是研究Intel的安全人员更多）</p><p>还有一个点在于和Linux等系统被公开的漏洞比较，可以看到Linux系统中的critical和severe等级的漏洞占比明显小于TEE，这也可以侧面说明当前TEE开发所采用的方法远远不如其他系统健壮（robust），得到的启发是可以参考这些系统的开发方法。</p><h3 id="3-3-TrustZone-assisted-TEE漏洞的来源"><a href="#3-3-TrustZone-assisted-TEE漏洞的来源" class="headerlink" title="3.3 TrustZone-assisted TEE漏洞的来源"></a>3.3 TrustZone-assisted TEE漏洞的来源</h3><p>architecture：TEE system architecture中存在的缺陷，比如没有使用ASLR的内存保护</p><p>implementation：TEE system’s software中的实现问题，比如buffer overflows</p><p>hardware：考虑的是可能降低TEE安全性的hardware behavior，比如side-channels</p><p>即使有更少的critical and servere漏洞，但Trustonic面临着严重的architectural局限性，漏洞报告揭露了很多critical implementation bugs，很多都和Table I中漏洞本质相同。</p><p>另外，作者还叙述了其他可能未来被利用的bugs，比如 concurrency bugs</p><h2 id="4-Architectural-Issues"><a href="#4-Architectural-Issues" class="headerlink" title="4 Architectural Issues"></a>4 Architectural Issues</h2><h3 id="4-1-Attack-Surface"><a href="#4-1-Attack-Surface" class="headerlink" title="4.1 Attack Surface"></a>4.1 Attack Surface</h3><p><strong>TEE系统运行在TEE kernel space</strong>（driver）</p><p>SW中的drivers：协调对安全敏感设备的访问（用于用户身份验证的指纹传感器，用于安全DRM保护内容安全输出的显示缓存）驱动中往往容易存在很多复杂的bugs，所以不应该运行在TEE kernel space（S-EL1 mode），Trustonic和Nvidia都采用了一个运行在S-EL0中的microkernel架构；而Qualcomm，HUAWEI，Linaro都在S-EL1 mode中。其中，Qualcomm和Linaro采用了单一的结构，所有的priviledged code都运行在kernel space，Huawei将部分trusted OS功能移交给user space。</p><p><strong>wide interfaces between TEE system subcomponents.</strong>（interface）</p><p>参考图1，至少4种守护进程对TrustZone驱动有权限访问（N-EL0-》N-EL1）</p><p>SMC call interface赋予了NW软件访问相当可观数量的TAs——暴露了TEE kernel（N-EL1-》S-EL1）</p><p>TEE kernel给TA提供了很多系统调用（对TEE系统调用的访问权限是粗粒度的）比如，Qualcomm TEE中，TAs具有对所有的system calls非常大的访问权限。（S-EL0-》S-EL1）</p><p><strong>Excessively large TEE TCB.</strong>（TCB）</p><p>TEE系统设计的一个基本原则是需要依赖于一个很小的TCB。</p><p>作者认为，通过进行分析，当前的商用TEE没有遵守这条准则。下表中的TAs是相对保守的，因为一些TAs可能会被动态加载。由于TA通过SMC从NW接受输入，一些潜在的漏洞可能被利用。另外，对比microkernel（seL4)来说，TAs是很大的。</p><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201029200129363.png" alt="image-20201029200129363"></p><h3 id="4-2-普通世界和安全世界之间的隔离"><a href="#4-2-普通世界和安全世界之间的隔离" class="headerlink" title="4.2 普通世界和安全世界之间的隔离"></a>4.2 普通世界和安全世界之间的隔离</h3><p><strong>TA can map physical memory in the NW.</strong></p><p>高效的内存共享会让不同世界之间的数据传输有很小的延迟。一些TEE系统提供的机制可能会很容易被滥用从而导致privilege escalation。</p><p>比如，Qualcomm TEE中的一个trusted OS system call会允许任何TA映射到属于NW的物理内存中。攻击者可能会通过扫描Linux kernel的physical address space来占领一个Android OS，并且patch it从而引入后门（E6）（emmm这个system call也太离谱了，这个call是想直接打破NW和SW的壁垒吗？）</p><p>Trustonic中规定了TA不能任意地读写physical memory（map in or modify），这是通过特定的TrustZone driver来限制的。因此，如果TAs希望在shared memory中交换data volumes，必须向特定的driver TA发出请求。</p><p>samsung中的TIMA（TrustZone-based Integrity Measurement Architecture）机制：a TA driver提供了physical memory的映射，而另一个TA使用该服务来测量system image的完整性。白名单中限制了TA driver可以被TA读写的数目，但这个数目被硬编码成了34，还是很大的。一旦损害了这些TA，攻击者也能很轻易地hijack Android。</p><p><strong>Information leaks to NW through debugging channels.</strong></p><p>TEE debug机制导致从SW到NW的信息泄露。《ATTACKING YOUR TRUSTED CORE: EXPLOITING TRUSTZONE ON ANDROID》中描述的privilege escalation attack利用了一种系统调用，该调用允许TA application将自己的stack trace（堆栈跟踪？）转存到NW的内存区域中。</p><p>应用这种机制，攻击者能够获取GlobalTask的物理内存区域，并利用这些信息实施攻击。</p><h3 id="4-3-内存保护机制"><a href="#4-3-内存保护机制" class="headerlink" title="4.3 内存保护机制"></a>4.3 内存保护机制</h3><p><strong>Absent or weak ASLR implementation.</strong></p><p>TA都被加载到了虚拟地址空间中的固定的地址（0x1000），每个TA都被提供了一个common library，从0x7D01000开始。(我知道他们每个TA初始加载的虚拟地址，有什么作用吗？)-》这样的话，在TA中发现的任何漏洞都能够在不需要决定TA的loading address的情况下进行利用。（问题是，固定的加载地址会带来啥危害吗？我感觉各自的地址空间貌似都是各自的，别的进程应该也看不了吧）</p><p>mcLib中有大量的代码，这也可能会提供a source of gadgets to call functions（类似于rop的原材料？），调用安全OS system calls。</p><p>除了Qualcomm TEE，其他的商用TEE都没有采用ASLR，并且Qualcomm TEE中只有非常小的一部分physical memory（100MB）提供了ASLR。（虽然理论上可以使用64bit的虚拟地址空间，但实际上Qualcomm TEE的地址范围被限制在9bit（512b）攻击者就相对来说比较容易猜出TA的基地址）研究的这些TEE系统并没有使用专门用于TEE kernel的KASLR。</p><p><strong>No stack cookies, guard pages, or execution protection</strong></p><p>Stack cookies: unique values that help detect stack smashing instances and abort the program execution.（一旦溢出了，就停止进程？）</p><p>Guard pages: 对每个进程中的mutable data segments（namely,stack,heap,global data)划定界限，以防止在一个segment中触发overflow来corrupt另外一个段，从而在非法访问时触发故障。（将进程中的数据段划分开来，从而避免某个段中的缓存区移除的影响）</p><p>Execution protection（XP）：阻止程序执行特定的memory regions。比如说使用memory page attributes XN（Execute Never），UXN，PXN（Privileged）</p><p>（这边的主要问题是Trustonic）</p><p>虽然Trustonic提供了secure driver，但是由于缺少stack cookies，导致它非常被利用用来实施缓冲区溢出攻击。它在没有设置guard pages的情况下从TA中的数据段分配globals以及stack。并且，stack在数据段的最后，globals在它之前，这非常容易被利用overflow一个区域到另一个区域。</p><p>huawei啥都没有，作者猜测应该是使用了Micrium µ/OS  用最少的内存保护机制换取一个最优的性能。</p><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201030113819168.png" alt="image-20201030113819168"></p><h3 id="4-4-Trust-Bootstrapping"><a href="#4-4-Trust-Bootstrapping" class="headerlink" title="4.4 Trust Bootstrapping"></a>4.4 Trust Bootstrapping</h3><p><strong>Lack of software-independent TEE integrity reporting.</strong></p><p>Arm TrustZone中缺少将software integrity measurements的结果安全传送给remote third party的硬件机制。验证机制都是由软件来完成的话，会降低安全性，因为所有的信任链上的软件都必须运行在EL3 mode。</p><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201030140016456.png" alt="image-20201030140016456"></p><p><strong>III-supported TA revocation.</strong></p><p>TA 的升级能够修正旧版本的漏洞和其他的错误，提高设备的安全性。TA revocation能够有效避免patched TAs被downgraded。</p><p>TA如果被downgraded就会带来很大的安全隐患。</p><h2 id="5-Implementation-Issues"><a href="#5-Implementation-Issues" class="headerlink" title="5 Implementation Issues"></a>5 Implementation Issues</h2><h3 id="5-1-Validation-Bugs"><a href="#5-1-Validation-Bugs" class="headerlink" title="5.1 Validation Bugs"></a>5.1 Validation Bugs</h3><p>validation bugs: 包含对input或者output values不正确的处理。</p><p><strong>Validation bugs within the secure monitor.</strong> </p><p>一旦在secure monitor中发现了bug，攻击者很容易获得整个设备的控制权。</p><p>通过在SMC call中构造一个输入，攻击者能够向SW memory的任何地方写入一个zero double word。为了降低critical bugs发生的概率，大部分的TEE系统采用了ATF。但不幸的是，ATF中也有critical bugs。举个例子， 下面的代码的本意是为了检测(ptr+inc)是否发生了溢出，但如果input base pointer和offset wrap around，就不会检测出溢出情况。在（伪造的）AArch32中，如果在2的32次方到2的64次方-1的情况下，是不会被判断为溢出的。</p><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201030215959785.png" alt="image-20201030215959785"></p><p><strong>Validation bugs within TAs.</strong></p><p>TEE systems的漏洞报告中占比最大的是与TA相关的validation bugs。</p><p>举个例子：boomerang attacks：vulnerable TA并不会正确验证input memory address，允许攻击者访问NW内存区域并且读写REE apps或者OS的内存。</p><p><strong>Validation bugs within the trusted kernel.</strong></p><p>这边的意思大概是trusted kernel所提供的system call可能会带来风险隐患。（华为的这个例子是说没有任何输入检查，会带来很大的安全隐患）</p><p><strong>Validation bugs within secure boot loader.</strong></p><p>X.509 certificate parser中的stack-based buffer overflow可以让攻击者能够在image verification阶段安装或者加载一个伪造的X.509 certificate。</p><h3 id="5-2-功能性bugs"><a href="#5-2-功能性bugs" class="headerlink" title="5.2 功能性bugs"></a>5.2 功能性bugs</h3><p>functional bugs: 是由于programming errors导致的问题（实现与程序员设计的不一致）</p><p><strong>Bugs in memory protection.</strong></p><p>ATF中的一个bug：memory translation tables的一个配置错误，导致S-EL1中的原本只应该是只读的memory areas一直都是可执行的。</p><p><strong>Bugs in configuration of peripherals.</strong></p><p>有个例子：Qualcomm TEE CVE-2016-10423：TA可以读取前面一个TA在SPI interface中的数据（没有对SPI bus的隔离访问（同时也没有前面一个TA退出时没有清除上下文数据））</p><p><strong>Bugs in security mechanisms.</strong></p><p>安全协议以及密码原语中存在的bugs。在ATF中，攻击者可以利用authentication checks中的缺陷绕过Amlogic S905 SoC secure boot process，因为只检查了boot image的完整性，而不是signatures。</p><h3 id="5-3-Extrinsic-Bugs"><a href="#5-3-Extrinsic-Bugs" class="headerlink" title="5.3 Extrinsic Bugs"></a>5.3 Extrinsic Bugs</h3><p>extrinsic bugs：improper handling of external factors（外部因素的不正确处理）</p><p><strong>concurrency bugs.</strong></p><p>OP-TEE中对文件系统concurrent access，允许一个TA删除trusted storage中的directory，而该directory正在被另一个TA创建。</p><p><strong>software side-channels.</strong></p><p>由区别于program logic的specific implementation artifacts导致，会泄露基于program exectution time的undeired information。（与程序的编程逻辑无关，由攻击者故意构造的访问方式导致的）</p><h2 id="6-Hardware-Issues"><a href="#6-Hardware-Issues" class="headerlink" title="6 Hardware Issues"></a>6 Hardware Issues</h2><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201031102703976.png" alt="image-20201031102703976"></p><p>阴影的部件表示这些trusted components被单独分配给TEE software，允许与off-SoC peripherals进行访问。（部分涂色的表示可以被部分或者全部地用于这些SW）</p><h3 id="6-1-Architectural-Implications"><a href="#6-1-Architectural-Implications" class="headerlink" title="6.1 Architectural Implications"></a>6.1 Architectural Implications</h3><p><strong>Attacks through reconfigurable hardware components.</strong></p><p>OP-TEE是可以支持在Xilinx Zynq-7000以及Zynq UltraScale+上运行的，但对新平台的支持也可能会带来新的攻击面。FPGA的可配置硬件通常链接到main bus中，这也就意味着硬件必须组织运行在主CPU中的软件访问memory regions。一些攻击可能通过reconfiguration hardware logic来打破TrustZone-based system的安全性。</p><p><strong>Attacks through energy management mechanisms.</strong></p><p>比如说通过运行恶意kernel driver，该kernel推动频率和电压调节器运行在超过供应商规定的限制上，直到出现错误计算，从而提取出密钥，绕过code signing operations。</p><h3 id="6-2-microarchitectural-side-channels"><a href="#6-2-microarchitectural-side-channels" class="headerlink" title="6.2 microarchitectural side-channels"></a>6.2 microarchitectural side-channels</h3><p><strong>leaking information through caches.</strong></p><p>虽然secure cache lines是无法被NW访问的，但是两个世界都在竞争cache lines的使用权时被保证有相同的权利。（一般使用的方法是prime+probe？具体怎么用的我不太清楚secure world和normal world难道不是实现就已经分配好了缓存空间吗？使用时再进行contention？）</p><p><strong>leaking information throuth branch predictor.</strong></p><p>BTB(branch target buffer)单元中存储的是计算得到的taken branch instructions的目标地址，当对应的分支指令成功预测了就取指。BTB是被secure world和normal world共享的。不同于cache的cache-line粒度，在BTB攻击中的力度是byte级别的，这里的probe机制会增加attack vector的spatial resolution。</p><p><strong>leaking information using Rowhammer.</strong></p><p>仅仅通过memory read operation，攻击者就能够翻转physical memory的bits。</p><p>Rowhmmaer通过在non-secure memory border高频率的memory read operations会导致secure memory发生错误。</p><p>rowhammer需要控制好环境，而且相对来说很容易缓解</p><h2 id="7-TrustZone-Assisted-TEEs的防御措施"><a href="#7-TrustZone-Assisted-TEEs的防御措施" class="headerlink" title="7 TrustZone-Assisted TEEs的防御措施"></a>7 TrustZone-Assisted TEEs的防御措施</h2><h3 id="7-1-Architectural-Defenses"><a href="#7-1-Architectural-Defenses" class="headerlink" title="7.1 Architectural Defenses"></a>7.1 Architectural Defenses</h3><p><strong>Multi-isolated environments</strong></p><ul><li>在TEE组件之间增加隔离粒度（隔离的更细），控制安全漏洞可能造成的损害</li><li>限制运行在SW中的代码总量，减少发生提权攻击的可能性</li></ul><p>进行的尝试1：在NW中创建隔离环境（IEE）</p><ul><li>SANCTUARY和TrustICE：利用TZASC的特性</li><li>vTZ等论文尝试在NW中使用了硬件虚拟化扩展</li></ul><p>进行的尝试2：增强TA之间的隔离</p><ul><li>让TA运行在不同的isolated secure guests OSes（但由于SW中缺少硬件虚拟化，采取该方法的系统都使用same-privilege isolation来secure hypervisor from secure guest OSes）</li></ul><p><strong>secure cross-world channels</strong></p><p>SW和NW的隔离可能是不安全的，SW中的秘密信息可能被攻击者窃取。</p><p>理论上可以通过</p><ul><li>fix vulnerable TEE kernel system calls</li><li>cross-world isolation</li></ul><p>这些措施来加强secure NW-SW channels</p><p>但实际上的情况是</p><ul><li>在NW访问TEE资源时几乎没有authentication</li><li>insecure shared-memory for data exchange within the channel</li></ul><p>研究人员的尝试：</p><ul><li>SANCTUARY完成了exclusive shared memory</li><li>TFence绕过kernel创建了一个partially privileged process（a shielded  portion of the REE application process)，该进程能够直接和TEE通信。</li></ul><p><strong>encryption memory</strong></p><p>TEE memory protection中存在的缺陷大部分都可以从主流OS中找到机制解决。不同于SGX，TrustZone也没有内置支持on-chip memory encryption.</p><p>针对这个问题，研究人员们提供的方法有：</p><ul><li>允许TAs完全运行在cache中，当他们写回主存中，对TA state进行加密</li><li>Ginseng通过对variables标记为sensitive，这些variables平时运行在CPU registers，在保存回memory中时加密处理</li></ul><p><strong>Trusted computing primitives</strong></p><p>commercial TEEs依赖于secure boot来保证TEE image的完整性。但是目前的机制还不足以保证TA的client（不管是远程的还是本地的）来验证TEE和TA binaries的完整性。</p><p>所以作者的观点是完成额外的computing primitives，比如remote attestation和sealed storage</p><h3 id="7-2-implementation-defenses"><a href="#7-2-implementation-defenses" class="headerlink" title="7.2 implementation defenses"></a>7.2 implementation defenses</h3><p><strong>managed code runtimes</strong></p><p>用C编写的TEE系统往往没有提供memory safety，很多validation bugs是由memory violation errors产生的。</p><p>在TLR（alternative TEE system），TA并不会被编译成native code，而是.Net managed code，该code还会翻译为small-sized managed code runtime。虽然性能变差了，但是避免了validation bugs。</p><p><strong>type-safe programming languages</strong></p><p>使用type-safe的编程语言来完成TrustZone-assisted TEE软件的特定部分，比如说RustZone，OP-TEE的extension，TA都是由Rust编写的。</p><p><strong>Software verification</strong></p><p>implementation产生的原因就在于软件部分的预期要求和具体实现的不一致。</p><p>所以作者提出的解决方法是进行software verification，其中包含了model checking，symbolic execution以及formal methods，在于保证实现完全符合需求。</p><p>本文提到了Komodo对特定TEE components的formal verification取得了非常重要的进步（which implements the specification of Intel SGX enclaves）</p><h3 id="7-3-hardware-defenses"><a href="#7-3-hardware-defenses" class="headerlink" title="7.3 hardware defenses"></a>7.3 hardware defenses</h3><p><strong>architectural countermeasures</strong></p><p><strong>microarchitectural countermeasures</strong></p><ul><li>软件上careful implementation of cryptographic algorithms或者使用特定的硬件来避免cryptographic-related operations的信息泄露</li><li>利用cache maintenance techniques来避免cache上的信息泄露（要不然就是不使用L2 cache，要不然就是使用L2 cache之后要记得cache flush。</li></ul><p>对于避免Rowhammer，TEEs应该避免在NW-SW boundary使用memory。</p><h2 id="8-Beyond-TrustZone-Assisted-TEEs"><a href="#8-Beyond-TrustZone-Assisted-TEEs" class="headerlink" title="8 Beyond TrustZone-Assisted TEEs"></a>8 Beyond TrustZone-Assisted TEEs</h2><p>基于RISC-V的TEE</p><ul><li>keystone</li><li>HexFive</li></ul><p><img src="/2021/01/29/2021-01-29-SoK-TrustZone/image-20201101105647248.png" alt="image-20201101105647248"></p><p>一些思考</p><ul><li>虽然arm在设计中设计的非常优秀，但实现中可能存在非常多的问题。所以漏洞一直都是能挖到的</li><li>arm上应该也有很多rowhammer的攻击，通过翻转NS这根线的比特位来改变处于的状态。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;S&amp;amp;P2020中关于TrustZone的SoK精读笔记~&lt;/p&gt;
    
    </summary>
    
      <category term="TrustZone" scheme="http://yoursite.com/categories/TrustZone/"/>
    
    
      <category term="TrustZone" scheme="http://yoursite.com/tags/TrustZone/"/>
    
      <category term="paper - System Security" scheme="http://yoursite.com/tags/paper-System-Security/"/>
    
  </entry>
  
  <entry>
    <title>Sanctuary-NDSS2019</title>
    <link href="http://yoursite.com/2020/06/20/2021-01-29-Sanctuary-NDSS2019/"/>
    <id>http://yoursite.com/2020/06/20/2021-01-29-Sanctuary-NDSS2019/</id>
    <published>2020-06-20T13:27:50.000Z</published>
    <updated>2021-05-24T11:42:50.585Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章是对<strong>SANTUARY:ARMing TrustZone with User-space Enclaves</strong>这篇论文的阅读笔记。</p><a id="more"></a><h1 id="SANCTUARY：ARMing-TrustZone-with-User-space-Enclaves"><a href="#SANCTUARY：ARMing-TrustZone-with-User-space-Enclaves" class="headerlink" title="SANCTUARY：ARMing TrustZone with User-space Enclaves"></a>SANCTUARY：ARMing TrustZone with User-space Enclaves</h1><p>由于厂商的严格限制，开发人员在开发或使用TrustZone受到很多限制（设备提供商进行限制的原因主要是Trusted App（TA）数量的增加会增加TEE的攻击面：也就是任何安全配置不严格或者有害TA将会降低系统的安全性），配置一个TA需要开发者和供应商双方的信任，这对双方来说都有很大的开销。供应商提供一些TEE功能接口，但是，这对移动应用程序来说是远远不够的，比如银行业务。intel SGX技术在学术和工业界引发的巨大讨论解释了对不受限制的TEE应用的需求，但是目前还没有在移动端应用上有类似的安全架构。  </p><p>SANCTUARY是第一款不依赖于虚拟化的TrustZone生态体系中可以无限制使用TEEs的安全架构。SANCTUARY允许在TrustZone中的normal world中以比较强的隔离组件运行security-sensitive apps，类似于sgx中的用户空间的enclaves。</p><p>研究人员们考虑将sensitive app放到normal world中，通过利用TrustZone的Address-Space Controller（TZASP），提供了两个硬件级别的隔离：</p><ul><li>security-sensitive app are shielded against a compromised normal-world OS;（防normal world中的恶意os）</li><li><strong>the system is also protected from potentially malicious apps in isolated compartments</strong>（防IEEs环境中的恶意apps）</li></ul><p>IEEs的存在能够最小化TEE的攻击面，TEE的最大潜能能够被利用</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>由于移动设备上存在着巨大的攻击面，所以导致在保护敏感应用（银行，支付，电子身份服务）时面临这巨大的安全和隐私挑战。由此，arm公司提出了TEE和TrustZone的概念。</p><p>normal world中运行Legacy OS（老式操作系统，LS）和用户级别的app；而secure world中运行的是security-sensitive app，secure world是在TrustZone内核和硬件上的可信执行环境（Trusted Execution Environment，TEE）</p><p><strong>TrustZone的问题</strong></p><p>近十多年来，TrustZone主要是被生产提供商出于自己的目的使用，TrustZone研究缺乏进展的主要原因是Trusted APP（TA）的安装会增加了受到安全攻击的可能性。也就是，TrustZone-enabled app中的bug将会导致很大数量的设备暴露在真实世界中的安全威胁中。</p><p>Google总结TrustZone的设计缺陷如下：</p><ul><li>weak isolation between TAs in the TEE（TEE中TA之间的不牢固的隔离）</li><li>TCB expansion（可信计算基的扩展）</li><li>highly privileged access to platform, making TrustZone a high-value target for attackers（TrustZone能够以很高的权限进入平台，这使得TrustZone对于攻击者来说是一个很高价值的目标）</li></ul><p>因此，设备提供商总是控制和限制对TEE的访问。一方面，vendor和app开发者在建立信任关系时必须要一个全面的安全评估；另一方面，对于开发人员来说，在TEE中开发一个TA是需要很大的开发开销。虽然vendor提供了一些针对normal world app的TEE接口，比如密钥存储设备，但这些功能无法保护开发者自己的敏感代码和数据。</p><p><strong>现有的安全架构</strong></p><p>目前的很多基于ARM的安全架构依赖于虚拟内存进行隔离，但对于安全世界中的TrustZone中的TA的隔离还是不充分的。在目前的多核平台上完全利用时间隔离的措施将会极大地影响用户体验（悬挂整个系统来保护TA的运行）</p><p>在分析了开发者遇到的问题和TrustZone所作出的妥协和努力后，得出结论：<strong>目前提供的TEE服务是无法满足功能丰富的安全移动服务</strong>。</p><p>目标：解决上述提到的问题，方便第三方的app开发者在无需进行硬件修改的情况下能够最大程度地使用TEE。</p><p>名词解释：</p><ul><li>SA：Sanctuary Apps，在IEEs中的secure-sensitive app，相当于SGX用户空间中的enclaves</li><li>isolated compartments：IEEs，SANCTUARY实例</li><li>LA：Legacy Apps</li><li>LOS：Legacy OS</li><li>TF：Trusted Firmware</li></ul><p><strong>目标</strong></p><ul><li><p>将secure-sensitive app移植到IEE中，减少了TEE中的代码量</p></li><li><p>SANCTUARY通过dynamically partitioning和re-allocating系统资源达到了SA隔离：CPU内核和物理内存会被暂时保留给IEE来运行SA，并不会悬挂系统的剩余部分</p></li><li><p>利用TZASC（地址空间控制器）来保证SAs和其他系统组件之间的hardware-enforced，two-way isolation（硬件执行且双向的隔离）且无需硬件上的修改</p></li></ul><p>要解决的问题主要：1）如何动态分配内核；2）如何在普通世界中强制一个严格的隔离；3）提供和SGX类似的安全服务；4）在现实场景中能够提高性能</p><p><strong>贡献</strong></p><ul><li>提出了SANCTUARY的设计，在IEE环境中提供了类似于enclave的功能；（提出设计）</li><li>在HiKey 960开发板和OP-TEE上实现了概念验证；（实现）</li><li>分析了当有一个强大攻击者的设置下SANCTUARY的安全属性（安全性）</li><li>进一步探讨了SANCTUARY在建立和通信时的开销（性能）</li></ul><h2 id="2-背景"><a href="#2-背景" class="headerlink" title="2 背景"></a>2 背景</h2><p>TrustZone代表的是ARM架构中在处理器设计和SoCs中的安全加强。</p><p>TrustZone-enabled处理器在4个不同的privilege levels运行（EL0-EL3）</p><ul><li>EL3（monitor mode）：在ARM Trusted Firmware（TF）上，secure world和normal world在EL0-2三个等级上进行分割来管理各自的地址空间</li><li>EL2：optionally used for a hypervisor</li><li>EL1：OS kernel</li><li>EL0：used for execution of application</li></ul><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/1.png" alt="1"></p><p>SMC（secure monitor call）：从normal world到secure world的上下文切换指令。当一个内核发出SMC指令时，在多核系统中的其他内核都可以仍然处于normal world mode。</p><p>内存地址空间也被分为secure world和normal world，这种隔离是由TrustZone地址空间控制器来完成的。</p><p>运行TrustZone的设备是在secure world中启动的。在secure world启动完毕之后Trusted OS（TOS），secure world就会切换到normal world，并开始启动老式操作系统（LOS）。（secure boot：在运行之前引导加载器以加密形式检查TOS。事实上，很多vendor就是通过secure boot锁定终端用户的修改，来保证安全世界的完整性。比如说，通过哈希获得安全验证码，一旦修改后，验证码不能对得上，就无法启动）</p><p>如图1所示，TZASC在系统总线和内存芯片之间的位置。TZASC基于不同的总线事务特征提供多个内存区域和访问控制设置。（通过总线事务特征对内存区域进行划分，并进行访问控制）</p><p>最开始的设计只限于两种不同的内存访问：non-secure（NS=1）和secure访问（NS=0）。secure模式下的内核能够访问secure和non-secure的内存；而non-secure模式下的内核只能访问non-secure的内存。</p><p>2013引入的TZC-400，可以利用总线事务上的额外特征——identity-based filtering（基于身份的过滤）来分隔受保护的内存区域。在目前的ARM参考设计中指出，每个设备（比如CPU，GPU，DMA控制器）都能够在硬件中被分配一个bus-master ID，从而充当一个总线主设备（bus master）的角色。这就可以将内存区域分配给特定的bus master来进行non-secure访问。</p><h2 id="3-攻击模型和要求"><a href="#3-攻击模型和要求" class="headerlink" title="3 攻击模型和要求"></a>3 攻击模型和要求</h2><p><strong>攻击者模型</strong></p><ul><li>攻击者可以破坏normal world中的所有软件，最高可以到optional hypervisor（EL2）（通过远程或者本地软件攻击）</li><li>进行passive physical attacks</li><li>攻击者无法破坏secure world软件以及monitor mode</li></ul><p>不考虑涉及硬件的物理攻击。SANCTUARY也不确保可用性，比如抵御DoS攻击。</p><p><strong>几点假设</strong></p><ul><li>normal world中的app和LOS是不可信的</li><li>不同特权级别的隔离是硬件通过虚拟内存执行的</li><li>现存的架构抵御措施，比如Execute Never(XN), Unprivileged Execute Never(UXN), Privileged Execute Never(PXN), Privileged Access Never(PAN)都被配置并且被激活</li><li>secure world中的boot loader和EL3硬件（monitor mode）都是可信的</li></ul><p>SANCTUARY可以通过将一部分Trusted Apps部署为Sanctuary Apps（IEEs App）来减少secure world中的软件数量。</p><p><strong>需求分析</strong></p><p>SANCTUARY必须达到的安全要求</p><ul><li>代码和数据完整性：1）SA执行的隔离；2）SA代码被装载到IEEs中进行认证</li><li>数据机密性：1）数据在安全信道中提供（运行之前）；2）执行期间的空间隔离；3）temperal isolation，在SA执行结束后，敏感信息不能被访问</li><li>通向安全世界的安全信道：通过exclusive shared memory，只能由SA和secure world访问</li><li>考虑恶意SA的存在，尽可能地限制SA的访问权限（EL0）</li><li>硬件执行的资源隔离：保证严格的空间隔离（spatial）和时间（temporal）隔离（空间的话，就是无法访问内存，时间我的理解是执行之前，执行中，执行之后三个时间段来考虑无法获取秘密信息）</li><li>最小的软件改变：利用现存的secure world OS和normal world OS的接口来避免最少的修改</li><li>积极的用户体验：通过最小化SA的run-time environment来保持低延迟</li></ul><h2 id="4-SANCUTARY设计"><a href="#4-SANCUTARY设计" class="headerlink" title="4 SANCUTARY设计"></a>4 SANCUTARY设计</h2><p>SANCTUARY allows <strong>the creation of multiple parallel isolated compartments</strong> on ARM devices in the normal world which are stricly isolated from the LOS and Legacy Apps(LAs).（SANCTUARY允许ARM设备上的normal world创建多个平行的isolated compartment，这些IEE与LOS和LA严格隔离。）</p><p>这边的isolated compartment，就是上一篇论文中的isolated execution environment，本文作者进一步把它阐述为SANCTUARY instances，其中运行的secure-sensitive app被称为Sanctuary Apps（SA）。每一个SANCTUARY instances一次只能运行一个SA。由于每个SANCTUARY instances与其他实例都严格隔离，所以每个SA之间也是严格隔离的。另外，SANCTUARY instances也是与secure world隔离的。</p><p>SANCTUARY实例通过以下几点保证空间的独立性：</p><ul><li>利用TZC-400 memory controller分割物理内存；</li><li>给SANCTUARY instances指定一个CPU core</li><li>exclude the SANCTUARY Instances’s memory from  shared caches.（不让使用共享缓存）</li></ul><p>时间的独立性（temporal isolation）</p><ul><li>从可信状态（TF）启动SANCTUARY CPU内核</li><li>在退出之前将内存中的所有敏感信息清空</li></ul><p>SANCTUARY对现有的TEE架构只需要扩展而无需影响normal world和secure world中已经配置好的软件功能。</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/2.png" alt="img"></p><h3 id="4-1-SANCTUARY-Isolation"><a href="#4-1-SANCTUARY-Isolation" class="headerlink" title="4.1 SANCTUARY Isolation"></a>4.1 SANCTUARY Isolation</h3><p>SANCTUARY实现了normal world的隔离。通过利用ARM的新的内存访问控制器TZC-400，一块特定的内存可以被控制exclusively（专有的）被某个CPU内核访问。</p><p>图2展示了SANCTUARY的设计概览，同时也显示了SANCTUARY的two-way isolation：SANCTUARY instances被配置have exclusive access to Sanctuary RAM部分，而该实例同时也不允许访问normal world memory，也就是他们也不被允许访问core0和core1的内存或者是其他SA的内存。 </p><p>SANCTUARY支持</p><ul><li>shared memory between normal world and SA-》高效通信</li><li>shared memory between secure world and SA -》建立安全信道</li></ul><p>secure-world software是可信的，因此能够访问所有的内存（normal-world memory, SANCTUARY memory, secure-world memory）</p><p>多SA之间的隔离</p><p>SANCTUARY实例可以持续地运行在相同的内核也可以运行在不同的CPU内核上。</p><p>Multi-SA isolation: <strong>All SAs are executed completely independently of each other.</strong>当SA执行完毕时，系统返回初始状态，下一个SANCTUARY实例能够被启动。（<em>一次只能运行一个SA吗？</em>）</p><p>Privilege isolation: SAs被限制以user-mode运行。Sanctuary Library (SL)以EL1-mode（privileged mode）运行，是为了提供两个功能：1）initial an execution environment for the SA;2)provide service interfaces to the SA(为了访问SANCTUARY的安全服务) </p><h3 id="4-2-SANCTUARY初始化"><a href="#4-2-SANCTUARY初始化" class="headerlink" title="4.2 SANCTUARY初始化"></a>4.2 SANCTUARY初始化</h3><p>SA代码是由LOS加载的，所以它的完整性必须被验证。</p><ol><li><p>SANCTUARY在不影响系统可用性的情况下，选择一个CPU core，将该CPU core中之前运行的LOS的数据保存到normal world中。其他的CPU内核仍然处于LOS的控制之下，所以并不会影响系统的可用性。</p></li><li><p>将SL和SA的代码加载至separate memory section，在激活memory isolation后，通过digital signatures对加载的代码进行验证（SL的签名由device vendor提供，而SA的签名由SA开发者提供）。验证成功后，SANCTUARY core starts from a defined initial state,boots the SL  and executes the SA.</p></li><li><p>当SA结束后，the dedicated core移除memory中的信息，使缓存中的数据无效，并关闭。将被分配的memory和CPU core的使用权重新还给了LOS。</p></li></ol><h3 id="4-3-SANCTUARY安全服务"><a href="#4-3-SANCTUARY安全服务" class="headerlink" title="4.3 SANCTUARY安全服务"></a>4.3 SANCTUARY安全服务</h3><p>SA是从不可信的unprotected memory中加载的，所以SA的initial content中是不能包含机密信息的。而机密数据可以在SA被创建后通过一个secure channel传递过来。为了保证SA不是malicious的，TA需要在传递之前对SA的integrity和authenticity进行验证。为了确保SA机密数据的安全传递和安全存储，SANCTUARY提供了一系列的安全服务，这些安全服务由设备供应商提供的TA来完成，下文称之为vendor TA。</p><p>Remote Attestation：基于TrustZone平台身份特性（platform identity feature），SANCTUARY的完整性测量结果能够准确地传送给指定的第三方。将完整性可信报告与通向SA的可信信道相链接，将会创造一个安全可信的信道，通过该信道，我们能够传递机密信息（ Linking the authentic integrity report with the establishment of a secure channel to the SA creates a secure and authenticated channel through which confidential data can be provisioned.）（<strong>个人理解：可信信道的建立需要双方的信任，由于secure world是可信的，所以这里只需要SANCTUARY对secure world证明自己的完整性，SANCTUARY实例将自己的完整性报告通过NSAID准确地传送到指定的第三方，就是这边的secure world中的应用，secure world进行验证后，建立信道就可以进行机密信息的传输。</strong>）</p><p>sealing：类似于sgx的sealing，用从SA二进制文件计算得来的散列值派生出的unique encryption key（derived from the hash value computed over the SA binary）对机密信息进行加密（sgx中的sealing分为两种，两种的区别在于当应用更新换代后，密钥是否改变，如果不变后代还能解密前代应用的数据（sealing to sealing identity），反之则无法解密之前的数据（sealing to enclave identity））</p><h3 id="4-4-SANCTUARY软件模型"><a href="#4-4-SANCTUARY软件模型" class="headerlink" title="4.4 SANCTUARY软件模型"></a>4.4 SANCTUARY软件模型</h3><p><strong>（每个SA都隶属于一个不可信的LA）each SA belongs to an untrusted LA.</strong>也就是，SA就是LA的一部分，在应用程序市场上进行安装的时候，可以使用标准的安装流程。通过将SA和LA结合，SL的功能性将可以减小。LA作为一个代理，可以允许SA使用LOS提供的服务，另外，LA和SA可以通过共享内存交换信息。当SA需要将信息保存到LA中永久存储，就可以用sealing在传递给LA之前进行加密操作。（LA和SA的关系是什么，他们之间的互动）</p><p>总结一下，这边的sealing服务更像是为LA和SA通信设计的；而remote attestation是为了SA和secure world之间通信设计的。</p><h2 id="5-实现"><a href="#5-实现" class="headerlink" title="5 实现"></a>5 实现</h2><p>基于的硬件：HiKey960（four ARM Cortex-A73 and four Cortex-A53 cores），ARMv8 SoC。（HiKey960是少数几款允许开发者在secure world中配置自己的软件的开发板之一）</p><p>SANCTUARY软件组件</p><ul><li><p>secure world Trusted OS-》OP-TEE（SANCTUARY并不局限特定的TOS）</p></li><li><p>Legacy OS-》与使用的OP-TEE捆绑的Linux发行版</p></li><li><p>使用自定义的kernel module作为LOS的一部分，用于在normal world中管理SANCTUARY实例</p></li><li><p>在OP-TEE中，完成了两个vendor TA，分别是Proxy TA（用于remote attestation）和Sealing TA（用于sealing）</p></li><li><p>一个SANCTUARY实例包括Sanctuary Library（SL）和一个SA。在本文的原型实现中，使用了Zircon micro kernel（因为很小，只有1MB且多功能性）作为SL的基础。</p></li></ul><p>图3中的STA就是本文作者添加到OP-TEE中的自定义部分，代码量仅有1313行（所有secure部分的修改），其中两个vendor TA占一半的代码量。同时，由于将所有第三方开发者对TA的修改移出了TCB，TCB的大小也减小了。</p><p>以Pearl-TEE为例，实现一个mobile payment和chat TA包含了900和200LoC，这可以看做是完成一个有用的TA的最低标准。作者认为，这也表明了从将TA从secure world中移除比对OP-TEE和TF的代码量增加更重要。（增加这样的一个TA程序就会达到几百行，如果无限制地向secure world中写入代码，将会导致TCB越来越大，所以进行一次性的修改更好）</p><p>（对该表的解释：除了增加两个vendor TA，作者仅对TCB进行少量的一次性修改）</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/3.png" alt="img"></p><p><strong>SANCTUARY 硬件组件</strong>。SANCTUARY利用的原理是每个CPU core都可以被分配一个unique master ID，因此，每个内存事务都只被一个core执行。事务ID也能够从硬件级别上过滤内存访问，这些过滤和许可操作都是由TZC-400内存控制器执行的。TZC-400基于两个特性来允许或者禁止对内存区域的访问： 1)CPU内核运行代码的访问事务类型（secure or non-secure）；2）执行SANCTUARY instances的CPU core的bus master ID（鉴别是secure world还是normal world；另一方面，鉴别bus master ID）（解释图3）</p><p><strong>SANCTUARY usage.</strong>当LA想要在SANCTUARY实例中的一个SA中执行敏感代码时，</p><ol><li>LA向KM请求执行与LA绑定的SA；</li><li>KM通过加载SANCTUARY二进制文件（SL和SA）启动SANCTUARY实例的设置。接着，KM将某个CPU内核上的LOS移除并将控制权移交给STA；</li><li>STA执行安全相关的步骤，比如SA的验证；</li><li>在成功建立起SANCTUARY实例，KM触发SANCTUARY的引导程序；</li><li>当引导程序结束后，SA能够运行敏感代码，并且能够与LA和TA进行通信。</li></ol><h3 id="5-1-Legacy-OS"><a href="#5-1-Legacy-OS" class="headerlink" title="5.1 Legacy OS"></a>5.1 Legacy OS</h3><p>KM主要负责管理SANCTUARY实例所需要的所有资源，位于LOS中。</p><ul><li>KM能够为SANCTUARY实例提供运行时所需要的CPU core，将LOS从某个CPUcore中清除出去，也可以在SANCTUARY实例结束运行时将该core归还给LOS。 </li><li>KM为SANCTUARY实例动态分配内存，并建立从SA到TA的双向信道</li><li>在SANCTUARY实例能够运行之前，KM将SANCTUARY binaries（SL和SA）加载至即将被exclusively分到SANCTUARY内核的内存中</li></ul><p>总结：KM就是准备各种资源，比如CPU core资源，内存资源，以及LA和SA的访问资源</p><h3 id="5-2-安全服务"><a href="#5-2-安全服务" class="headerlink" title="5.2 安全服务"></a>5.2 安全服务</h3><p>Trusted Apps-》SEL0（secure world user space)</p><p>OP-TEE -&gt;SEL1 (secure world kernel space)</p><p>Proxy TA：负责建立一个SA到remote servers连接的安全信道，所有通过Proxy TA传输的数据都用platform key认证过，并且与发送者SA的身份绑定。（私钥加密，公钥解密？或者是用plateform key对称加密？）</p><p>Sealing TA：将数据与一个特定的SA绑定，并且在设备上永久存储（sealing to enclave）每个SA使用一个individual key。</p><p>STA：代表OP-TEE中的kernel module。STA使用预先配置好的签名验证SL，建立SANCTUARY实例，最后tear them down。（对SA binary计算得哈希值；判断某个SANCTUARY实例中正在哪个运行的SA）</p><p>secure world和normal world中的上下文切换工作由TF负责</p><h3 id="5-3-Sanctuary"><a href="#5-3-Sanctuary" class="headerlink" title="5.3 Sanctuary"></a>5.3 Sanctuary</h3><p>一个SANCTUARY实例包含两个部分：SL和SA。SL为运行SA提供基本的进程和内存管理功能。</p><p>当Ziron启动后，它为SA准备好运行所需要的环境，包括配置CPU内核，设置内存映射以及一个基本的运行环境。</p><p>接着，SA作为Ziron微内核的一个normal world用户进程。在运行过程中，SA可以和LA或者TA进行通信。</p><h3 id="5-4-Memory-isolation-unit"><a href="#5-4-Memory-isolation-unit" class="headerlink" title="5.4 Memory isolation unit"></a>5.4 Memory isolation unit</h3><p>在给SANCTUARY的执行分配指定的内核进行隔离之外，通过利用TZASC可以保护SANCTUARY内存不受其他内核中来自normal world的访问。</p><p>TZC-400 基于bus master ID设置内存访问许可。</p><p>传统上，在ARMv8的架构中，所有的内核都被分配了一个独一无二的多处理器ID（uniquely-assigned multi-processor-IDs）。当内核中的事务被传送到系统总线上时，多处理器ID会通过一个指定的labeling component被转化为bus master ID。但是在HiKey960的开发板中，内核上的所有事务都被标记为同样的bus master ID。对于SANCTUARY来说，只需要修改映射策略（mapping policy）以便于内核中的bus transactions被标记上不同的bus master ID。（<em>物理地址映射到虚拟地址的时候，标记为某个特定的core的内存地址？</em> 还是<em>直接对core ID进行映射修改？</em>）</p><p>对labeling ID-mapping policy的修改使用的是ARM Fast Models virtualation工具。在软件上，配置TZC-400从而通过对bus transactions的bus master ID labels进行过滤，使得内存区域被唯一地分配给单独的内核。（SANCTUARY需要格外做的是标记上unique ID，对每个事物分配bus master ID labels已经是由TZC-400做好的）</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/4.png" alt="img"></p><h3 id="5-5-execution-life-cycle"><a href="#5-5-execution-life-cycle" class="headerlink" title="5.5 execution life cycle"></a>5.5 execution life cycle</h3><p>假设SL的签名已经存储在了secure world中。</p><p><strong>Sancturay Setup.</strong>安装步骤是由normal world中的KM（管理系统资源）和secure world中的STA执行的（执行所有的安全相关的步骤）。1）在需要执行SA中的敏感代码时由LA触发，LA在文件系统中加载SL and SA binaries，并通过procfs转交给KM。SL binary只能被加载一次，并一直在内存中保持到系统关闭（shut down）；（Sanctuary Data是KM保留了用于SA运行时进行内存分配的内存，另外，部分也会用于SANCTUARY实例的通信信道，比如LA和SA之间进行通信，secure shared memory则是用于SA和TA之间进行通信。（LA）</p><p>2）KM选择a CPU core来运行SANCTUARY实例，接着，采用linux的hotplug技术shut down这个被选择的内核；（KM）</p><p>3）KM调用STA，并对选择的core提供了一个ID作为参数。这里的调用就进入了monitor mode（SMC调用，从normal world进入secure world），TF在进行上下文切换时检查被选择的core是否被shut down，然后将控制权转交给STA。STA通过配置TZC-400将SANCTUARY内存锁定。（STA）</p><p>TZC-400对内存区域的配置。举个例子</p><p>这里假设一共有8个core，将0-7分配给这8个core作为编号，假定SANCTUARY被选择的内核编号为ID 7。假设这里仅有CPU core有访问内存的需求。TZC-400对内存区域进行分块，最高可以分成9块，配置这9块地址空间覆盖SL和SA二进制文件，Sanctuary Data和secure shared memory所驻留的连续内存空间。</p><p>地址范围的确定，比如region1，最低地址（lowest address）由REGION_BASE_LOW_1和REGION_BASE_HIGH_1 registers设置，最高地址（highest address）由REGION_TOP_LOW_1和REGION_TOP_HIGH_1 register设置。</p><p>这里以region1举例，当region1被配置好后，接下来通过REGION_ID_ACCESS_1 register被分配给SANCTUARY core。如图5所示，其中，upper 16 bits定义了non-secure write access permissions，low16 bits定义了non-secure read access permissions.每个bit都和一个bus master ID相对应。假设这边的bit0和bit16都被配置为1，其他都为0，就意味着bus master ID为0的设备在region1上能够进行读写。</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/5.png" alt="img"></p><p>external interrupts are configured using the core’s CPU interface of the GIC(General Interrupt Controller) which can not be accessed by other cores.</p><p>假设这边的REGION_ID_ACCESS_1的值为0x800080，那么就代表这region1的地址仅能被ID为7的设备访问。0x800080-》0x00800080，0080中的1在低8位上，也就是ID为7的bit上。</p><p>0x7F007F代表除了SANCTUARY core其他core都能访问的normal world内存。（SANCTUARY core ID为7）</p><p>non-secure shared memory：0xFF00FF</p><p>secure-world memory：0x0</p><p>最终对不同的内存区域，core ID和运行模式的内存许可在图3中。STA使用存储的电子签名验证SL binary。</p><p>（REGION_ID_ACCESS_1寄存器的设置，STA通过RSASSA_PKCS1-v1_5和SHA-256对SL进行认证）</p><p><strong>Sanctuary Boot.</strong> </p><p>1）在SANCTUARY被成功设置后，KM调用TF启动SANCTUARY core。（分成三步，分别是TF初始化，TF检查SANCTUARY实例，TF启动core）</p><p>在启动core之前，TF首先会检查SANCTUARY实例是否被正确地锁定和验证。SANCTUARY first executes the TF in EL3.在接受到boot命令后，SANCTUARY core在EL3上进行TF的初始化。在初始化的过程中，还需要配置好exception handler（在SL set up的过程中，exception handler会调用TF；而在teardown的过程中，TF也会被调用来shut down SL）</p><p>2）TF初始化完毕后，SANCTUARY core切换到EL1，并跳转到SL的入口点。</p><p>不允许SANCTUARY内存被缓存到L2 cache中。 外部中断配置使用core的GIC（General Interrupt Controller）的CPU接口，这个接口不能被其他内核访问。</p><p><strong>SA运行</strong>。</p><p>当与对应的LA通信时是通过non-secure shared memory。由于在non-secure shared memory中访问的数据都是可以被normal world访问的，所以这部分并不是SANCTUARY memory partition。这部分的通信，在SANCTUARY部分是通过Zircon system call完成的，而在normal world部分，是由LOS中的KM来配置的。</p><p>当与vendor TA通信时通过secure shared memory。在secure world这边，该通信是由STA完成。secure shared memory是指派给SANCTUARY core的受保护的SANCTUARY内存区域。</p><p>SA与TA的通信有两种实现方法：1）将Ziron中包含OP-TEE驱动，切换到secure world的工作就可以由SANCTUARY自己来完成；2）到安全世界的连接由SA对应的LA触发。本文作者选用的是第二种，这样可以对Ziron核进行更少的修改。</p><p><strong>SANCTUARY teardown</strong></p><p>由LA触发SANCTUARY的teardown操作。</p><p>1）当LA对SA发起信号表示SANCTUARY的服务并不再需要时，关闭SANCTUARY core。如果需要的话，SA通过sealing服务保存自己的状态。内部清理操作使Zircon核返回初始状态，并使L1 cache中的数据无效避免数据泄露，接着，SL对STA发起信号，表示自己已经成功完成了清理操作；（SA）</p><p>2）TF关闭该内核。在切换世界并将控制权转交给STA之前，TF进一步判断SANCTUARY core是否被真正地关闭；接着，STA检查SA是否完成了自己的清理操作，接着 unlock SANCTUARY内存，将secure memory和Sanctuary Data清零，防止信息泄露。（TF和STA）</p><p>3）TZC-400的配置被恢复，这样，SANCTUARY内存区域和SANCTUARY core都被释放。（内存部分）（TZC-400）</p><h2 id="6-安全性分析"><a href="#6-安全性分析" class="headerlink" title="6 安全性分析"></a>6 安全性分析</h2><p>根据图2，攻击者能够在本平台上从三个角度进行攻击：</p><ul><li>normal world用户空间</li><li>normal world OS</li><li>malicious SA</li></ul><p>在这三种情况下，攻击者的目标都是破坏victim SA的完整性或者数据机密性或者获取LOS的控制权。这些可以发生SA的整个life-cycle中（setup，boot，execution，teardown）。</p><p>本文从以下五个角度来进行安全分析：</p><ul><li>normal world中的恶意代码的目标可能是在SL和SA binaries被加载之前对他们进行操控；（加载前修改，通过完整性检测发现）</li><li>克服SANCTUARY的隔离；（？不知道咋克服）</li><li>操纵永久存储在SA中的数据；（sealing ？）</li><li>通过cache从某个SA中提取信息（可以做到吗？L2都关了）</li><li>恶意SA</li></ul><h3 id="6-1-binary-integrity"><a href="#6-1-binary-integrity" class="headerlink" title="6.1 binary integrity"></a>6.1 binary integrity</h3><p>SL和SA的binaries都在无加密地保存在normal world中的内存。对SL和SA的完整性是通过本地认证和远程认证来实现的。</p><p>SANCTUARY在secure-world内存中保存了一份SL的签名。在SANCTUARY实例执行之前，STA首先对SL binary的签名进行验证。如果验证失败，则证明SL binary一定是被修改过，那么该文件将不会被执行，SANCTUARY的建立过程也会被中断。</p><p>SANCTUARY通过remote attestation来验证SA的完整性。STA对SA生成一个签名，将该签名一并发给server，server在将敏感数据发送给SA前，将SA与该签名进行对比，如果SA处于一个invalid状态，则停止传递。</p><h3 id="6-2-code-and-data-isolation"><a href="#6-2-code-and-data-isolation" class="headerlink" title="6.2 code and data isolation"></a>6.2 code and data isolation</h3><p>在SL被验证之前，SANCTUARY memory isolation就被TrustZone完成。在SANCTUARY内存被锁定之后，只有SANCTUARY core才能在自己的内存区域中从normal world进行读写操作。</p><p>被选择的SANCTUARY core永远在TF中被启动，接着，跳转到SL的一个地址，该地址作为一个常数被保存在TF中。在SANCTUARY的启动过程中，其他内核的中断都被disabled，只有SANCTUARY core自己能够配置它的GIC。最后，也只有SANCTUARY core能够关闭自己。</p><p>在SANCTUARY的运行期间，到secure world的切换的调用必须由SANCTUARY core发起，如果是其他core发起，该调用会被blocked。如果确实是由SANCTUARY core发起，TEE中的vendor TA还会使用STA判断SANCTUARY实例是否在correct state，只有检查通过，才能在secure shared memory上读写数据。（就是在运行的过程中，会通过proxy TA利用remote attestation）</p><p>在SANCTUARY instances的内存区域被locked之前或者被释放（unlocked）之后，STA都会对SANCTUARY内存进行重写，而不是为SL或者SA保留一个固定值。在关闭之后，SL会恢复原来的值，所以并不会保留有SA数据。</p><h3 id="6-3-安全存储"><a href="#6-3-安全存储" class="headerlink" title="6.3 安全存储"></a>6.3 安全存储</h3><p>当需要将SA data进行永久性存储的时候，就会使用sealing技术，sealing所用到的密钥是从SA binary的散列值派生得来的。所以，只有一个未发生修改的SA能够成功解密自己的sealed data。</p><p>对sealed data的永久保存，SANCTUARY实例使用TEE提供的功能，可能需要SA将自己的数据与设备绑定（不太清楚）或者将数据保存到roll-back protected memory。</p><h3 id="6-4-抗击缓存攻击的能力"><a href="#6-4-抗击缓存攻击的能力" class="headerlink" title="6.4 抗击缓存攻击的能力"></a>6.4 抗击缓存攻击的能力</h3><p>在ARMv8平台上，考虑攻击者从L1 cache或者L2 cache层面上进行攻击，L1 是core-exclusive，而L2 cache是shared。配置攻击有两个场景：direct attacks和side-channel attacks。</p><p>一个拥有特权的攻击者即使在没有读取主存物理地址的允许时，也可能获得对SANCTUARY instances的cached data的直接访问。对于L1 cache，是通过将SANCTUARY instances运行在自己的core上，并在实例被关闭和解锁之前都对L1 cache的数据进行无效化处理。对于L2 cache，一个是通过设置outer uncacheable，就是不允许SANCTUARY 内存被缓存到L2上，这也会带来一定的开销。另一个方法是在硬件级别修改缓存，增加对L2访问时的基于身份的过滤。</p><p><strong>侧信道攻击</strong></p><p>L1 cache是在core中运行的，并且在shut down之前，L1 cache中的数据会全部无效化，所以L1 cache不会受到侧信道攻击的威胁。</p><p>但对于L2 cache，对L2 cache进行身份过滤时也无法避免侧信道攻击的问题。只有不允许SANCTUARY memory缓存到L2 cache中，才能解决这个问题。</p><h3 id="6-5-恶意SA"><a href="#6-5-恶意SA" class="headerlink" title="6.5 恶意SA"></a>6.5 恶意SA</h3><p>如果用户无意间安装了一个恶意的SA，以此尝试攻击normal world中的LA和LOS。SA仅仅拥有user privilege（EL0），而SL是EL1.即使攻击者进行了提权操作，获取了SL的控制权，secure world内存仍然是无法被攻击者访问，因为SA运行在normal world中，SA只能访问被分配的SANCTUARY内存，而不允许访问其他的normal world内存，所以仅有与LA通信用的non-secure shared memory会被影响。</p><p>SANCTUARY的设计针对于LOS和IEE同时运行的场景，但是一个时刻只能运行一个SA，所以不存在SA之间的非预期的信息流，也就是恶意SA泄露其他SA的信息。</p><h2 id="7-评估"><a href="#7-评估" class="headerlink" title="7 评估"></a>7 评估</h2><h3 id="7-1-基准测试"><a href="#7-1-基准测试" class="headerlink" title="7.1 基准测试"></a>7.1 基准测试</h3><p>评估平台：HiKey960 (four ARM Cortex-A73，four Cortex-A53 cores，每个Cortex-A73内核装载了64KB L1指令缓存和64KB的L1数据缓存，分享2MB的L2缓存，Cortex-A53分享512KB的L2缓存，具有32KB的L1指令缓存和32KB的数据缓存)</p><p>若需要使用L2 cache，则不考虑侧信道攻击（也就是侧信道攻击是无法避免的）在shared L2中，作者考虑的是identity-based filtering是实现的。</p><p>其中，方括号的值是表示在不使用L2的情况下，测量结果几乎未受到影响。</p><p>1）Sanctuary中的通信。</p><p>图2展示了在SANCTUARY中存在的不同的通信信道。</p><p>SA和TA之间通信的较高开销是由于上下文切换是由LA触发的，所以SA需要先与normal world进行通信，而后由LA进行触发。</p><p>虽然LA-》SA的通信时间增加了1.66倍，但所需要的时间仍然是practical的，与标准的TrustZone通信所需要的时间相当。</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/6.png" alt="img"></p><p>2）Sanctuary设置</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/7.png" alt="img"></p><p>运行SANCTUARY实例和TA的时间差别主要是在隔离一个CPU内核上。</p><p>首先是从加载Sanctuary binaries步骤，都只需要7ms；</p><p>第二步，使用linux的hotplug技术关闭内核；</p><p>第三步，SANCTUARY被锁定并验证；</p><p>第四步，Ziron核启动，这里作者分成了三个小步，1）对core的初始化；2）platform component被初始化，kernel 环境被设置；3）用户环境被设置。</p><p>虽然在不适用L2 cache时，所用到的时间分别是7倍和36倍，但总的时长是450ms。如果使用identity-based filtering特性，setup需要的时间大概是200ms。</p><p>3）SANCTUARY teardown</p><p>在shut up步骤，L1 cache被无效化，Zircon kernel恢复到原始状态。在unlock步骤，SANCTUARY内存被赋予0值。完整的teardown操作大概需要100ms。</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/8.png" alt="img"></p><p>对于SANCTUARY来说，set up和teardown除去runtime的时间，在有L2的情况下需要340ms；而在没有L2的情况下大约需要600ms。</p><h3 id="7-2-Use-Case：OTP生成双因素认证"><a href="#7-2-Use-Case：OTP生成双因素认证" class="headerlink" title="7.2 Use-Case：OTP生成双因素认证"></a>7.2 Use-Case：OTP生成双因素认证</h3><p>OTP：One-time Password app：用于对SA密封一个密钥，在将来的某个点恢复它来生成一个新的OTP。使用SANCTUARY的话，服务提供商就可以提供保护密钥的自定义app，而且无需在TEE中安装自己的TA。</p><p>（1）场景定义：two-factor authentication，网站上用于认证用户的策略</p><p>第一个因素，代表的是用户和用户的密钥；第二个因素，代表着生成fresh OTPs的硬件token或者移动设备。OTPs通过用户设备和验证服务器之间共享的密钥生成而来。这里的OTPs是通过一个时间戳算法生成的。</p><p>GenOTP app，TEE中包含了一对非对称密钥（SKdevice，PKdevice），在GenOTP的安装过程中，PKdevice被传送给retailer的后端</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/9.png" alt="img"></p><p>（2）生成密钥</p><p>通过上图第一行和第二行的操作后，SA得到了密钥KTOTP。SA可以一直保存该密钥，使用sealing技术将KTOTP进行加密，得到SSA_S（借助sealing TA根据SA binary 哈希值派生得到sealing操作的密钥KSA）。（也就是这边的第三行）</p><p>（3）产生OTP</p><p>当消费者想要生成一个fresh OTP来登录进零售商的online shop时，可以选择从LA生成OTP。SA通过get_state调用Sealing TA，Sealing TA恢复保存的数据，得到SSA_S，接下来根据SA binary哈希值得到Sealing的对称密钥，对SSA_S进行解密，解密后的数据为SSA，其中包含密钥KTOTP，运行TOTP算法利用KTOTP和当前的时间戳就可以得到OTP。</p><p>（4）GenOTP的性能</p><p><img src="/2020/06/20/2021-01-29-Sanctuary-NDSS2019/10.png" alt="img"></p><p>不适用L2 cache的运行时间是使用的1.3倍。通过该实验证明，即使在没有L2参与的情况下，SANCTUARY使用一个normal world和secure world组件所需要的时间是不会影响用户体验的，而且在这个过程中，普通的应用程序也可以继续</p><p>思考：</p><p>SANCTUARY instances 被tear down后，SA何去何从？</p><h2 id="8-相关工作"><a href="#8-相关工作" class="headerlink" title="8 相关工作"></a>8 相关工作</h2><p> Secure Software Architecture</p><p>Disadvantage of providing isolation using virtualization: i)their TCB contains a relatively large hypervisor, ii)they block usaga of virtualization for non-security purposes, ii)they require additional hardware to protect  against DMA attacks, iv)they negatively inflence the performance of the OS.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章是对&lt;strong&gt;SANTUARY:ARMing TrustZone with User-space Enclaves&lt;/strong&gt;这篇论文的阅读笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="ARM" scheme="http://yoursite.com/categories/ARM/"/>
    
    
      <category term="ARM" scheme="http://yoursite.com/tags/ARM/"/>
    
      <category term="TrustZone" scheme="http://yoursite.com/tags/TrustZone/"/>
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>ARM基础知识</title>
    <link href="http://yoursite.com/2020/06/20/2020-06-20-ARM-basic/"/>
    <id>http://yoursite.com/2020/06/20/2020-06-20-ARM-basic/</id>
    <published>2020-06-20T10:23:34.000Z</published>
    <updated>2020-06-20T13:22:36.013Z</updated>
    
    <content type="html"><![CDATA[<p>本笔记借鉴的主要是ARMv7的相关的介绍，目前的v8和v7在各方面有着一定的差异。</p><a id="more"></a><h1 id="ARM基本知识"><a href="#ARM基本知识" class="headerlink" title="ARM基本知识"></a>ARM基本知识</h1><h3 id="处理器模式"><a href="#处理器模式" class="headerlink" title="处理器模式"></a>处理器模式</h3><p>ARM处理器有7种CPU mode，其中6种特权模式：FIQ，IRQ，Supervisor（SVC），Abort（ABT），Undefined（UND），System（SYS）以及一种非特权模式：User（USR）。在引入TrustZone后，新增了一种monitor（MON） mode。</p><h3 id="FIQ和IRQ的区别"><a href="#FIQ和IRQ的区别" class="headerlink" title="FIQ和IRQ的区别"></a>FIQ和IRQ的区别</h3><ol><li>FIQ模式提供了更多的banked寄存器，r8到r16还有SPSR；而IRQ模式下，r8到r12没有对应的banked寄存器，也就意味着ARM的IRQ模式下，中断处理程序要自己保存这几个寄存器，退出中断处理程序时还要恢复这几个寄存器。而FIQ模式因为有这几个banked寄存器，模式切换时CPU自动保存这些值到banked寄存器，退出FIQ时自动恢复，节省了时间。</li><li>FIQ比IRQ优先级高，两者如果同时产生，FIQ先处理。</li><li>当CPU位于FIQ模式处理FIQ中断时，所有的中断都被屏蔽，FIQ会被很快执行。但当CPU位于IRQ模式处理IRQ中断时，如果此时有FIQ中断时，正在执行的IRQ中断会被抢断，CPU会切换到IFIQ模式去执行这个FIQ中断。</li><li>FIQ的入口地址是0x1c，IRQ的入口地址是0x18.0x18处只能放一条指令，为了不与0x1c处的FIQ冲突，这个位置只能跳转；而0x1c处之后没有任何中断向量表了，这样可以直接在1c处防止FIQ的中断处理程序，由于跳转的范围限制，至少少了一条跳转指令。（这条其实不是很理解）</li></ol><h3 id="ARM中断"><a href="#ARM中断" class="headerlink" title="ARM中断"></a>ARM中断</h3><p>通过特定指令触发的软件中断，引起CPU执行流程的改变，在ARMv7中有三个：SVC，SMC和HVC。</p><ul><li>SVC（supervisor call instruction)：通常在用户进程切换到内核进程中使用，比如syscall会让CPU进入到SVC mode；</li><li>HVC（Hypervisor call instruction）：为ARM虚拟化技术的扩展指令，触发CPU进入HYP mode；</li><li>而SMC（Secure Monitor Call）会触发CPU进入monitor mode。</li></ul><h2 id="ARM寄存器"><a href="#ARM寄存器" class="headerlink" title="ARM寄存器"></a>ARM寄存器</h2><p>关于arm的banked register的概念，翻译成中文的意思是影子寄存器。ARM有16个通用寄存器，这16个通用寄存器用4个bit来表示。但<strong>在不同的模式下，同样的4bit可能会指向不同的物理寄存器，这些物理寄存器就被称之为影子寄存器。</strong></p><p>不考虑TrustZone时，ARM中通用寄存器的数目：</p><ul><li>1个状态寄存器CPSR（Current Program Status Register，当前程序状态寄存器）（也就是R16）</li><li>5个异常模式下的状态寄存器的banked register（IRQ，FIQ，Abort，UND，SVC）</li><li>16个通用寄存器R0~R15</li><li>10个异常模式下的R13和R14的banked register</li><li>5个FIQ模式下的R8~R12的banked register</li></ul><p>CPSR可以在任何模式下被访问，每一种模式下的banked register是它专门的物理状态寄存器，称为SPSR（Saved Program Status Register，备份的程序状态寄存器），当异常发生时，SPSR用于保存CPSR的当前值，从异常退出时则由SPSR来恢复CPSR。</p><p>寄存器R13一般被用作堆栈指针SP。而处理器的每种运行模式都有自己独立的物理寄存器R13，在用户应用程序的初始化部分，一般都要初始化每种模式下的R13，使其指向该运行模式的栈空间。当程序运行进入异常模式时，将需要保护的寄存器放入R13所指向的堆栈，而当程序从异常模式返回时，则从对应的堆栈中恢复，采用这种方式从而保证异常发生后程序的正常执行。</p><p>R14是子程序链接寄存器LR（Link Register），当执行子程序调用指令（BL）时，R14可得到R15的备份。</p><p>常用的banked registers如下图所示。HYP模式是ARM为虚拟化扩展引入的Hypervisor mode，与TrustZone无关。</p><p><img src="/2020/06/20/2020-06-20-ARM-basic/1.jpg" alt="img"></p><p>另一类寄存器为CP15协处理器，主要用于系统配置，比如配置异常向量表、开关MMU等。一般在OS初始化时，首先会配置这些寄存器。与security extension相关的两个重要寄存器是SCR和MVBAR。</p><h3 id="SCR表格"><a href="#SCR表格" class="headerlink" title="SCR表格"></a>SCR表格</h3><table><thead><tr><th>Bits</th><th>Name</th><th>Function</th></tr></thead><tbody><tr><td>[0]</td><td>NS bit</td><td>0：secure；1：non-secure</td></tr><tr><td>[1]</td><td>IRQ</td><td>0：IRQ异常触发CPU进入IRQ mode；<br>1：IRQ异常触发进入monitor mode</td></tr><tr><td>[2]</td><td>FIQ</td><td>0：FIQ异常触发CPU进入FIQ mode；<br>1：IRQ异常触发进入monitor mode</td></tr><tr><td>[3]</td><td>EA</td><td>0：external abort异常触发CPU进入ABT mode； <br>1：external abort异常触发CPU进入monitor mode</td></tr><tr><td>[4]</td><td>FW</td><td>0：non-secure mode下CPSR的F bit不可写；<br>1：non-secure mode下CPSR的F bit可写</td></tr><tr><td>[5]</td><td>AW</td><td>0：non-secure mode下CPSR的A bit不可写；<br>1：non-secure mode下CPSR的A bit可写</td></tr><tr><td>[6:31]</td><td>reserved</td><td>-</td></tr></tbody></table><h3 id="MVBAR"><a href="#MVBAR" class="headerlink" title="MVBAR"></a>MVBAR</h3><table><thead><tr><th>Bits</th><th>Name</th><th>Function</th></tr></thead><tbody><tr><td>[5:31]</td><td>Monitor Vector Base Address</td><td>Monitor mode异常向量表的基地址</td></tr><tr><td>[0:4]</td><td>Reserved</td><td>-</td></tr></tbody></table><p>SCR和MVBAR都只能在secure state下才能修改。</p><h3 id="CPU状态"><a href="#CPU状态" class="headerlink" title="CPU状态"></a>CPU状态</h3><p>引入banked register的目的是，在当中断或者异常产生的时候，CPU会将当前“CPU的状态”保存在banked register中。从CPU角度来看，它的“状态”包括：</p><ol><li>PC（也就是R15）值；</li><li>CPSR的值</li></ol><p>当中断或异常发生的时候，CPU只是：</p><ol><li>被保存在当前模式下的R14中的PC值；</li><li>被保存在当前模式下的banked register中的CPSR值</li></ol><p>而通用寄存器R0中的是应用的状态，保存应用的状态是相对比较昂贵的，因为要保存至少13个寄存器（R0-12）。</p><h2 id="ARM-Cortex-A、R、M系列"><a href="#ARM-Cortex-A、R、M系列" class="headerlink" title="ARM Cortex-A、R、M系列"></a>ARM Cortex-A、R、M系列</h2><p>ARM Cortex-A(Application)：适用于应用领域，支持ARM和Thumb指令集，并支持虚拟地址和内存管理。</p><p>ARM Cortex-R(Realtime)：适用于高实时性领域，支持ARM和Thumb指令集，只支持物理地址，并支持内存管理</p><p>ARM Cortex-M(MicroController)：适用于微处理器领域，只支持Thumb指令集</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.cnblogs.com/locean/p/4945057.html" target="_blank" rel="noopener">ARM之FIQ（快速中断）IRQ（中断）</a></li><li><a href="https://www.jianshu.com/p/d786a65bbdc9" target="_blank" rel="noopener">ARM Trustzone技术（三）ARMv7-A Exceptions&amp;Interrupts Handling的安全扩展</a></li><li><a href="https://blog.csdn.net/qq405180763/article/details/39203037" target="_blank" rel="noopener">ARM寄存器（R13/R14/R15)</a></li><li><a href="[https://baike.baidu.com/item/%E5%BD%B1%E5%AD%90%E5%AF%84%E5%AD%98%E5%99%A8/6435933](https://baike.baidu.com/item/影子寄存器/6435933)">影子寄存器</a></li><li><a href="https://www.jianshu.com/p/ee41a4544874" target="_blank" rel="noopener">ARM Trustzone技术（二）ARMv7-A Processor mode&amp;registers的安全扩展</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本笔记借鉴的主要是ARMv7的相关的介绍，目前的v8和v7在各方面有着一定的差异。&lt;/p&gt;
    
    </summary>
    
      <category term="ARM" scheme="http://yoursite.com/categories/ARM/"/>
    
    
      <category term="ARM" scheme="http://yoursite.com/tags/ARM/"/>
    
      <category term="汇编" scheme="http://yoursite.com/tags/%E6%B1%87%E7%BC%96/"/>
    
  </entry>
  
  <entry>
    <title>TrustZone介绍</title>
    <link href="http://yoursite.com/2020/06/20/2020-06-20-TrustZone%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/2020/06/20/2020-06-20-TrustZone笔记-1/</id>
    <published>2020-06-20T10:23:34.000Z</published>
    <updated>2020-06-20T13:18:17.654Z</updated>
    
    <content type="html"><![CDATA[<p>本篇基于一些是对TrustZone的介绍，同样基于ARMv7.</p><a id="more"></a><h1 id="TrustZone"><a href="#TrustZone" class="headerlink" title="TrustZone"></a>TrustZone</h1><p>TPM（Trusted Platform Module）加解密的动作在芯片中进行，将信息存储在芯片中。但TPM无法给予运行时攻击。攻击者可能会在运行时进行破解，直接在内存中读取解密过的东西。</p><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/0.jpg" alt="img"></p><p>而TrustZone仅相信trust app，也就是由他保护的硬件，只有trust app才能够访问。这样，即使攻击者获得了操作系统的权限，也无法访问到敏感数据。这就是常说的“支持TrustZone技术的芯片能够提供对外围硬件资源的硬件级别的保护和安全隔离”。</p><p>TrustZone 是ARM公司未来解决可能遇到的软硬件问题提出来的一种硬件解决方案。关键思想在于<strong>隔离</strong>。</p><h2 id="TrustZone构成"><a href="#TrustZone构成" class="headerlink" title="TrustZone构成"></a>TrustZone构成</h2><p>该技术将CPU的工作装填分成了正常世界状态（Normal World Status，NWS）和安全世界状态（Secure World Status，SWS）。</p><p>设备启动之后CPU运行在普通世界，执行的是普通世界的APP。当触发了SMC系统调用进入安全世界后，CPU就跑在安全世界，运行安全世界的APP。此时，普通世界的APP是无法访问到安全APP所用的资源，包括内存、缓存、touch、display等，攻击者也无法获取到信息。</p><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/1.jpg" alt="img"></p><p>可选部分是看SOC是否支持保护外设功能。</p><p>软件部分所要完成的核心工作就是基于第二点可虚拟化内核，使用SMC调用，使CPU进行安全世界，从而跑安全世界的APP。内核虚拟化是指通过CPU虚拟化出两个内核，并且把安全世界的OS运行在内核0中，普通世界的OS运行在内核1中。两个OS独立运行在不同的虚拟内核中，通过时间片进行两个内核见切换执行。</p><p>TrustZone的硬件架构主要体现在内核虚拟化、内存隔离、外设/总线隔离技术和中断隔离技术。</p><h2 id="外设-总线隔离技术"><a href="#外设-总线隔离技术" class="headerlink" title="外设/总线隔离技术"></a>外设/总线隔离技术</h2><h3 id="AXI总线"><a href="#AXI总线" class="headerlink" title="AXI总线"></a>AXI总线</h3><p>AXI总线上每个读写信道都增加了一个额外的控制信号</p><ul><li>AWPROT[1]：总线写事务控制信号——低电平为安全写事务，高电平为非安全写事务</li><li>ARPROT[1]：总线读事务控制信号——低电平为安全读事务，高电平为非安全读事务</li></ul><p>当设备向总线提出读写事务请求时必须将控制信号发送到总线上。总线根据这个信号和CPU当前所处于的世界来判断是否能够读写。</p><h3 id="外设如何隔离？"><a href="#外设如何隔离？" class="headerlink" title="外设如何隔离？"></a>外设如何隔离？</h3><p>外设是与APB相连的，但APB总线没有诸如AXI总线上的相关安全控制信号，所以这里引入了APB-to-AXI桥，外设还是与APB总线连接，而APB-to-AXI桥上的TZPCDECPORT信号决定配置外设是否安全。该桥保证非安全世界无法访问外设。</p><p>TZPCDECPORT输入信号可以在SoC设计时静态地设置，也可以通过TrustZone保护控制器（TrustZone Protection Controller，TZPC）进行编程，在程序运行时动态地设置，也就是可以通过TZPC动态配置地外设是安全或者是非安全的。</p><h2 id="内存隔离技术"><a href="#内存隔离技术" class="headerlink" title="内存隔离技术"></a>内存隔离技术</h2><h3 id="RAM，ROM如何隔离？"><a href="#RAM，ROM如何隔离？" class="headerlink" title="RAM，ROM如何隔离？"></a>RAM，ROM如何隔离？</h3><p>CPU core MMU 的安全隔离主要针对的是CPU内存空间的安全访问控制，TrustZone通过地址空间控制器（TrustZone Address Space Controller，TZASC）和存储适配器（TrustZone Memory Adaptor，TZMA）来保障物理内存（DRAM）的安全。针对on-SoC的静态内存（ROM和SRAM）的区域划分，通过使用TZMA来完成。</p><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/2.jpg" alt="img"></p><p>TZASC可以把内存地址空间划分为一系列的内存空间，对两个世界的APP分别配置（通过新增一条地址线表示NS位），运行在安全世界的被配置为安全的，并防止非安全事务访问安全内存空间。另外，TZASC将设备分区为几个安全设备，防止非安全事务访问安全设备。（<em>TZASC只能用来支持存储映射设备，不能用于块设备？</em>）</p><p>cache和内存为了支持TrustZone的安全策略，也做了相应的扩展。cache的tag增加了NS位，用于标识这一行的安全状态。低电平标识安全状态，而高电平标识处于非安全状态。内存管理单元（memory management unit，MMU）的tag增加了NSTID位，功能与NS一样。</p><p>TZC400接在SRAM上用于保护SRAM内存，可接在DDRC上用于保护DDR内存。保护内存，将内存划分成16个region，每个Master都有一个nsaid标识。设置每个region对nsaid的访问权限，也可以设置每个region的secure/non-secure权限。访问的控制流程：如果PE是以secure发起的访问，则直接检查该region的secure权限；如果是以non-secure发起的访问，则先检查的non-secure权限，再检查该region的nsaid权限。</p><h2 id="中断隔离技术"><a href="#中断隔离技术" class="headerlink" title="中断隔离技术"></a>中断隔离技术</h2><h3 id="如何进入安全世界"><a href="#如何进入安全世界" class="headerlink" title="如何进入安全世界"></a>如何进入安全世界</h3><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/3.jpg" alt="img"></p><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/4.jpg" alt="img"></p><p>上面两张图显示了如何在两个世界中进行切换，这里引入了特殊机制——监控模式（MON），负责不同执行环境的切换。</p><ol><li>普通世界的APP通过syscall svc指令进入kernel space OS（SVC mode）；</li><li>kernel space OS通过smc指令进入monitor mode；</li><li>运行在monitor mode的代码首先保存non-secure状态的CPU contexts（上下文），比如说lr，sp，spsr等等，然后将CPU NS位置为0，表示进入secure status，通过rfe（return from exception）进入secure OS；</li><li>secure OS唤醒secure APP处理完相应的安全资源访问请求后，发送smc指令，再次回到monitor mode；</li><li>运行在monitor mode下的代码同样首先保存secure状态的CPU contexts，然后将CPU NS位置为1，表示进入non-secure status，并恢复non-secure状态下的CPU contexts，通过rfe指令重新回到non-secure OS。</li></ol><p>除了软件调用SMC，上图1中的”2步骤“显示了也可以通过配置硬件中断触发进入monitor模式，比如FIQ，IRQ，external data abort，external prefetch abort，都可以通过配置系统寄存器来决定哪些硬件中断可以触发CPU陷入monitor mode。</p><p><strong>ARM处理器是如何知道当前处于什么状态的？</strong></p><p>支持TrustZone的ARM处理器的协处理器CP15有个安全配置寄存器（Secure Configuration Register，SCR），该寄存器的NS位用于指明当前的系统状态。NS为低电平时，处于安全状态；否则，就处于非安全状态。</p><p>从上面的图中可以看出来，系统的安全状态与系统的应用模式和特权模式无关。两个世界都有用户模式和特权模式，但在不同模式下所具有的权限是不一样的，NS位只能被运行在处于特权模式的安全世界中的APP改变，系统在非安全状态下不能访问SCR。 而当系统位于monitor模式下，不管NS是0还是1，都可以访问所有安全世界的资源。</p><p><strong>如何进入monitor模式？</strong></p><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/5.jpg" alt="img"></p><p>进入monitor模式有以下三个方法：</p><ul><li>SMC是一个特殊指令，类似于软件中断指令（software interrupt，SWI），由此进入monitor模式；</li><li>外部中止预取指令外部中止和数据中止，外部中止是访问存储系统时发生，但不被MMU所检测到异常，通常发生在普通世界访问安全世界资源时发生；</li><li>中断，包括FIQ（Fast Interrupt Request，快速中断请求），IRQ（Interrupt Request，中断请求）（FIQ是安全世界的中断源，IRQ是普通世界的中断源）</li></ul><p>第一类进入monitor模式是无条件的，而后两种则依赖于SCR的配置。</p><ul><li>针对第二类，EA=0时，表示外部中止时处理器进入中止模式；EA=1时，表示外部中止时处理器进入monitor模式</li><li>针对第三类（IRQ），IRQ=0时，表示发生IRQ时处理器进入中止模式；IRQ=1时，表示发生IRQ时处理器进入monitor模式</li><li>针对第三类（FIQ），FIQ=0时，表示发生FIQ时处理器进入中止模式；FIQ=1时，表示发生FIQ时处理器进入monitor模式</li></ul><p><strong>如何从安全世界返回普通世界？</strong></p><p>也要从monitor模式切换回来（应该是上述流程图的反向）。</p><p>运行在安全世界的软件有权改变SCR的NS位，但不建议这么做，因为一旦NS位被置为1，系统就会立马切换到non-secure状态，此时pipline中缓存的secure state下运行的指令、data register中保存的secure data都会变成non-secure，这样会使得非安全世界看到流水线的指令以及正在寄存器中的数据的可能。通常只有monitor可能直接修改主SCR的NS位。</p><p><strong>TrustZone的中断控制器</strong></p><p>在ARM传统的向量中断控制器（VIC）基础上，还添加了TrustZone中断控制器（TZIC）。TZIC和VIC通过菊花链的方式连接组成两级中断控制系统，从而做到普通中断和安全中断的隔离，安全中断无法被普通世界截获。TZIC是第一级中断控制器，所有中断源的中断请求都连在TZIC上，最先截获设备的中断请求，通过对TZIC的TZICIntSelect寄存器进行编程，可以对中断源产生的中断类型进行设置。这儿举个例子，如果TZICIntSelect中的某一位为1，相应的中断源请求被配置为FIQ中断，如果为0，则该中断源的中断请求就被交给VIC来处理。</p><p>TZICIntSelect寄存器复位值为0，也就是默认所有中断都交给VIC处理。这样，对于不支持TrustZone的软件系统来说，可以把TZIC看作是全透明的。</p><p>下图中，中断1和2在TZICIntSelect中都设置为1，所以直接交给了TZIC处理；</p><p>中断3在TZICIntSelect设置为0，交给VIC处理；</p><p>中断4在TZICIntSelect中设置为0，交给VIC处理，但在VICIntSelect中也设置为0，又交还给了TZIC。</p><p>也就是中断1,2,4都属于FIQ，而中断3属于IRQ。</p><p><img src="/2020/06/20/2020-06-20-TrustZone笔记-1/5.jpg" alt="img"></p><p><strong>TrustZone的异常向量表</strong></p><p>异常向量表的作用就是告诉CPU在不同的异常发生后，入口函数分别在哪里。</p><p>支持TrustZone的ARM处理器有三个异常向量表：普通世界的异常向量表，安全世界的异常向量表和monitor的异常向量表。</p><p>配置Vector table除了需要指定各个exception handler的入口函数以外，最重要的是指定vector table的地址，这样CPU才能计算出各个入口函数的地址。系统开机时，安全世界的异常向量表基地址是0x00000000（normal vectors）或0xffff0000（high vectors），取决于处理器输入信号VINTHI（cp15寄存器SCTLR的V bit），其他两个向量表的基地址开机时未定义，使用前必须软件设置。</p><p>与以往的ARM处理器不同的是，每个异常向量表的位置在运行时可以动态移动，将新的向量表基地址写入CP15的VBAR寄存器即可，monitor的向量表基地址由monitor的异常向量表基地址寄存器指定。</p><p>另外，普通世界与安全世界的向量表基地址除了与VBAR有关，还与处理器的V位有段，v=1，则向量表基地址采用高地址，而与VBAR无关。普通世界和安全世界的V位是独立的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.csdn.net/hovan/article/details/42520879" target="_blank" rel="noopener">trust zone之我见</a></li><li><a href="https://zhuanlan.zhihu.com/p/88629648" target="_blank" rel="noopener">浅析ARM TrustZone与Intel SGX</a></li><li><a href="https://www.jianshu.com/p/3f952f2c8bf4" target="_blank" rel="noopener">ARM Trustzone技术（一）综述</a></li><li><a href="https://paper.seebug.org/296/" target="_blank" rel="noopener">TrustZone安全技术研究</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇基于一些是对TrustZone的介绍，同样基于ARMv7.&lt;/p&gt;
    
    </summary>
    
      <category term="ARM" scheme="http://yoursite.com/categories/ARM/"/>
    
    
      <category term="ARM" scheme="http://yoursite.com/tags/ARM/"/>
    
      <category term="TrustZone" scheme="http://yoursite.com/tags/TrustZone/"/>
    
  </entry>
  
  <entry>
    <title>python hahslib</title>
    <link href="http://yoursite.com/2020/04/19/2020-06-20-python%20hahslib/"/>
    <id>http://yoursite.com/2020/04/19/2020-06-20-python hahslib/</id>
    <published>2020-04-19T06:23:34.000Z</published>
    <updated>2020-06-20T10:14:38.483Z</updated>
    
    <content type="html"><![CDATA[<p>在python环境中调用AES-GCM库</p><a id="more"></a><p>毕设中需要一个文件加密的步骤，本来是打算随便找个库来加密解密就好了，但是导师建议使用AES-GCM，阅读了有关文献，GCM模式能够进行身份验证，相对来说比较推荐。</p><p>开始考虑的还是希望直接调用已有的库比如openssl，就比较方便嘛，但是openssl不支持对AES-GCM模式的命令行调用。但是openssl中是有GCM的头文件的，但是C处理文件实在太麻烦了。。所以还是选择了python吧。</p><p>python中有个库cryptemis是可以对图片文件进行AES加密处理的，但是看代码用的模式是AES-CFB。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aes_cipher = AES.new(key, AES.MODE_CFB, iv)</span><br></pre></td></tr></table></figure><p>git clone下来之后把mode改成了GCM也得到了预期的效果。但是在两个容器中配置的过程比较繁琐，这里记录一下。</p><p>python3中AES相关的库是pycryptodome，python2中是pycryptodom。<br>这里调用了hashlib库是为了获得相对来说更乱序的iv值。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">key = hl.sha3_512(hl.sha1(password.encode()).hexdigest().encode()).hexdigest()[:AES.block_size].encode()</span><br><span class="line">iv = hl.sha3_512(hl.blake2s(password.encode()).hexdigest().encode()).hexdigest()[:AES.block_size].encode()</span><br></pre></td></tr></table></figure><p>直接测试的时候发现出现了下述错误</p><blockquote><p>AttributeError: module ‘hashlib’ has no attribute ‘blake2b’</p></blockquote><p>直接百度或者google的时候都说是自己的文件名与导入的报名撞了，但这里并没有呀。而且在我电脑上的环境上跑的很顺畅。hashlib是python内建模块，它的版本与python挂钩，我windows上的python是3.7，而服务器中的是2.7，大概率是版本问题。通过dir(hashlib)查看了一下，确实没有相应的函数，那么接下来就是升级python了。hashlib的官方文档中说3.6中升级有了blake2b，也就是说只需要升级到3.6及以上即可。</p><p>安装python3.7</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install software-properties-common</span><br><span class="line">sudo add-apt-repository ppa:deadsnakes/ppa</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt install python3.7</span><br><span class="line">python3.7 –version</span><br></pre></td></tr></table></figure><p>将python3的链接指向python3.7</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -rf /usr/bin/python3</span><br><span class="line">sudo rm -rf /usr/bin/pip3</span><br></pre></td></tr></table></figure><p>添加python3的软链接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /usr/bin/python3.7 /usr/bin/python3</span><br></pre></td></tr></table></figure><p>安装pip</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://bootstrap.pypa.io/get-pip.py</span><br><span class="line">python3 get-pip.py   //运行安装脚本</span><br></pre></td></tr></table></figure><p>添加pip3的软链接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /usr/bin/pip3.7 /usr/bin/pip3</span><br></pre></td></tr></table></figure><p>然后就可以依次安装numpy包、pillow包、pycryptodome包。</p><p>参考文献</p><ul><li><a href="https://kb.kutu66.com/encryption/post_131657" target="_blank" rel="noopener">encryption-如何选择AES加密模式</a></li><li><a href="https://github.com/0x01h/cryptemis" target="_blank" rel="noopener">cryptemis</a></li><li><a href="https://www.digitalocean.com/community/questions/unable-to-install-pyhton-3-7-version-on-ubuntu-16-04-error-couldn-t-find-any-package-by-regex-python3-7" target="_blank" rel="noopener">下载python3.7</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在python环境中调用AES-GCM库&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>NVDLA学习</title>
    <link href="http://yoursite.com/2019/12/29/2020-04-19-NVDLA%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2019/12/29/2020-04-19-NVDLA学习/</id>
    <published>2019-12-29T14:17:15.000Z</published>
    <updated>2020-04-19T07:56:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>毕设要用NVDLA，在这里记录一下NVDLA的安装过程和学习。</p><a id="more"></a><h1 id="NVDLA-Virtual-Simulator"><a href="#NVDLA-Virtual-Simulator" class="headerlink" title="NVDLA Virtual Simulator"></a>NVDLA Virtual Simulator</h1><p>NVDLA的安装文档写的很详细，但已经是2017年写的，很长时间没更新，而且对很多工具的版本要求都很emm怀旧，安装的时候还是遇到几个问题。NVDLA也可以直接运用docker版本的，但直接用原代码编译能加强对NVDLA整体的理解嘛（虽然我编译完根本不知道发生了啥:(）</p><p>NVDLA Open Source Project中主要有四个文件夹。</p><ul><li><p>doc<br>Docunmentation for NVDLA</p></li><li><p>hw<br>RTL, Cmodel and testbench for NVDLA</p></li><li><p>sw<br>NVDLA SW</p></li><li><p>vp<br>Virtual Platform for NVDLA</p></li></ul><h2 id="下载Virtual-Simulator"><a href="#下载Virtual-Simulator" class="headerlink" title="下载Virtual Simulator"></a>下载Virtual Simulator</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/nvdla/vp.git  </span><br><span class="line">cd vp  </span><br><span class="line">git submodule update --init --recursive</span><br></pre></td></tr></table></figure><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><h3 id="install-required-tools-and-libraries"><a href="#install-required-tools-and-libraries" class="headerlink" title="install required tools and libraries"></a>install required tools and libraries</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install g++ cmake libboost-dev python-dev libglib2.0-dev libpixman-1-dev liblua5.2-dev swig libcap-dev libattr1-dev</span><br></pre></td></tr></table></figure><h3 id="install-SystemC-2-3-0"><a href="#install-SystemC-2-3-0" class="headerlink" title="install SystemC 2.3.0"></a>install SystemC 2.3.0</h3><p>这里需要注意的是必须用的systemC 2.3.0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wget -O systemc-2.3.0a.tar.gz http://www.accellera.org/images/downloads/standards/systemc/systemc-2.3.0a.tar.gz</span><br><span class="line">tar -xzvf systemc-2.3.0a.tar.gz</span><br><span class="line">cd systemc-2.3.0a</span><br><span class="line">sudo mkdir -p /usr/local/systemc-2.3.0/</span><br><span class="line">mkdir objdir</span><br><span class="line">cd objdir</span><br><span class="line">../configure --prefix=/usr/local/systemc-2.3.0</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><h3 id="install-perl-package-required"><a href="#install-perl-package-required" class="headerlink" title="install perl package required"></a>install perl package required</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">wget -O YAML-1.24.tar.gz http://search.cpan.org/CPAN/authors/id/T/TI/TINITA/YAML-1.24.tar.gz</span><br><span class="line">tar -xzvf YAML-1.24.tar.gz</span><br><span class="line">cd YAML-1.24</span><br><span class="line">perl Makefile.PL</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line">wget -O IO-Tee-0.65.tar.gz http://search.cpan.org/CPAN/authors/id/N/NE/NEILB/IO-Tee-0.65.tar.gz</span><br><span class="line">tar -xzvf IO-Tee-0.65.tar.gz</span><br><span class="line">cd IO-Tee-0.65</span><br><span class="line">perl Makefile.PL</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><h3 id="install-NVDLA-CMOD"><a href="#install-NVDLA-CMOD" class="headerlink" title="install NVDLA CMOD"></a>install NVDLA CMOD</h3><p>CMOD安装需要保证环境配置得当，我的环境配置版本与readme中略有不同。</p><ul><li>java -jdk1.8</li><li>Perl</li><li>CPP</li><li>python</li><li>System -systemc-2.3.0</li><li>[for Verilator builds] Verilator-Verilator</li><li>[for Verilator builds] clang-clang </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/nvdla/hw.git</span><br><span class="line">cd hw</span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>这一步执行完毕后需要按照提示输入对应的工具路径，这里我的工具路径如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DEFAULT_CPP:=/usr/bin/cpp</span><br><span class="line">DEFAULT_GCC:=/usr/bin/g++</span><br><span class="line">DEFAULT_PERL:=/usr/bin/perl</span><br><span class="line">DEFAULT_JAVA:=/usr/bin/java</span><br><span class="line">DEFAULT_SYSTEMC:=~/systemc-2.3.0</span><br><span class="line">DEFAULT_VERILATOR:=verilator</span><br><span class="line">DEFAULT_CLANG:=clang</span><br><span class="line">DEFAULT_PROJ:=nv_small</span><br></pre></td></tr></table></figure><p>make执行完毕后再输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tools/bin/tmake -build cmod_top</span><br></pre></td></tr></table></figure><h2 id="Build-and-Install-the-Virtual-Simulator"><a href="#Build-and-Install-the-Virtual-Simulator" class="headerlink" title="Build and Install the Virtual Simulator"></a>Build and Install the Virtual Simulator</h2><h3 id="Cmake-build-under-the-vp-repository-directory"><a href="#Cmake-build-under-the-vp-repository-directory" class="headerlink" title="Cmake build under the vp repository directory"></a>Cmake build under the vp repository directory</h3><p>build/是希望安装virtual simulator的位置，/usr/local/systemC是SystemC的安装目录，~/hw是本地NVDLA HW仓库的位置，nv_small是NVDLA HW project name.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmake -DCMAKE_INSTALL_PREFIX=build/ -DSYSTEMC_PREFIX=~/usr/local/systemc-2.3.0/ -DNVDLA_HW_PREFIX=~/hw -DNVDLA_HW_PROJECT=nv_small</span><br></pre></td></tr></table></figure><h3 id="Compile-and-install"><a href="#Compile-and-install" class="headerlink" title="Compile and install"></a>Compile and install</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd vp/</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>编译vp中遇到了很多问题，里面直接导致无法运行的是这个</p><blockquote><p>/usr/local/systemc-2.3.0/include/sysc/packages/boost/get_pointer.hpp:21:40: error: ‘template<class> class std::auto_ptr’ is deprecated [-Werror=deprecated-declarations]<br> template<class t> T * get_pointer(std::auto_ptr<t> const&amp; p)</t></class></class></p></blockquote><p>产生的主要原因issue上的作者说是gcc版本应该用4.8的，后来在网上查到了不用修改gcc版本就可以成功编译的方法。<br><strong>修改vp/CMakeLists.txt</strong>(参考网址：<a href="https://blog.csdn.net/hywCogost/article/details/82114529" target="_blank" rel="noopener">https://blog.csdn.net/hywCogost/article/details/82114529</a>)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 注释掉以下三行</span><br><span class="line"># set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -DSC_INCLUDE_DYNAMIC_PROCESSES -Wall -Werror $&#123;AWS_FPGA_CFLAGS&#125; $&#123;TRACE_CFLAGS&#125;&quot;)</span><br><span class="line"># set(CMAKE_CXX_FLAGS_DEBUG &quot;$&#123;CMAKE_CXX_FLAGS_DEBUG&#125; -DSC_INCLUDE_DYNAMIC_PROCESSES -Wall -Werror -DDEBUG_LOG=1 $&#123;AWS_FPGA_CFLAGS&#125; $&#123;TRACE_CFLAGS&#125;&quot;)</span><br><span class="line"># set(CMAKE_CXX_FLAGS_RELEASE &quot;$&#123;CMAKE_CXX_FLAGS_RELEASE&#125; -DSC_INCLUDE_DYNAMIC_PROCESSES -Wall -Werror $&#123;AWS_FPGA_CFLAGS&#125; $&#123;TRACE_CFLAGS&#125;&quot;)</span><br><span class="line"># 添加如下：</span><br><span class="line">set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -DSC_INCLUDE_DYNAMIC_PROCESSES -Wall  $&#123;AWS_FPGA_CFLAGS&#125; $&#123;TRACE_CFLAGS&#125;&quot;)</span><br><span class="line">set(CMAKE_CXX_FLAGS_DEBUG &quot;$&#123;CMAKE_CXX_FLAGS_DEBUG&#125; -DSC_INCLUDE_DYNAMIC_PROCESSES -Wall  -DDEBUG_LOG=1 $&#123;AWS_FPGA_CFLAGS&#125; $&#123;TRACE_CFLAGS&#125;&quot;)</span><br><span class="line">set(CMAKE_CXX_FLAGS_RELEASE &quot;$&#123;CMAKE_CXX_FLAGS_RELEASE&#125; -DSC_INCLUDE_DYNAMIC_PROCESSES -Wall  $&#123;AWS_FPGA_CFLAGS&#125; $&#123;TRACE_CFLAGS&#125;&quot;)</span><br></pre></td></tr></table></figure><p>也就是将这三条语句中的Werror去掉，同样的操作还要将子目录下CMakeList.txt中的CMake_CXX_FLAGS语句中国的-Werror删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">./models/nvdla/CMakeLists.txt +87</span><br><span class="line">./models/nvdla/CMakeLists.txt +88</span><br><span class="line">./models/nvdla/CMakeLists.txt +89</span><br><span class="line"></span><br><span class="line">./fpga/aws-fpga/fpga_sc_wrapper/CMakeLists.txt +91</span><br><span class="line">./fpga/aws-fpga/fpga_sc_wrapper/CMakeLists.txt +92</span><br><span class="line">./fpga/aws-fpga/fpga_sc_wrapper/CMakeLists.txt +93</span><br><span class="line"></span><br><span class="line">./fpga/aws-fpga/cosim_sc_wrapper/CMakeLists.txt +82</span><br><span class="line">./fpga/aws-fpga/cosim_sc_wrapper/CMakeLists.txt +83</span><br><span class="line">./fpga/aws-fpga/cosim_sc_wrapper/CMakeLists.txt +84</span><br></pre></td></tr></table></figure><h2 id="Running-the-Virtual-Simulator"><a href="#Running-the-Virtual-Simulator" class="headerlink" title="Running the Virtual Simulator"></a>Running the Virtual Simulator</h2><p>要运行virtual simulator首先要准备好linux kernel image，可以自己手动编译或者直接用NVDLA项目中已经编译好的image。我因为开始的一个智障报错把两个都试了一遍。用NVDLA中已经编译好的image比较省事且快，但文档中说的不是很清楚，但在这个<a href="https://github.com/nvdla/vp/issues/1" target="_blank" rel="noopener">issue</a>解释清楚了。</p><p>我就简单说一下里面没有提到的部分，就是修改aarcha64_nvdla.lua中的kernel和driver的路径。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-kernel /path/to/sw/prebuilt/arm64-linux/image/linux/Image</span><br><span class="line">-driver /path/to/sw/prebuilt/arm64-linux/image/linux/rootfs.ext4</span><br></pre></td></tr></table></figure><p>以下来简单说一下手动交叉编译一个linux内核的过程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://buildroot.org/downloads/buildroot-2017.11.tar.gz</span><br><span class="line">tar -zxvf buildroot-2017.11.tar.gz</span><br><span class="line">cd buildroot-2017.11/</span><br><span class="line">sudo apt-get install libncurses5-dev // make menuconfig时会用到</span><br><span class="line">make qemu_aarch64_virt_defconfig</span><br><span class="line">make menuconfig</span><br></pre></td></tr></table></figure><p>需要自定义的配置如下：</p><blockquote><ul><li>Target Options -&gt; Target Architecture -&gt; AArch64 (little endian)  </li><li>Target Options -&gt; Target Architecture Variant -&gt; cortex-A57  </li><li>Toolchain -&gt; Custom kernel headers series -&gt; 4.13.x  </li><li>Toolchain -&gt; Toolchain type -&gt; External toolchain    </li><li>Toolchain -&gt; Toolchain -&gt; Linaro AArch64 2017.08  </li><li>Toolchain -&gt; Toolchain origin -&gt; Toolchain to be downloaded and installed  </li><li>Kernel -&gt; () Kernel version -&gt; 4.13.3  </li><li>Kernel -&gt; Kernel configuration -&gt; Use the architecture default configuration  </li><li>System configuration -&gt; Enable root login with password -&gt; Y  </li><li>System configuration -&gt; Root password -&gt; nvdla  </li><li>Target Packages -&gt; Show packages that are also provided by busybox -&gt; Y  </li><li>Target Packages -&gt; Networking applications -&gt; openssh -&gt; Y  </li></ul></blockquote><p>最后，编译</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j4</span><br></pre></td></tr></table></figure><h3 id="Running-Kernel-Image-in-the-Virtual-Simulator"><a href="#Running-Kernel-Image-in-the-Virtual-Simulator" class="headerlink" title="Running Kernel Image in the Virtual Simulator"></a>Running Kernel Image in the Virtual Simulator</h3><p>在运行之前，需要修改conf/aarch64_nvdla.lua中的路径信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-driver ~/vp/buildroot-2017.11/output/images/rootfs.ext4</span><br><span class="line">-kernel ~/vp/buildroor-2017.11/output/images/Images</span><br></pre></td></tr></table></figure><p>接下来，就可以运行文件。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> SC_SIGNAL_WRITE_CHECK=DISABLE</span><br><span class="line">./build/bin/aarch64_toplevel -c conf/aarch64_nvdla.lua</span><br></pre></td></tr></table></figure><p>然后我又遇到了这个问题</p><blockquote><p>Could not set up host forwarding rule ‘tcp::6666-:6666’</p></blockquote><p>针对这个问题，我直接把lua文件中的<code>tcp::6666-:6666</code>这段给删了，接下来运行未发生报错。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mount -t 9p -o trans=virtio r /mnt</span><br><span class="line">cd /mnt/tests/hello</span><br><span class="line">./aarch64_hello</span><br></pre></td></tr></table></figure><p>运行成功，没有报错。</p><h1 id="NVDLA-documentation"><a href="#NVDLA-documentation" class="headerlink" title="NVDLA documentation"></a>NVDLA documentation</h1><p>NVDLA在accelerate deep learning 中起到的是inference的作用，也就是一个网络已经训练好了，需要做实际应用了。</p><h1 id="nvdla-vp模拟推断"><a href="#nvdla-vp模拟推断" class="headerlink" title="nvdla vp模拟推断"></a>nvdla vp模拟推断</h1><p>nvdla的文档真的太少了。。。官方文档给了就跟没给一样，开发过程完全靠issue上一起摸着石头过河的人的提问。。。这里还是要感谢导师和学长的帮助。</p><p>NVDLA在virtual platform上应该只能进行inference的操作，并且会很慢。nvdla_compiler是编译器，将caffe网络文件编译成NVDLA可读的nvdla文件，也就是最后生成的fast-math.nvdla。</p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./nvdla_compiler --profile fast-math --configtarget nv_small --cprecision int8 --prototxt models/deep-residual-networks/prototxt/ResNet-50-deploy.prototxt --caffemodel ResNet-50-model.caffemodel --informat nchw --calibtable resnet50.json</span><br></pre></td></tr></table></figure><ul><li><p><code>--profile</code>：编译生成的nvdla的四种模式（performance|basic|default|fast-math），fast_math应该是占用资源最少的一种模式，fast-math的时候一共162层，但如果是default，一共有334层</p></li><li><p><code>--configtarget</code>：生成的文件的规模，可以选择的是nv_small,nv_large,nv_full,对应的分别是资源的多少，nv_small&lt;nv_large&lt;nv_full;</p></li><li><p><code>--cprecision</code>：精度，默认fp16，nv_small只支持int8，如果使用int8的话，需要加上calibtable参数（for quantizing pre-trained models from floating point to int8 and programming converters in NVDLA for scaling/re-scaling tensors）;</p></li><li><p><code>--prototxt</code>：prototxt文件是负责网络结构的定义,我这边的prototxt和caffemodel文件都来源于<a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener">何恺明的github</a></p></li><li><p><code>--caffemodel</code>：caffemodel文件存储net参数以及所有layer的weights.</p></li><li><p><code>--informat</code>：该参数的设置是为了消除一个错误警报，但是作者在github上面有说该error其实出现了也无所谓，建议无视</p></li><li><p><code>--calibtable</code>：调用resnet50.json文件，该文件是vp自带的，应该是精度转化的json文件，如果是测试int8就需要</p></li></ul><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>运行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./nv_runtime  --loadable fast_math.nvdla --image boat.jpg  --rawdump --normalize 1</span><br></pre></td></tr></table></figure><p>runtime只能在aarch64架构下运行，所以在vp上会利用qemu先进入aarch64架构中，然后会安装nvdla driver，这里分别有opendla_1.ko和opendla_2.ko，opendla_1.ko是专门给nv_full的，opendla_2.ko供nv_small和nv_large使用。</p><ul><li><p><code>--image</code>：后面跟的要进行推断的图片文件</p></li><li><p><code>--normalize</code>：标准化输入的图片</p></li><li><p><code>--rawdump</code>：将输出结果从小数变成0、1</p></li></ul><p>我目前在软件上推断一次要两个小时，用的nv_full，用nv_small一直中间没有推断结束就断掉，貌似issue上有人有类似问题、、尴尬。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="http://nvdla.org/vp.html" target="_blank" rel="noopener">Virtual Platform</a></li><li><a href="https://blog.csdn.net/hywCogost/article/details/82114529" target="_blank" rel="noopener">Ubuntu16.04 NVDLA环境搭建</a></li><li><a href="https://blog.csdn.net/smiler_sun/article/details/89608320" target="_blank" rel="noopener">NVDLA virtual platform环境搭建</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;毕设要用NVDLA，在这里记录一下NVDLA的安装过程和学习。&lt;/p&gt;
    
    </summary>
    
      <category term="NVDLA" scheme="http://yoursite.com/categories/NVDLA/"/>
    
    
      <category term="NVDLA" scheme="http://yoursite.com/tags/NVDLA/"/>
    
  </entry>
  
  <entry>
    <title>最近读的闲书-2019</title>
    <link href="http://yoursite.com/2019/12/22/2019-12-22-book-recent/"/>
    <id>http://yoursite.com/2019/12/22/2019-12-22-book-recent/</id>
    <published>2019-12-22T09:02:52.000Z</published>
    <updated>2021-05-09T10:33:11.353Z</updated>
    
    <content type="html"><![CDATA[<p>发现了“微信读书”这个宝藏APP，大部分的名家作品都能找得到www。这两周读了汪曾祺的散文集《宋朝人的吃喝》和张爱玲的《沉香屑第一炉香》和《小团圆》。随便写写读后感。</p><a id="more"></a><p>汪曾祺，张爱玲，木心是近现代我最喜欢的三个作家。汪曾祺的作品尤为适合心情闲散的时候读，有一种治愈的感觉。</p><h1 id="宋朝人的吃喝"><a href="#宋朝人的吃喝" class="headerlink" title="宋朝人的吃喝"></a>宋朝人的吃喝</h1><p>打算入手这本的实体书了，叫宋朝人的吃喝不过是里面有一章节的名字，谈写作，谈名人，谈食物的都有。谈写作的部分写的极好，适合广大高中生阅读。我很赞同汪老“随遇而安”的人生态度，有一说一，这样容易过的幸福。</p><p>前两天和同学聊天，他一段话说的极好。</p><blockquote><p>不过生活的本质，都是回归无聊和平淡的，哪怕结了婚也一样，所以还是得学会生活。</p></blockquote><p>汪老我觉得是个骨子里非常会生活的人，他这一生没有吃过多少苦，吃的那一点点苦，反而给平淡的生活加了点料，晚年回想起来有种甘之若饴的滋味。</p><h1 id="张爱玲小说集"><a href="#张爱玲小说集" class="headerlink" title="张爱玲小说集"></a>张爱玲小说集</h1><p>《沉香屑第一炉香》听说要拍了，选角是什么鬼(╯‵□′)╯︵┻━┻</p><p>原作本身是极有电影画面感的，电影配上这阵容，算了算了。</p><p>张爱玲本人其实就是一个很有意思的人，杨绛说她古怪、奇装异服、丑，我觉得有点偏颇。张爱玲自己也知道自己性格孤僻，不是个开朗活泼的人，所以朋友少，其实也很容易感到自卑。而在衣服上，张爱玲是个很注重生活情调的人，她不管是骨子里还是表现出来的，都是个完完全全的小资产阶级。而长相上，我觉得可以用当代话来说，是一种超模脸，冷淡有气质。</p><p>张爱玲的家境是让人羡慕的，祖上三代赫赫有名，但同时也是不幸。荣耀的像贾府一样的家庭在走到她这一代的时候已经是非常畸形的，而她也没有得到像贾宝玉那样的宠爱。父亲暴戾，母亲任性，上天赋予了她天才的一面，也给了她异于常人的敏感多思。敏感的人，往往是不容易感到幸福的。  </p><p>读小团圆，读到前面，她絮絮叨叨地说自己的家庭，谈的最多的是蕊秋，总说着对母亲的死心，足见她有多么爱自己的母亲。因为爱的浓烈，也最容易被伤害。蕊秋作为母亲，是极其不合格的，她从来没有想过如何做好一名母亲，孩子很小的时候，就离开他们去追求自己的幸福，寻求称为一名新时代的女性。回来了之后，也少有母女、母子的温存，吃饭的时候也只是教育批评。终其一生，不过是一个被宠坏了的富家小姐，从来就没有成长过。张爱玲和张子静生活在这样的家庭，着实是让人心疼的。</p><p>张爱玲一生自己活的清清楚楚明明白白，她不会表面一套背地一套，作品也总是就地取材，身边的人都是她的作品原型，她就是个天生的作家。</p><p>读张爱玲，有时候有种梦回高中的感觉，那时候读《金锁记》，有一种后背发凉的悲哀；读《天才梦》，被文笔惊艳到。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;发现了“微信读书”这个宝藏APP，大部分的名家作品都能找得到www。这两周读了汪曾祺的散文集《宋朝人的吃喝》和张爱玲的《沉香屑第一炉香》和《小团圆》。随便写写读后感。&lt;/p&gt;
    
    </summary>
    
      <category term="读书杂谈" scheme="http://yoursite.com/categories/%E8%AF%BB%E4%B9%A6%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="读书" scheme="http://yoursite.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
      <category term="生活" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
</feed>
